[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "5027A",
    "section": "",
    "text": "Overview\nThis course will introduce scientists and practitioners interested in applying statistical approaches in their daily routine using R as a working environment. Participants will be introduced into R and R Studio while learning how to perform common statistical analyses. After a short introduction on R and its principles, the focus will be on questions that could be addressed using common statistical analyses, both for descriptive statistics and for statistical inference.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#learning-outcomes",
    "href": "index.html#learning-outcomes",
    "title": "5027A",
    "section": "Learning outcomes",
    "text": "Learning outcomes\n\nUnderstand how to read, interpret and write scripts in R.\nLearn how to check and clean data\nLearn statistical tools to address common questions in research activities.\nAn introduction to efficient, readable and reproducible analyses\nBeing comfortable with using R when performing both descriptive and inferential statistics.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#how-to-use-this-book",
    "href": "index.html#how-to-use-this-book",
    "title": "5027A",
    "section": "How to use this book",
    "text": "How to use this book\nFor many of the chapters, we will provide the code you need to use. You can copy and paste from the book using the clipboard in the top-right corner.\nWe also provide the solutions to many of the activities. No-one is going to check whether you tried to figure it out yourself rather than going straight to the solution but remember this: if you copy and paste without thinking, you will learn nothing.\nFinally, on occasion we will make updates to the book such as fixing typos and including additional detail or activities and as such this book should be considered a living document. Please tell me if you find any mistakes.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#course-structure",
    "href": "index.html#course-structure",
    "title": "5027A",
    "section": "Course Structure",
    "text": "Course Structure\nWe have:\n\n\nOne workshop per week, these both timetabled in-person sessions, and you should check Timetabler for up to-date information on scheduling. However, everything you need to complete workshops will be available on this site.\n\nIf you feel unwell, or cannot attend a session in-person don’t worry you can access everything, and follow along in real time, or work at your own pace.\n\n\nOne assignment per week - this will be in the form of quizzes or short assignments, each assignment is worth 2% of your module grade (to a maximum of 15%) and there will be 10 assignments total.\nOne data analysis project - this will be a single piece of coursework (details after reading week) worth 20% of the the module grade",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "04-penguin-project.html",
    "href": "04-penguin-project.html",
    "title": "1  Meet the Penguins",
    "section": "",
    "text": "1.1 Meet the Penguins\nThis data, taken from the palmerpenguins (Horst et al. (2022)) package was originally published by Gorman et al. (2014). In our course we will work with real data that has been shared by other researchers.\nThe palmer penguins data contains size measurements, clutch observations, and blood isotope ratios for three penguin species observed on three islands in the Palmer Archipelago, Antarctica over a study period of three years.\nThese data were collected from 2007 - 2009 by Dr. Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network. The data were imported directly from the Environmental Data Initiative (EDI) Data Portal, and are available for use by CC0 license (“No Rights Reserved”) in accordance with the Palmer Station Data Policy. We gratefully acknowledge Palmer Station LTER and the US LTER Network. Special thanks to Marty Downs (Director, LTER Network Office) for help regarding the data license & use. Here is our intrepid package co-author, Dr. Gorman, in action collecting some penguin data:\nHere is a map of the study site",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Meet the Penguins</span>"
    ]
  },
  {
    "objectID": "04-penguin-project.html#activity-1-organising-our-workspace",
    "href": "04-penguin-project.html#activity-1-organising-our-workspace",
    "title": "1  Meet the Penguins",
    "section": "\n1.2 Activity 1: Organising our workspace",
    "text": "1.2 Activity 1: Organising our workspace\nBefore we can begin working with the data, we need to do some set-up.\n\nGo to RStudio Cloud and open the Penguins R project\n\nCreate the following folders using the + New Folder button in the Files tab\n\ndata\noutputs\nscripts\n\n\n\n\n\n\nR is case-sensitive so type everything EXACTLY as printed here\n\n\n\n\ndir.create(\"data\",\n           showWarnings = FALSE)\n\ndir.create(\"outputs\",\n           showWarnings = FALSE)\n\ndir.create(\"scripts\",\n           showWarnings = FALSE)\n\n# or this can be run using apply\nlapply(c(\"data\", \"outputs\", \"scripts\"), function(dir_name) {\n  dir.create(dir_name, showWarnings = FALSE)\n})\n\nHaving these separate subfolders within our project helps keep things tidy, means it’s harder to lose things, and lets you easily tell R exactly where to go to retrieve data.\nThe next step of our workflow is to have a well organised project space. RStudio Cloud does a lot of the hard work for you, each new data project can be set up with its own Project space.\nWe will define a project as a series of linked questions that uses one (or sometimes several) datasets. For example a coursework assignment for a particular module would be its own project, a series of linked experiments or particular research project might be its own project.\nA Project will contain several files, possibly organised into sub-folders containing data, R scripts and final outputs. You might want to keep any information (wider reading) you have gathered that is relevant to your project.\n\n\n\n\nAn example of a typical R project set-up\n\n\n\nWithin this project you will notice there is already one file .Rproj. This is an R project file, this is a very useful feature, it interacts with R to tell it you are working in a very specific place on the computer (in this case the cloud server we have dialed into). It means R will automatically treat the location of your project file as the ‘working directory’ and makes importing and exporting easier. More on projects can be found in the [R4DS]((https://r4ds.had.co.nz/workflow-projects.html) book.\n\n\n\nIt is very important to NEVER to move the .Rproj file, this may prevent your workspace from opening properly.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Meet the Penguins</span>"
    ]
  },
  {
    "objectID": "04-penguin-project.html#activity-2-access-our-data",
    "href": "04-penguin-project.html#activity-2-access-our-data",
    "title": "1  Meet the Penguins",
    "section": "\n1.3 Activity 2: Access our data",
    "text": "1.3 Activity 2: Access our data\nNow that we have a project workspace, we are ready to import some data.\n\nUse the link below to open a page in your browser with the data open\nRight-click Save As to download in csv format to your computer (Make a note of where the file is being downloaded to e.g. Downloads)\n\n\n\n\n Download penguin data as csv\n\n\n\n\n\n\n\nTop image: Penguins data viewed in Excel, Bottom image: Penguins data in native csv format\n\n\n\nIn raw format, each line of a CSV is separated by commas for different values. When you open this in a spreadsheet program like Excel it automatically converts those comma-separated values into tables and columns.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Meet the Penguins</span>"
    ]
  },
  {
    "objectID": "04-penguin-project.html#activity-3-upload-our-data",
    "href": "04-penguin-project.html#activity-3-upload-our-data",
    "title": "1  Meet the Penguins",
    "section": "\n1.4 Activity 3: Upload our data",
    "text": "1.4 Activity 3: Upload our data\n\nThe data is now in your Downloads folder on your computer\nWe need to upload the data to our remote cloud-server (RStudio Cloud), select the upload files to server button in the Files tab\nPut your file into the data folder - if you make a mistake select the tickbox for your file, go to the cogs button and choose the option Move.\n\n\n\n\n\nHighlighted the buttons to upload files, and more options\n\n\n\n\n1.4.1 Read data from a url\nIt is also possible to use a url as a filepath\n\nurl &lt;- \"https://raw.githubusercontent.com/UEABIO/data-sci-v1/main/book/files/penguins_raw.csv\"\nread_csv(url)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Meet the Penguins</span>"
    ]
  },
  {
    "objectID": "04-penguin-project.html#activity-4-make-a-script",
    "href": "04-penguin-project.html#activity-4-make-a-script",
    "title": "1  Meet the Penguins",
    "section": "\n1.5 Activity 4: Make a script",
    "text": "1.5 Activity 4: Make a script\nLet’s now create a new R script file in which we will write instructions and store comments for manipulating data, developing tables and figures. Use the File &gt; New Script menu item and select an R Script.\nAdd the following:\n\n#___________________________----\n# SET UP ----\n# An analysis of the bill dimensions of male and female \n# Adelie, Gentoo and Chinstrap penguins\n\n# Data first published in  Gorman, KB, TD Williams, and WR Fraser. \n# 2014. \n# “Ecological Sexual Dimorphism and Environmental Variability \n# Within a Community of Antarctic Penguins (Genus Pygoscelis).” \n# PLos One 9 (3): e90081.\n# https://doi.org/10.1371/journal.pone.0090081. \n#__________________________----\n\nThen load the following add-on package to the R script, just underneath these comments. Tidyverse isn’t actually one package, but a bundle of many different packages that play well together - for example it includes ggplot2 a package for making figures.\nAdd the following to your script:\n\n# PACKAGES ----\nlibrary(tidyverse) # tidy data packages\nlibrary(janitor) # cleans variable names\n#__________________________----\n\nSave this file inside the scripts folder and call it 01_import_penguins_data.R\n\n\n\nClick on the document outline button (top right of script pane). This will show you how the use of the visual outline\n\n\nAllows us to build a series of headers and subheaders, this is very useful when using longer scripts.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Meet the Penguins</span>"
    ]
  },
  {
    "objectID": "04-penguin-project.html#activity-5-read-in-data",
    "href": "04-penguin-project.html#activity-5-read-in-data",
    "title": "1  Meet the Penguins",
    "section": "\n1.6 Activity 5: Read in data",
    "text": "1.6 Activity 5: Read in data\nNow we can read in the data. To do this we will use the function readr::read_csv() that allows us to read in .csv files. There are also functions that allow you to read in .xlsx files and other formats, however in this course we will only use .csv files.\n\nFirst, we will create an object called penguins_data that contains the data in the penguins_raw.csv file.\nAdd the following to your script, and check the document outline:\n\n\n# IMPORT DATA ----\npenguins_raw &lt;- read_csv (\"data/penguins_raw.csv\")\n\n# penguins_raw &lt;- read_csv(here(\"data\", \"penguins_raw.csv\"))\n\n# check the data has loaded\nhead(penguins_raw)\n#__________________________----\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\nPAL0708\n1\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A1\nYes\n11/11/2007\n39.1\n18.7\n181\n3750\nMALE\nNA\nNA\nNot enough blood for isotopes.\n\n\nPAL0708\n2\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A2\nYes\n11/11/2007\n39.5\n17.4\n186\n3800\nFEMALE\n8.94956\n-24.69454\nNA\n\n\nPAL0708\n3\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n16/11/2007\n40.3\n18.0\n195\n3250\nFEMALE\n8.36821\n-25.33302\nNA\n\n\nPAL0708\n4\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A2\nYes\n16/11/2007\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nAdult not sampled.\n\n\nPAL0708\n5\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n16/11/2007\n36.7\n19.3\n193\n3450\nFEMALE\n8.76651\n-25.32426\nNA\n\n\nPAL0708\n6\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A2\nYes\n16/11/2007\n39.3\n20.6\n190\n3650\nMALE\n8.66496\n-25.29805\nNA\n\n\n\n\n\n\n\n\n\nNote the differences between read.csv() and read_csv. We covered this in differences between tibbles and dataframes - here most obviously is a difference in column names.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Meet the Penguins</span>"
    ]
  },
  {
    "objectID": "04-penguin-project.html#activity-check-your-script",
    "href": "04-penguin-project.html#activity-check-your-script",
    "title": "1  Meet the Penguins",
    "section": "\n1.7 Activity: Check your script",
    "text": "1.7 Activity: Check your script\n\n\nSolution\n\n\n#___________________________----\n# SET UP ----\n# An analysis of the bill dimensions of male and female \n# Adelie, Gentoo and Chinstrap penguins\n\n# Data first published in  Gorman, KB, TD Williams, and WR Fraser. \n# 2014. \n# “Ecological Sexual Dimorphism and Environmental Variability \n# Within a Community of Antarctic Penguins (Genus Pygoscelis).” \n# PLos One 9 (3): e90081.\n# https://doi.org/10.1371/journal.pone.0090081. \n#__________________________----\n\n# PACKAGES ----\n# tidy data packages\nlibrary(tidyverse) \n# cleans variable names\nlibrary(janitor) \n# make sure dates are processed properly\nlibrary(lubridate) \n#__________________________----\n\n# IMPORT DATA ----\npenguins_raw &lt;- read_csv (\"data/penguins_raw.csv\")\n\n# check the data has loaded, prints first 10 rows of dataframe\nhead(penguins_raw) \n#__________________________----",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Meet the Penguins</span>"
    ]
  },
  {
    "objectID": "04-penguin-project.html#activity-test-yourself",
    "href": "04-penguin-project.html#activity-test-yourself",
    "title": "1  Meet the Penguins",
    "section": "\n1.8 Activity: Test yourself",
    "text": "1.8 Activity: Test yourself\nQuestion 1. In order to make your R project reproducible what filepath should you use?\n\nAbsolute filepath\nRelative filepath\nQuestion 2. Which of these would be acceptable to include in a raw datafile?\n\nHighlighting some blocks of cells\nExcel formulae\nA column of observational notes from the field\na mix of ddmmyy and yymmdd date formats\nQuestion 3. What should always be the first set of functions in our script? ?()\n\nQuestion 4. When reading in data to R we should use\n\nread_csv()\nread.csv()\nQuestion 5. What format is the penguins_raw data in?\n\nmessy data\ntidy data\n\n\nExplain This Answer\n\n\nEach column is a unique variable and each row is a unique observation so this data is in a long (tidy) format\n\n\nQuestion 6. The working directory for your projects is by default set to the location of?\n\nyour data files\nthe .Rproj file\nyour R script\nQuestion 7. Using the filepath \"data/penguins_raw.csv\" is an example of\n\nan absolute filepath\na relative filepath\nQuestion 8. What operator do I need to use if I wish to assign the output of the read_csv function to an R object (rather than just print the dataframe into the console)?\n\n\n\n\n\nGorman, K., Williams, T., & Fraser, W. (2014). Ecological sexual dimorphism and environmental variability within a community of antarctic penguins (genus pygoscelis). PLos One, 9(3), e90081. https://doi.org/10.1371/journal.pone.0090081\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Meet the Penguins</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html",
    "href": "05-dplyr.html",
    "title": "2  Data cleaning",
    "section": "",
    "text": "2.1 Introduction to dplyr\nIn this section we will be introduced to some of the most commonly used data wrangling functions, these come from the dplyr package (part of the tidyverse). These are functions you are likely to become very familiar with.\nverb\naction\n\n\n\nselect()\nchoose columns by name\n\n\nfilter()\nselect rows based on conditions\n\n\narrange()\nreorder the rows\n\n\nsummarise()\nreduce raw data to user defined summaries\n\n\ngroup_by()\ngroup the rows by a specified column\n\n\nmutate()\ncreate a new variable",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#introduction-to-dplyr",
    "href": "05-dplyr.html#introduction-to-dplyr",
    "title": "2  Data cleaning",
    "section": "",
    "text": "Important\n\n\n\nTry running the following functions directly in your consoleThe R console is the interactive interface within the R environment where users can type and execute R code. It is the place where you can directly enter commands, see their output, and interact with the R programming language in real-time. or make a scraps.R scrappy file to mess around in.\n\n\n\n\n2.1.1 Select\nIf we wanted to create a dataset that only includes certain variables, we can use the dplyr::select() function from the dplyr package.\nFor example I might wish to create a simplified dataset that only contains species, sex, flipper_length_mm and body_mass_g.\nRun the below code to select only those columns\n\nselect(\n   # the data object\n  .data = penguins_raw,\n   # the variables you want to select\n  `Species`, `Sex`, `Flipper Length (mm)`, `Body Mass (g)`)\n\nAlternatively you could tell R the columns you don’t want e.g. \n\nselect(.data = penguins_raw,\n       -`studyName`, -`Sample Number`)\n\nNote that select() does not change the original penguins tibble. It spits out the new tibble directly into your console.\nIf you don’t save this new tibble, it won’t be stored. If you want to keep it, then you must create a new object.\nWhen you run this new code, you will not see anything in your console, but you will see a new object appear in your Environment pane.\n\nnew_penguins &lt;- select(.data = penguins_raw, \n       `Species, `Sex`, `Flipper Length (mm)`, `Body Mass (g)`)\n\n\n2.1.2 Filter\nHaving previously used dplyr::select() to select certain variables, we will now use dplyr::filter() to select only certain rows or observations. For example only Adelie penguins.\nWe can do this with the equivalence operator ==\n\nfilter(.data = new_penguins, \n       `Species` == \"Adelie Penguin (Pygoscelis adeliae)\")\n\nWe can use several different operators to assess the way in which we should filter our data that work the same in tidyverse or base R.\n\n\n\nBoolean expressions\n\nOperator\nName\n\n\n\nA &lt; B\nless than\n\n\nA &lt;= B\nless than or equal to\n\n\nA &gt; B\ngreater than\n\n\nA &gt;= B\ngreater than or equal to\n\n\nA == B\nequivalence\n\n\nA != B\nnot equal\n\n\nA %in% B\nin\n\n\n\n\n\nIf you wanted to select all the Penguin species except Adelies, you use ‘not equals’.\n\nfilter(.data = new_penguins, \n       `Species` != \"Adelie Penguin (Pygoscelis adeliae)\")\n\nThis is the same as\n\nfilter(.data = new_penguins, \n       `Species` %in% c(\"Chinstrap penguin (Pygoscelis antarctica)\",\n                      \"Gentoo penguin (Pygoscelis papua)\")\n       )\n\nYou can include multiple expressions within filter() and it will pull out only those rows that evaluate to TRUE for all of your conditions.\nFor example the below code will pull out only those observations of Adelie penguins where flipper length was measured as greater than 190mm.\n\nfilter(.data = new_penguins, \n       `Species` == \"Adelie Penguin (Pygoscelis adeliae)\", \n       `Flipper Length (mm)` &gt; 190)\n\n\n2.1.3 Arrange\nThe function arrange() sorts the rows in the table according to the columns supplied. For example\n\narrange(.data = new_penguins, \n        `Sex`)\n\nThe data is now arranged in alphabetical order by sex. So all of the observations of female penguins are listed before males.\nYou can also reverse this with desc()\n\narrange(.data = new_penguins, \n        desc(`Sex`))\n\nYou can also sort by more than one column, what do you think the code below does?\n\narrange(.data = new_penguins,\n        `Sex`,\n        desc(`Species`),\n        desc(`Flipper Length (mm)`))\n\n\n2.1.4 Mutate\nSometimes we need to create a new variable that doesn’t exist in our dataset. For example we might want to figure out what the flipper length is when factoring in body mass.\nTo create new variables we use the function mutate().\nNote that as before, if you want to save your new column you must save it as an object. Here we are mutating a new column and attaching it to the new_penguins data oject.\n\nnew_penguins &lt;- mutate(.data = new_penguins,\n                     body_mass_kg = `Body Mass (g)`/1000)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#pipes",
    "href": "05-dplyr.html#pipes",
    "title": "2  Data cleaning",
    "section": "\n2.2 Pipes",
    "text": "2.2 Pipes\n\n\n\n\n\n\n\n\nPipes look like this: |&gt; , a pipeAn operator that allows you to chain multiple functions together in a sequence allows you to send the output from one function straight into another function. Specifically, they send the result of the function before |&gt; to be the first argument of the function after |&gt;. As usual, it’s easier to show, rather than tell so let’s look at an example.\n\n# this example uses brackets to nest and order functions\narrange(.data = filter(\n  .data = select(\n  .data = penguins_raw, \n  species, `Sex`, `Flipper Length (mm)`), \n  `Sex` == \"MALE\"), \n  desc(`Flipper Length (mm)`))\n\n\n# this example uses sequential R objects \nobject_1 &lt;- select(.data = penguins_raw, \n                   `Species`, `Sex`, `Flipper Length (mm)`)\nobject_2 &lt;- filter(.data = object_1, \n                   `Sex` == \"MALE\")\narrange(object_2, \n        desc(`Flipper Length (mm)`))\n\n\n# this example is human readable without intermediate objects\npenguins_raw |&gt;  \n  select(`Species`, `Sex`, `Flipper Length (mm)`) |&gt;  \n  filter(`Sex` == \"MALE\") |&gt;  \n  arrange(`Flipper Length (mm)`))\n\nThe reason that this function is called a pipe is because it ‘pipes’ the data through to the next function. When you wrote the code previously, the first argument of each function was the dataset you wanted to work on. When you use pipes it will automatically take the data from the previous line of code so you don’t need to specify it again.\n\n2.2.1 Task\nTry and write out as plain English what the |&gt; above is doing? You can read the |&gt; as THEN\n\n\nSolution\n\nTake the penguins data AND THEN Select only the species, sex and flipper length columns AND THEN Filter to keep only those observations labelled as sex equals male AND THEN Arrange the data from HIGHEST to LOWEST flipper lengths.\n\n\n\n\nFrom R version 4 onwards there is now a “native pipe” |&gt;\n\n\nThis doesn’t require the tidyverse magrittr package and the “old pipe” %&gt;% or any other packages to load and use.\n\n\nYou may be familiar with the magrittr pipe or see it in other tutorials, and website usages. The native pipe works equivalntly in most situations but if you want to read about some of the operational differences, this site does a good job of explaining .",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#clean-the-penguin-data",
    "href": "05-dplyr.html#clean-the-penguin-data",
    "title": "2  Data cleaning",
    "section": "\n2.3 Clean the Penguin Data",
    "text": "2.3 Clean the Penguin Data\n\n\n\n\n\n\nWarning\n\n\n\nRe-open your 01_import_penguins_data.R started in Chapter 1 and start to add these commands to your data importing and cleaning script:\n\n\n\n2.3.1 Activity 1: Explore data structure\nBefore working with your data, it’s essential to understand its underlying structure and content. In this section, we’ll use powerful functions like glimpse(), str(), summary(), head(),tail()and the add-on functionskimr::skim()` to thoroughly examine your dataset. These tools provide insights into data types, variable distributions, and sample records, helping you identify initial issues such as missing values or inconsistent data types. By gaining a clear understanding of your data’s structure, you’ll be better equipped to address any problems and proceed confidently with data cleaning and analysis.\nWhen we run glimpse() we get several lines of output. The number of observations “rows”, the number of variables “columns”. Check this against the csv file you have - they should be the same. In the next lines we see variable names and the type of data.\n\nglimpse(penguins_raw)\n\nRows: 344\nColumns: 17\n$ studyName             &lt;chr&gt; \"PAL0708\", \"PAL0708\", \"PAL0708\", \"PAL0708\", \"PAL…\n$ `Sample Number`       &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1…\n$ Species               &lt;chr&gt; \"Adelie Penguin (Pygoscelis adeliae)\", \"Adelie P…\n$ Region                &lt;chr&gt; \"Anvers\", \"Anvers\", \"Anvers\", \"Anvers\", \"Anvers\"…\n$ Island                &lt;chr&gt; \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgerse…\n$ Stage                 &lt;chr&gt; \"Adult, 1 Egg Stage\", \"Adult, 1 Egg Stage\", \"Adu…\n$ `Individual ID`       &lt;chr&gt; \"N1A1\", \"N1A2\", \"N2A1\", \"N2A2\", \"N3A1\", \"N3A2\", …\n$ `Clutch Completion`   &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", …\n$ `Date Egg`            &lt;chr&gt; \"11/11/2007\", \"11/11/2007\", \"16/11/2007\", \"16/11…\n$ `Culmen Length (mm)`  &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34…\n$ `Culmen Depth (mm)`   &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18…\n$ `Flipper Length (mm)` &lt;dbl&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190,…\n$ `Body Mass (g)`       &lt;dbl&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 34…\n$ Sex                   &lt;chr&gt; \"MALE\", \"FEMALE\", \"FEMALE\", NA, \"FEMALE\", \"MALE\"…\n$ `Delta 15 N (o/oo)`   &lt;dbl&gt; NA, 8.94956, 8.36821, NA, 8.76651, 8.66496, 9.18…\n$ `Delta 13 C (o/oo)`   &lt;dbl&gt; NA, -24.69454, -25.33302, NA, -25.32426, -25.298…\n$ Comments              &lt;chr&gt; \"Not enough blood for isotopes.\", NA, NA, \"Adult…\n\n\nWe can see a dataset with 345 rows (including the headers) and 17 variables It also provides information on the type of data in each column\n\n&lt;chr&gt; - means character or text data\n&lt;dbl&gt; - means numerical data\n\nWhen we run summary() we get similar information, in addition for any numerical values we get summary statistics such as mean, median, min, max, quartile ranges and any missing (NA) values\n\nsummary(penguins_raw)\n\n  studyName         Sample Number      Species             Region         \n Length:344         Min.   :  1.00   Length:344         Length:344        \n Class :character   1st Qu.: 29.00   Class :character   Class :character  \n Mode  :character   Median : 58.00   Mode  :character   Mode  :character  \n                    Mean   : 63.15                                        \n                    3rd Qu.: 95.25                                        \n                    Max.   :152.00                                        \n                                                                          \n    Island             Stage           Individual ID      Clutch Completion \n Length:344         Length:344         Length:344         Length:344        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   Date Egg         Culmen Length (mm) Culmen Depth (mm) Flipper Length (mm)\n Length:344         Min.   :32.10      Min.   :13.10     Min.   :172.0      \n Class :character   1st Qu.:39.23      1st Qu.:15.60     1st Qu.:190.0      \n Mode  :character   Median :44.45      Median :17.30     Median :197.0      \n                    Mean   :43.92      Mean   :17.15     Mean   :200.9      \n                    3rd Qu.:48.50      3rd Qu.:18.70     3rd Qu.:213.0      \n                    Max.   :59.60      Max.   :21.50     Max.   :231.0      \n                    NA's   :2          NA's   :2         NA's   :2          \n Body Mass (g)      Sex            Delta 15 N (o/oo) Delta 13 C (o/oo)\n Min.   :2700   Length:344         Min.   : 7.632    Min.   :-27.02   \n 1st Qu.:3550   Class :character   1st Qu.: 8.300    1st Qu.:-26.32   \n Median :4050   Mode  :character   Median : 8.652    Median :-25.83   \n Mean   :4202                      Mean   : 8.733    Mean   :-25.69   \n 3rd Qu.:4750                      3rd Qu.: 9.172    3rd Qu.:-25.06   \n Max.   :6300                      Max.   :10.025    Max.   :-23.79   \n NA's   :2                         NA's   :14        NA's   :13       \n   Comments        \n Length:344        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\n\nFinally the add-on package skimr provides the function skimr::skim() provides an easy to view set of summaries including column types, completion rate, number of unique variables in each column and similar statistical summaries along with a small histogram for each numeric variable.\n\nlibrary(skimr)\nskim(penguins_raw)\n\n\nData summary\n\n\nName\npenguins_raw\n\n\nNumber of rows\n344\n\n\nNumber of columns\n17\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n10\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\nstudyName\n0\n1.00\n7\n7\n0\n3\n0\n\n\nSpecies\n0\n1.00\n33\n41\n0\n3\n0\n\n\nRegion\n0\n1.00\n6\n6\n0\n1\n0\n\n\nIsland\n0\n1.00\n5\n9\n0\n3\n0\n\n\nStage\n0\n1.00\n18\n18\n0\n1\n0\n\n\nIndividual ID\n0\n1.00\n4\n6\n0\n190\n0\n\n\nClutch Completion\n0\n1.00\n2\n3\n0\n2\n0\n\n\nDate Egg\n0\n1.00\n10\n10\n0\n50\n0\n\n\nSex\n11\n0.97\n4\n6\n0\n2\n0\n\n\nComments\n290\n0.16\n18\n68\n0\n10\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nSample Number\n0\n1.00\n63.15\n40.43\n1.00\n29.00\n58.00\n95.25\n152.00\n▇▇▆▅▃\n\n\nCulmen Length (mm)\n2\n0.99\n43.92\n5.46\n32.10\n39.23\n44.45\n48.50\n59.60\n▃▇▇▆▁\n\n\nCulmen Depth (mm)\n2\n0.99\n17.15\n1.97\n13.10\n15.60\n17.30\n18.70\n21.50\n▅▅▇▇▂\n\n\nFlipper Length (mm)\n2\n0.99\n200.92\n14.06\n172.00\n190.00\n197.00\n213.00\n231.00\n▂▇▃▅▂\n\n\nBody Mass (g)\n2\n0.99\n4201.75\n801.95\n2700.00\n3550.00\n4050.00\n4750.00\n6300.00\n▃▇▆▃▂\n\n\nDelta 15 N (o/oo)\n14\n0.96\n8.73\n0.55\n7.63\n8.30\n8.65\n9.17\n10.03\n▃▇▆▅▂\n\n\nDelta 13 C (o/oo)\n13\n0.96\n-25.69\n0.79\n-27.02\n-26.32\n-25.83\n-25.06\n-23.79\n▆▇▅▅▂\n\n\n\n\n\nQ Based on our summary functions are any variables assigned to the wrong data type (should be character when numeric or vice versa)?\n\nYes\nNo\n\n\nExplanation\n\nAlthough some columns like date might not be correctly treated as character variables, they are not strictly numeric either, all other columns appear correct\n\nQ Based on our summary functions do we have complete data for all variables?\n\nYes\nNo\n\n\nExplanation\n\nNo, they are 2 missing data points for body measurements (culmen, flipper, body mass), 11 missing data points for sex, 13/14 missing data points for blood isotopes (Delta N/C) and 290 missing data points for comments\n\n\n2.3.2 Activity 2: Clean column names\n\n# CHECK DATA----\n# check the data\ncolnames(penguins_raw)\n#__________________________----\n\n [1] \"studyName\"           \"Sample Number\"       \"Species\"            \n [4] \"Region\"              \"Island\"              \"Stage\"              \n [7] \"Individual ID\"       \"Clutch Completion\"   \"Date Egg\"           \n[10] \"Culmen Length (mm)\"  \"Culmen Depth (mm)\"   \"Flipper Length (mm)\"\n[13] \"Body Mass (g)\"       \"Sex\"                 \"Delta 15 N (o/oo)\"  \n[16] \"Delta 13 C (o/oo)\"   \"Comments\"           \n\n\nWhen we run colnames() we get the identities of each column in our dataframe\n\nStudy name: an identifier for the year in which sets of observations were made\nRegion: the area in which the observation was recorded\nIsland: the specific island where the observation was recorded\nStage: Denotes reproductive stage of the penguin\nIndividual ID: the unique ID of the individual\nClutch completion: if the study nest observed with a full clutch e.g. 2 eggs\nDate egg: the date at which the study nest observed with 1 egg\nCulmen length: length of the dorsal ridge of the bird’s bill (mm)\nCulmen depth: depth of the dorsal ridge of the bird’s bill (mm)\nFlipper Length: length of bird’s flipper (mm)\nBody Mass: Bird’s mass in (g)\nSex: Denotes the sex of the bird\nDelta 15N : the ratio of stable Nitrogen isotopes 15N:14N from blood sample\nDelta 13C: the ratio of stable Carbon isotopes 13C:12C from blood sample\n\n\n2.3.2.1 Clean column names\nOften we might want to change the names of our variables. They might be non-intuitive, or too long. Our data has a couple of issues:\n\nSome of the names contain spaces\nSome of the names have capitalised letters\nSome of the names contain brackets\n\nR is case-sensitive and also doesn’t like spaces or brackets in variable names, because of this we have been forced to use backticks `Sample Number` to prevent errors when using these column names\n\n# CLEAN DATA ----\n\n# clean all variable names to snake_case \n# using the clean_names function from the janitor package\n# note we are using assign &lt;- \n# to overwrite the old version of penguins \n# with a version that has updated names\n# this changes the data in our R workspace \n# but NOT the original csv file\n\n# clean the column names\n# assign to new R object\npenguins_clean &lt;- janitor::clean_names(penguins_raw) \n\n# quickly check the new variable names\ncolnames(penguins_clean) \n\n [1] \"study_name\"        \"sample_number\"     \"species\"          \n [4] \"region\"            \"island\"            \"stage\"            \n [7] \"individual_id\"     \"clutch_completion\" \"date_egg\"         \n[10] \"culmen_length_mm\"  \"culmen_depth_mm\"   \"flipper_length_mm\"\n[13] \"body_mass_g\"       \"sex\"               \"delta_15_n_o_oo\"  \n[16] \"delta_13_c_o_oo\"   \"comments\"         \n\n\n\n\nImport and clean names\n\nWe can combine data import and name repair in a single step if we want to:\n\npenguins_clean &lt;- read_csv (\"data/penguins_raw.csv\",\n                      name_repair = janitor::make_clean_names)\n\n\n\n2.3.2.2 Rename columns (manually)\nThe clean_names function quickly converts all variable names into snake caseSnake case is a naming convention in computing that uses underscores to replace spaces between words, and writes words in lowercase. It’s commonly used for variable and subroutine names, filenames, and database table and column names. The N and C blood isotope ratio names are still quite long though, so let’s clean those with dplyr::rename() where “new_name” = “old_name”.\n\n# shorten the variable names for isotope blood samples\n# use rename from the dplyr package\npenguins_clean &lt;- rename(penguins_clean,\n         \"delta_15n\"=\"delta_15_n_o_oo\",  \n         \"delta_13c\"=\"delta_13_c_o_oo\")\n\n\n2.3.2.3 Rename text values manually\nSometimes we may want to rename the values in our variables in order to make a shorthand that is easier to follow. This is changing the values in our columns, not the column names.\n\n# use mutate and case_when \n# for a statement that conditionally changes \n# the names of the values in a variable\npenguins &lt;- penguins_clean |&gt; \n  mutate(species = case_when(\n  species == \"Adelie Penguin (Pygoscelis adeliae)\" ~ \"Adelie\",\n  species == \"Gentoo penguin (Pygoscelis papua)\" ~ \"Gentoo\",\n  species == \"Chinstrap penguin (Pygoscelis antarctica)\" ~ \"Chinstrap\",\n  .default = as.character(species)\n  )\n  )\n\n\n# use mutate and if_else\n# for a statement that conditionally changes \n# the names of the values in a variable\npenguins &lt;- penguins |&gt; \n  mutate(sex = if_else(\n    sex == \"MALE\", \"Male\", \"Female\"\n  )\n  )\n\n\n\n\n\n\n\nWarning\n\n\n\nNotice from here on out I am assigning the output of my code to the R object penguins, this means any new code “overwrites” the old penguins dataframe. This is because I ran out of new names I could think of, its also because my Environment is filling up with lots of data frame variants.\nBe aware that when you run code in this way, it can cause errors if you try to run the same code twice e.g. in the example above once you have changed MALE to Male, running the code again could cause errors as MALE is no longer present!\nIf you make any mistakes running code in this way, re-start your R session and run the code from the start to where you went wrong.\n\n\n\n\n\nHave you checked that the above code block worked? Inspect your new tibble and check the variables have been renamed as you wanted.\n\n\n\n\n2.3.2.4 Rename text values with stringr\nDatasets often contain words, and we call these words “(character) strings”.\nOften these aren’t quite how we want them to be, but we can manipulate these as much as we like. Functions in the package stringr, are fantastic. And the number of different types of manipulations are endless!\nBelow we repeat the outcomes above, but with string matching:\n\n# use mutate and case_when \n# for a statement that conditionally changes \n# the names of the values in a variable\npenguins &lt;- penguins_clean |&gt; \n  mutate(species = stringr::word(species, 1)\n  ) |&gt; \n  mutate(sex = stringr::str_to_title(sex))\n\nAlternatively we could decide we want simpler species names but that we would like to keep the latin name information, but in a separate column. To do this we are using regex. Regular expressions are a concise and flexible tool for describing patterns in strings\n\npenguins_clean |&gt; \n    separate(\n        species,\n        into = c(\"species\", \"full_latin_name\"),\n        sep = \"(?=\\\\()\"\n    ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstudy_name\nsample_number\nspecies\nfull_latin_name\nregion\nisland\nstage\nindividual_id\nclutch_completion\ndate_egg\nculmen_length_mm\nculmen_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\ndelta_15n\ndelta_13c\ncomments\n\n\n\nPAL0708\n1\nAdelie Penguin\n(Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A1\nYes\n11/11/2007\n39.1\n18.7\n181\n3750\nMALE\nNA\nNA\nNot enough blood for isotopes.\n\n\nPAL0708\n2\nAdelie Penguin\n(Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A2\nYes\n11/11/2007\n39.5\n17.4\n186\n3800\nFEMALE\n8.94956\n-24.69454\nNA\n\n\nPAL0708\n3\nAdelie Penguin\n(Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n16/11/2007\n40.3\n18.0\n195\n3250\nFEMALE\n8.36821\n-25.33302\nNA\n\n\nPAL0708\n4\nAdelie Penguin\n(Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A2\nYes\n16/11/2007\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nAdult not sampled.\n\n\nPAL0708\n5\nAdelie Penguin\n(Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n16/11/2007\n36.7\n19.3\n193\n3450\nFEMALE\n8.76651\n-25.32426\nNA\n\n\nPAL0708\n6\nAdelie Penguin\n(Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A2\nYes\n16/11/2007\n39.3\n20.6\n190\n3650\nMALE\n8.66496\n-25.29805\nNA\n\n\n\n\n\n\n\n2.3.3 Activity 2: Checking for duplications\nIt is very easy when inputting data to make mistakes, copy something in twice for example, or if someone did a lot of copy-pasting to assemble a spreadsheet (yikes!). We can check this pretty quickly\n\n# check for whole duplicate \n# rows in the data\npenguins |&gt; \n  duplicated() |&gt;  \n  sum() \n\n[1] 0\nGreat!\nIf I did have duplications I could investigate further and extract these exact rows:\n\n# Inspect duplicated rows\npenguins |&gt; \n    filter(duplicated(penguins))\n\nA tibble:0 × 17\n0 rows | 1-8 of 17 columns\n\n# Keep only unduplicated data\npenguins |&gt; \n    filter(!duplicated(penguins))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstudy_name\nsample_number\nspecies\nregion\nisland\nstage\nindividual_id\nclutch_completion\ndate_egg\nculmen_length_mm\nculmen_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\ndelta_15n\ndelta_13c\ncomments\n\n\n\nPAL0708\n1\nAdelie\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A1\nYes\n11/11/2007\n39.1\n18.7\n181\n3750\nMale\nNA\nNA\nNot enough blood for isotopes.\n\n\nPAL0708\n2\nAdelie\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A2\nYes\n11/11/2007\n39.5\n17.4\n186\n3800\nFemale\n8.94956\n-24.69454\nNA\n\n\nPAL0708\n3\nAdelie\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n16/11/2007\n40.3\n18.0\n195\n3250\nFemale\n8.36821\n-25.33302\nNA\n\n\nPAL0708\n4\nAdelie\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A2\nYes\n16/11/2007\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nAdult not sampled.\n\n\nPAL0708\n5\nAdelie\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n16/11/2007\n36.7\n19.3\n193\n3450\nFemale\n8.76651\n-25.32426\nNA\n\n\nPAL0708\n6\nAdelie\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A2\nYes\n16/11/2007\n39.3\n20.6\n190\n3650\nMale\n8.66496\n-25.29805\nNA\n\n\n\n\n\n\n\n2.3.4 Activity 3: Checking for typos\nWe can also look for typos by asking R to produce all of the distinct values in a variable. This is more useful for categorical data, where we expect there to be only a few distinct categories\n\n# Print only unique character strings in this variable\npenguins |&gt;  \n  distinct(sex)\n\n\n\n\nsex\n\n\n\nMale\n\n\nFemale\n\n\nNA\n\n\n\n\n\n\nHere if someone had mistyped e.g. ‘FMALE’ it would be obvious. We could do the same thing (and probably should have before we changed the names) for species.\nWe can also trim leading or trailing empty spaces with stringr::str_trim. These are often problematic and difficult to spot e.g.\n\ndf2 &lt;- tibble(label=c(\"penguin\", \" penguin\", \"penguin \")) \ndf2 # make a test dataframe\n\n\n\n\nlabel\n\n\n\npenguin\n\n\npenguin\n\n\npenguin\n\n\n\n\n\n\nWe can easily imagine a scenario where data is manually input, and trailing or leading spaces are left in. These are difficult to spot by eye - but problematic because as far as R is concerned these are different values. We can use the function distinct to return the names of all the different levels it can find in this dataframe.\n\ndf2 |&gt; \n  distinct()\n\n\n\n\nlabel\n\n\n\npenguin\n\n\npenguin\n\n\npenguin\n\n\n\n\n\n\nIf we pipe the data throught the str_trim function to remove any gaps, then pipe this on to distinct again - by removing the whitespace, R now recognises just one level to this data.\n\ndf2 |&gt; \n  mutate(label=str_trim(label, side=\"both\")) |&gt; \n  distinct()\n\n\n\n\nlabel\n\n\npenguin",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#working-with-dates",
    "href": "05-dplyr.html#working-with-dates",
    "title": "2  Data cleaning",
    "section": "\n2.4 Working with dates",
    "text": "2.4 Working with dates\nWorking with dates can be tricky, treating date as strictly numeric is problematic, it won’t account for number of days in months or number of months in a year.\nAdditionally there’s a lot of different ways to write the same date:\n\n13-10-2019\n10-13-2019\n13-10-19\n13th Oct 2019\n2019-10-13\n\nThis variability makes it difficult to tell our software how to read the information, luckily we can use the functions in the lubridate package.\n\n\n\nIf you get a warning that some dates could not be parsed, then you might find the date has been inconsistently entered into the dataset.\n\n\nPay attention to warning and error messages\n\n\n\nDepending on how we interpret the date ordering in a file, we can use ymd(), ydm(), mdy(), dmy()\n\n\nQuestion What is the appropriate function from the above to use on the date_egg variable?\n\n\nymd()ydm()mdy()dmy()\n\n\n\nSolution\n\n\npenguins &lt;- penguins |&gt;\n  mutate(date_egg = lubridate::dmy(date_egg))\n\n\nHere we use the mutate function from dplyr to create a new variable called date_egg_proper based on the output of converting the characters in date_egg to date format. The original variable is left intact, if we had specified the “new” variable was also called date_egg then it would have overwritten the original variable.\nOnce we have established our date data, we are able to perform calculations or extract information. Such as the date range across which our data was collected.\n\n2.4.1 Calculations with dates\n\npenguins |&gt; \n  summarise(min_date=min(date_egg_proper),\n            max_date=max(date_egg_proper))\n\nWe can also extract and make new columns from our date column - such as a simple column of the year when each observation was made:\n\npenguins |&gt; \n  mutate(year = lubridate::year(date_egg))",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#factors",
    "href": "05-dplyr.html#factors",
    "title": "2  Data cleaning",
    "section": "\n2.5 Factors",
    "text": "2.5 Factors\nIn R, factors are a class of data that allow for ordered categories with a fixed set of acceptable values.\nTypically, you would convert a column from character or numeric class to a factor if you want to set an intrinsic order to the values (“levels”) so they can be displayed non-alphabetically in plots and tables, or for use in linear model analyses (more on this later).\nWorking with factors is easy with the forcats package:\nUsing across - we can apply functions to columns based on selected criteria - here within mutate we are changing each column in the .cols argument and applying the function forcats::as_factor()\n\npenguins |&gt; \n  mutate(\n    across(.cols = c(\"species\", \"region\", \"island\", \"stage\", \"sex\"),\n           .fns = forcats::as_factor)\n  ) |&gt; \n  select(where(is.factor)) |&gt; \n  glimpse()\n\nRows: 344\nColumns: 5\n$ species &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelie…\n$ region  &lt;fct&gt; Anvers, Anvers, Anvers, Anvers, Anvers, Anvers, Anvers, Anvers…\n$ island  &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgersen, Torgers…\n$ stage   &lt;fct&gt; \"Adult, 1 Egg Stage\", \"Adult, 1 Egg Stage\", \"Adult, 1 Egg Stag…\n$ sex     &lt;fct&gt; Male, Female, Female, NA, Female, Male, Female, Male, NA, NA, …\n\n\n\n\n\n\n\n\nImportant\n\n\n\nUnless we assign the output of this code to an R object it will just print into the console, in the above I am demonstrating how to change variables to factors but we aren’t “saving” this change.\n\n\n\n2.5.1 Setting factor levels\nIf we want to specify the correct order for a factor we can use forcats::fct_relevel\n\npenguins &lt;- penguins |&gt; \n  mutate(mass_range = case_when(\n    body_mass_g &lt;= 3500 ~ \"smol penguin\",\n    body_mass_g &gt;3500 & body_mass_g &lt; 4500 ~ \"mid penguin\",\n    body_mass_g &gt;= 4500 ~ \"chonk penguin\",\n    .default = NA)\n  )\n\nIf we make a barplot, the order of the values on the x axis will typically be in alphabetical order for any character data\n\npenguins |&gt; \n  drop_na(mass_range) |&gt; \n  ggplot(aes(x = mass_range))+\n  geom_bar()\n\n\n\n\n\n\n\nTo convert a character or numeric column to class factor, you can use any function from the forcats package. They will convert to class factor and then also perform or allow certain ordering of the levels - for example using forcats::fct_relevel() lets you manually specify the level order.\nThe function as_factor() simply converts the class without any further capabilities.\n\npenguins &lt;- penguins |&gt; \n  mutate(mass_range = as_factor(mass_range))\n\n\nlevels(penguins$mass_range)\n\n[1] \"mid penguin\"   \"smol penguin\"  \"chonk penguin\"\n\n\nBelow we use mutate() and as_factor() to convert the column flipper_range from class character to class factor.\n\n# Correct the code in your script with this version\npenguins &lt;- penguins |&gt; \n  mutate(mass_range = fct_relevel(mass_range, \n                                  \"smol penguin\", \n                                  \"mid penguin\", \n                                  \"chonk penguin\")\n         )\n\nlevels(penguins$mass_range)\n\n[1] \"smol penguin\"  \"mid penguin\"   \"chonk penguin\"\n\n\nNow when we call a plot, we can see that the x axis categories match the intrinsic order we have specified with our factor levels.\n\npenguins |&gt; \n  drop_na(mass_range) |&gt;  \n  ggplot(aes(x = mass_range))+\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nFactors will also be important when we build linear models a bit later. The reference or intercept for a categorical predictor variable when it is read as a &lt;chr&gt; is set by R as the first one when ordered alphabetically. This may not always be the most appropriate choice, and by changing this to an ordered &lt;fct&gt; we can manually set the intercept.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#summary",
    "href": "05-dplyr.html#summary",
    "title": "2  Data cleaning",
    "section": "\n2.6 Summary",
    "text": "2.6 Summary\nIn this chapter we have successfully imported and checked our data for typos and small errors, we have also been introduce to some of the key functions in the dplyr package for data wrangling. Now that we have confidence in the format and integrity of our data, next time we will start to make insights and understand patterns.\n\n2.6.1 Save scripts\n\nMake sure you have saved your script 💾 and given it the filename 01_import_penguins_data.R it should be saved in your scripts folder\n\n\n\n\nCheck your script\n\n\n#___________________________----\n# SET UP ----\n## An analysis of the bill dimensions of male and female Adelie, Gentoo and Chinstrap penguins ----\n\n### Data first published in  Gorman, KB, TD Williams, and WR Fraser. 2014. “Ecological Sexual Dimorphism and Environmental Variability Within a Community of Antarctic Penguins (Genus Pygoscelis).” PLos One 9 (3): e90081. https://doi.org/10.1371/journal.pone.0090081. ----\n#__________________________----\n\n# PACKAGES ----\nlibrary(tidyverse) # tidy data packages\nlibrary(janitor) # cleans variable names\n#__________________________----\n# IMPORT DATA ----\npenguins_raw &lt;- read_csv (\"data/penguins_raw.csv\")\n\nattributes(penguins_raw) # reads as tibble\n\nhead(penguins_raw) # check the data has loaded, prints first 10 rows of dataframe\n\n# CLEAN DATA ----\n\n# clean all variable names to snake_case \n# using the clean_names function from the janitor package\n# note we are using assign &lt;- \n# to overwrite the old version of penguins \n# with a version that has updated names\n# this changes the data in our R workspace \n# but NOT the original csv file\n\n# clean the column names\n# assign to new R object\npenguins_clean &lt;- janitor::clean_names(penguins_raw) \n\n# quickly check the new variable names\ncolnames(penguins_clean) \n\n# shorten the variable names for N and C isotope blood samples\n\npenguins &lt;- rename(penguins_clean,\n         \"delta_15n\"=\"delta_15_n_o_oo\",  # use rename from the dplyr package\n         \"delta_13c\"=\"delta_13_c_o_oo\")\n\n# use mutate and case_when for a statement that conditionally changes the names of the values in a variable\npenguins &lt;- penguins_clean |&gt; \n  mutate(species = case_when(species == \"Adelie Penguin (Pygoscelis adeliae)\" ~ \"Adelie\",\n                             species == \"Gentoo penguin (Pygoscelis papua)\" ~ \"Gentoo\",\n                             species == \"Chinstrap penguin (Pygoscelis antarctica)\" ~ \"Chinstrap\"))\n\n# use mutate and if_else\n# for a statement that conditionally changes \n# the names of the values in a variable\npenguins &lt;- penguins |&gt; \n  mutate(sex = if_else(\n    sex == \"MALE\", \"Male\", \"Female\"\n  )\n  )\n\n# use lubridate to format date and extract the year\npenguins &lt;- penguins |&gt;\n  mutate(date_egg = lubridate::dmy(date_egg))\n\npenguins &lt;- penguins |&gt; \n  mutate(year = lubridate::year(date_egg))\n\n# Set body mass ranges\npenguins &lt;- penguins |&gt; \n  mutate(mass_range = case_when(\n    body_mass_g &lt;= 3500 ~ \"smol penguin\",\n    body_mass_g &gt;3500 & body_mass_g &lt; 4500 ~ \"mid penguin\",\n    body_mass_g &gt;= 4500 ~ \"chonk penguin\",\n    .default = NA)\n  )\n\n# Assign these to an ordered factor\n\npenguins &lt;- penguins |&gt; \n  mutate(mass_range = fct_relevel(mass_range, \n                                  \"smol penguin\", \n                                  \"mid penguin\", \n                                  \"chonk penguin\")\n         )\n\n\n\nDoes your workspace look like the below?\n\n\n\n\n\nMy neat project layout\n\n\n\n\n\n\n\nMy scripts and file subdirectory\n\n\n\n\nDoes your script run from a blank slateR projects are set not to store their .Rhistory file which means everything required to recreate your analysis is contained in your scripts blank slate without errors as described in {#sec-workflow}\n\n2.6.2 Checklist for data checking\n\nIs our dataframe in a tidy dataTidy data refers to a specific format for organizing datasets that makes data easier to work with for analysis and visualization in R, especially using the tidyverse. The concept was popularized by Hadley Wickham in his paper “Tidy Data” and is an essential principle for effective data manipulation. format?\n\nIs each column assigned to the correct data type?\n\nAre dates formatted correctly?\nAre factors set where needed, are the levels in the correct order?\n\n\nAre variables consistently named (e.g. using a naming convention such as snake_case)?\nAre text values in an appropriate format?\nDo we have any data duplication?\nAre there any typos or mistakes in character strings?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#activity-test-yourself",
    "href": "05-dplyr.html#activity-test-yourself",
    "title": "2  Data cleaning",
    "section": "\n2.7 Activity: Test yourself",
    "text": "2.7 Activity: Test yourself\nQuestion 1. In order to subset a data by rows I should use the function \nselect()\nfilter()\ngroup_by()\nQuestion 2. In order to subset a data by columns I should use the function \nselect()\nfilter()\ngroup_by()\nQuestion 3. In order to make a new column I should use the function \ngroup_by()\nselect()\nmutate()\narrange()\nQuestion 4. Which operator should I use to send the output from line of code into the next line? \n+\n&lt;-)\n|&gt;\n%in%\nQuestion 5. What will be the outcome of the following line of code?\n\npenguins |&gt; \n  filter(species == \"Adelie\")\n\n\nThe penguins dataframe object is reduced to include only Adelie penguins from now on\nA new filtered dataframe of only Adelie penguins will be printed into the console\n\n\nExplain this answer\n\nUnless the output of a series of functions is “assigned” to an object using &lt;- it will not be saved, the results will be immediately printed. This code would have to be modified to the below in order to create a new filtered object penguins_filtered\n\npenguins_filtered &lt;- penguins |&gt; \n  filter(species == \"Adelie\")\n\n\n\nQuestion 6. What is the main point of a data “pipe”?\n\nThe code runs faster\nThe code is easier to read\nQuestion 7. The naming convention outputted by the function `janitor::clean_names() is \nsnake_case\ncamelCase\nSCREAMING_SNAKE_CASE\nkebab-case\nQuestion 8. Which package provides useful functions for manipulating character strings?\n\nstringr\nggplot2\nlubridate\nforcats\nQuestion 9. Which package provides useful functions for manipulating dates?\n\nstringr\nggplot2\nlubridate\nforcats\nQuestion 10. If we do not specify a character variable as a factor, then ordering will default to what?\n\nnumerical\nalphabetical\norder in the dataframe",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#glossary",
    "href": "05-dplyr.html#glossary",
    "title": "2  Data cleaning",
    "section": "\n2.8 Glossary",
    "text": "2.8 Glossary\n\n\n\n\nterm\ndefinition\n\n\n\nblank slate\nR projects are set not to store their .Rhistory file which means everything required to recreate your analysis is contained in your scripts\n\n\nconsole\nThe R console is the interactive interface within the R environment where users can type and execute R code. It is the place where you can directly enter commands, see their output, and interact with the R programming language in real-time.\n\n\npipe\nAn operator that allows you to chain multiple functions together in a sequence\n\n\nsnake case\nSnake case is a naming convention in computing that uses underscores to replace spaces between words, and writes words in lowercase. It's commonly used for variable and subroutine names, filenames, and database table and column names\n\n\ntidy data\nTidy data refers to a specific format for organizing datasets that makes data easier to work with for analysis and visualization in R, especially using the tidyverse. The concept was popularized by Hadley Wickham in his paper \"Tidy Data\" and is an essential principle for effective data manipulation.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#reading",
    "href": "05-dplyr.html#reading",
    "title": "2  Data cleaning",
    "section": "\n2.9 Reading",
    "text": "2.9 Reading\n\nDplyr\nLubridate\nStringr",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "06-data-bias.html",
    "href": "06-data-bias.html",
    "title": "3  Data bias",
    "section": "",
    "text": "3.1 Sampling Bias",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data bias</span>"
    ]
  },
  {
    "objectID": "06-data-bias.html#sampling-bias",
    "href": "06-data-bias.html#sampling-bias",
    "title": "3  Data bias",
    "section": "",
    "text": "3.1.1 Explanation:\nSampling bias occurs when the data collected does not properly represent the population you are studying. This often happens if certain groups are over- or underrepresented. For example, if you survey only college students to understand a city’s general population, your data will be biased because it doesn’t capture other demographics like older adults or people who do not attend college.\n\n3.1.2 Why it matters:\nSampling bias leads to incorrect generalisations about the entire population, as conclusions are based on a skewed subset of data.\n\n\n\n\n\n\n\n\n\n\n\n\n\nGroup\nmean\nsd\n\n\n\nLocation 1\n50.16128\n9.916950\n\n\nLocation 2\n60.42465\n10.096742\n\n\nLocation 3\n69.79887\n9.783575\n\n\n\n\n\n\n\nprob_obs_location &lt;- biased_sample_data %&gt;% \n  group_by(Group) %&gt;% \n  summarise(n = n()) %&gt;% \n  mutate(prob_obs = n/sum(n))\n\n\nbiased_sample_data %&gt;% \n  # set as factor and provide levels\n  ggplot()+\n  geom_bar(aes(x=Group),\n           fill=\"steelblue\",\n           width=0.8)+\n  labs(x=\"\",\n       y = \"Number of observations\")+\n  geom_text(data=prob_obs_location,\n            aes(y=(n+50),\n                x=Group,\n                label=scales::percent(prob_obs)))+\n  coord_flip()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data bias</span>"
    ]
  },
  {
    "objectID": "06-data-bias.html#missing-not-at-random-mnar-bias",
    "href": "06-data-bias.html#missing-not-at-random-mnar-bias",
    "title": "3  Data bias",
    "section": "\n3.2 Missing Not at Random (MNAR) Bias",
    "text": "3.2 Missing Not at Random (MNAR) Bias\n\n3.2.1 Explanation:\nMNAR bias arises when data is systematically missing due to the value of the missing data itself. For instance, if people with extremely high incomes are less likely to report their income in a survey, this creates MNAR bias. The missing data is not random—it’s directly related to the variable being measured.\n\n3.2.2 Why it matters:\nMNAR bias distorts conclusions because certain trends are hidden in the missing data. Ignoring this can lead to underestimating the variability or misunderstanding the true patterns in the data.\n\n\n\n\n\n\n\n\n\nweather_data |&gt;\n  filter(Record == \"Temperature_Missing\") |&gt;\nggplot(aes(x = Day,\n           y = Temperature_Celsius)) +\n  geom_line(aes(colour = Colour,\n                alpha = Colour,\n                group = 1))+\n  ggtitle(\"Temperature Data with and without Missing Data\") +\n  ylab(\"Temperature (°C)\") +\n  geom_smooth(method = \"loess\",\n              se = FALSE,\n              colour = \"darkred\")+\n  geom_smooth(data = weather_data |&gt; filter(Record == \"Temperature\"),\n              method = \"loess\",\n              se = FALSE,\n              colour = \"blue\")+\n  scale_colour_identity()+\n  scale_alpha_manual(values = c(.4, .8))+\n  theme(legend.position = \"none\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data bias</span>"
    ]
  },
  {
    "objectID": "06-data-bias.html#survivorship-bias",
    "href": "06-data-bias.html#survivorship-bias",
    "title": "3  Data bias",
    "section": "\n3.3 Survivorship Bias",
    "text": "3.3 Survivorship Bias\n\n3.3.1 Explanation:\nSurvivorship bias occurs when you focus on the data points that survive a process and ignore those that did not. A famous example is from World War II, where analysts looked at the bullet holes on planes that returned from battle and suggested reinforcing areas where they saw damage. They overlooked the planes that didn’t return, which were hit in critical areas not visible on surviving planes.\n\n3.3.2 Why it matters:\nFocusing only on surviving or successful subjects can lead to false conclusions, as the failure cases (which provide crucial insights) are excluded from the analysis.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data bias</span>"
    ]
  },
  {
    "objectID": "06-data-bias.html#outlier-bias",
    "href": "06-data-bias.html#outlier-bias",
    "title": "3  Data bias",
    "section": "\n3.4 Outlier Bias",
    "text": "3.4 Outlier Bias\n\n3.4.1 Explanation:\nOutlier bias happens when extreme values (outliers) unduly influence the results of an analysis. Outliers can occur due to data entry errors, measurement errors, or true but rare events. For example, if you’re analyzing average income and a few extremely high incomes are present in the data, they can raise the average, making it seem like the typical person earns more than they actually do.\n\n3.4.2 Why it matters:\nOutliers can distort the results, especially when using statistical methods like the mean or regression. This can lead to misleading conclusions unless the outliers are properly handled.\n\n\n\n\n\n\n\n\n\n3.4.3 What to do about it",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data bias</span>"
    ]
  },
  {
    "objectID": "06-data-bias.html#omitted-variable-bias",
    "href": "06-data-bias.html#omitted-variable-bias",
    "title": "3  Data bias",
    "section": "\n3.5 Omitted variable bias",
    "text": "3.5 Omitted variable bias\n\n3.5.1 Explanation:\nOmitted variable bias occurs when a relevant variable is left out of an analysis, leading to incorrect conclusions. For example, a drug may appear ineffective if you don’t account for gender differences, but including gender in the analysis may reveal that the drug works well for women but not for men.\n\n3.5.2 Why it matters:\nIgnoring important variables can mask the true relationships between variables, leading to faulty interpretations and conclusions.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data bias</span>"
    ]
  },
  {
    "objectID": "07-data-insights.html",
    "href": "07-data-insights.html",
    "title": "4  Data insights",
    "section": "",
    "text": "4.0.1 Data checking\nImportantly you should have already generated an understanding of the variables contained within your dataset during the data wrangling steps. Including:",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data insights</span>"
    ]
  },
  {
    "objectID": "07-data-insights.html#explore-the-distribution-of-categories",
    "href": "07-data-insights.html#explore-the-distribution-of-categories",
    "title": "4  Data insights",
    "section": "\n4.1 Explore the distribution of categories",
    "text": "4.1 Explore the distribution of categories\nUnderstanding how your data is distributed across important grouping variables is essential for context. In this case, the Palmer Penguins dataset includes key groupings such as species, island, and year, which might have significant effects on the relationships we want to study (e.g., between bill length and bill depth). By summarizing and visualizing the distribution of these variables, we can ensure that our analyses account for group-level differences, leading to more robust insights.\n\n4.1.1 Frequency\nBy grouping the data according to the species variable, it calculates the total count (n) of penguins within each species. This summary helps us understand the distribution of penguin species in the dataset, giving insights into the sample size available for each group, which is important for any further analysis or comparison between species.\n\npenguins |&gt; \n  # calculations applied per species\n  group_by(species) |&gt; \n  # summarise the number of observations in each group\n  summarise(n = n())\n\n\n\n\nspecies\nn\n\n\n\nAdelie\n152\n\n\nChinstrap\n68\n\n\nGentoo\n124\n\n\n\n\n\n\nQuestion Are there 152 different penguins in our dataset? \nTRUE\nFALSE\n\n\nExplanation\n\nThe functions above count the number of rows of data - we need to determine if these are repeated or independent measures. We should remember that there is a column called individual_id if we use the n_distinct() function we can count how many unique IDs we have\n\npenguins |&gt; \n  # calculations applied per species\n  group_by(species) |&gt; \n  # summarise the number of observations in each group\n  summarise(n = n_distinct(individual_id))\n\n\n\n\nspecies\nn\n\n\n\nAdelie\n132\n\n\nChinstrap\n58\n\n\nGentoo\n94\n\n\n\n\n\n\nNow we can see that there are only 132 different Adelie penguins in our data\n\n\n4.1.2 Relative Frequency\nIt might be useful for us to make some quick data summaries here, like relative frequency\n\nprob_obs_species &lt;- penguins |&gt; \n  group_by(species) |&gt; \n  summarise(n = n()) |&gt; \n  # use mutate to make a new column relative frequency\n  mutate(prob_obs = n/sum(n))\n\nprob_obs_species\n\n\n\n\nspecies\nn\nprob_obs\n\n\n\nAdelie\n152\n0.4418605\n\n\nChinstrap\n68\n0.1976744\n\n\nGentoo\n124\n0.3604651\n\n\n\n\n\n\nSo about 44% of our sample is made up of observations from Adelie penguins. When it comes to making summaries about categorical data, that’s about the best we can do, we can make observations about the most common categorical observations, and the relative proportions.\n\npenguins |&gt; \n  mutate(species=fct_relevel(species, \n                             \"Adelie\",\n                             \"Gentoo\",\n                             \"Chinstrap\")) |&gt; \n  # set as factor and provide levels\n  ggplot()+\n  geom_bar(aes(x=species),\n           fill=\"steelblue\",\n           width=0.8)+\n  labs(x=\"Species\",\n       y = \"Number of observations\")+\n  geom_text(data=prob_obs_species,\n            aes(y=(n+10),\n                x=species,\n                label=scales::percent(prob_obs)))+\n  coord_flip()\n\n\n\n\n\n\n\nThis is an example of a figure we might use in a report or paper. Having cleaned up the theme, added some simple colour, made sure our labels are clear and descriptive, ordered our categories in ascending frequency order, and included some simple text of percentages to aid readability.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data insights</span>"
    ]
  },
  {
    "objectID": "07-data-insights.html#two-or-more-categories",
    "href": "07-data-insights.html#two-or-more-categories",
    "title": "4  Data insights",
    "section": "\n4.2 Two or more categories",
    "text": "4.2 Two or more categories\nThink about what might be a suitable confounding variable to investigate and graph here?\n\n\nSolution\n\nUnderstanding how frequency is broken down by island, species year and sex might be useful.\n\npenguins |&gt; \n  group_by(island, year, species, sex) |&gt; \n  summarise(n = n()) \n\n\n\n\nisland\nyear\nspecies\nsex\nn\n\n\n\nBiscoe\n2007\nAdelie\nFemale\n5\n\n\nBiscoe\n2007\nAdelie\nMale\n5\n\n\nBiscoe\n2007\nGentoo\nFemale\n16\n\n\nBiscoe\n2007\nGentoo\nMale\n17\n\n\nBiscoe\n2007\nGentoo\nNA\n1\n\n\nBiscoe\n2008\nAdelie\nFemale\n9\n\n\nBiscoe\n2008\nAdelie\nMale\n9\n\n\nBiscoe\n2008\nGentoo\nFemale\n22\n\n\nBiscoe\n2008\nGentoo\nMale\n23\n\n\nBiscoe\n2008\nGentoo\nNA\n1\n\n\nBiscoe\n2009\nAdelie\nFemale\n8\n\n\nBiscoe\n2009\nAdelie\nMale\n8\n\n\nBiscoe\n2009\nGentoo\nFemale\n20\n\n\nBiscoe\n2009\nGentoo\nMale\n21\n\n\nBiscoe\n2009\nGentoo\nNA\n3\n\n\nDream\n2007\nAdelie\nFemale\n9\n\n\nDream\n2007\nAdelie\nMale\n10\n\n\nDream\n2007\nAdelie\nNA\n1\n\n\nDream\n2007\nChinstrap\nFemale\n13\n\n\nDream\n2007\nChinstrap\nMale\n13\n\n\nDream\n2008\nAdelie\nFemale\n8\n\n\nDream\n2008\nAdelie\nMale\n8\n\n\nDream\n2008\nChinstrap\nFemale\n9\n\n\nDream\n2008\nChinstrap\nMale\n9\n\n\nDream\n2009\nAdelie\nFemale\n10\n\n\nDream\n2009\nAdelie\nMale\n10\n\n\nDream\n2009\nChinstrap\nFemale\n12\n\n\nDream\n2009\nChinstrap\nMale\n12\n\n\nTorgersen\n2007\nAdelie\nFemale\n8\n\n\nTorgersen\n2007\nAdelie\nMale\n7\n\n\nTorgersen\n2007\nAdelie\nNA\n5\n\n\nTorgersen\n2008\nAdelie\nFemale\n8\n\n\nTorgersen\n2008\nAdelie\nMale\n8\n\n\nTorgersen\n2009\nAdelie\nFemale\n8\n\n\nTorgersen\n2009\nAdelie\nMale\n8\n\n\n\n\n\n\n\npenguins |&gt; \n   ggplot(aes(x = species,\n             fill = sex))+\n   geom_bar(width=0.8,\n            position = position_dodge())+\n  labs(x=\"Species\",\n       y = \"Number of observations\")+\n  facet_grid(island ~ year)\n\n\n\n\n\n\n\n\nBy thinking about the way in which categories might interact we can consider interesting patterns or potential issues in data collection.\n\nLooking at these patterns I am reassured that the number of males and females spotted is roughly equal across species and locations.\nThere are different numbers of species on different islands, but this is consistent across years so hopefully represents true species distributions.\nThe number of penguins is consistent across years\nThere are some missing values for sex, but they are small and don’t fit a strong pattern.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data insights</span>"
    ]
  },
  {
    "objectID": "07-data-insights.html#missing-data",
    "href": "07-data-insights.html#missing-data",
    "title": "4  Data insights",
    "section": "\n4.3 Missing data",
    "text": "4.3 Missing data\nIn the previous section above we were able to characterise some missing data, but only a little and it appears to be fairly random. This means we can probably safely remove it from calculations or statistics without issue.\nBut what about our variables of interest? Culmen length and depth? We previously used skimr::skim and summary to identify there were two missing values each for culmen length and depth. Although this is unlikely to cause any issues of bias in our data it might be nice to know where these missing values are located in our data?\n\npenguins |&gt;\n  # Filter rows where culmen length is NA\n  filter(is.na(culmen_length_mm)) |&gt; \n  # Group by species, sex and island\n  group_by(species, sex, year, island) |&gt;                 \n  summarise(n_missing = n())    \n\npenguins |&gt;\n  filter(is.na(culmen_depth_mm)) |&gt;         \n  group_by(species, sex, year, island) |&gt;               \n  summarise(n_missing = n())    \n\n\n\n\nspecies\nsex\nyear\nisland\nn_missing\n\n\n\nAdelie\nNA\n2007\nTorgersen\n1\n\n\nGentoo\nNA\n2009\nBiscoe\n1\n\n\n\n\n\n\n\nspecies\nsex\nyear\nisland\nn_missing\n\n\n\nAdelie\nNA\n2007\nTorgersen\n1\n\n\nGentoo\nNA\n2009\nBiscoe\n1\n\n\n\n\n\n\nThere is data missing from one Adelie penguin in 2007 on Torgersen, and one value missing from a Gentoo penguin in 2009 on Biscoe. This is true for both culmen length and depth, it is probably the same penguin in both cases, but how could we change our code to be sure?\n\n\nSolution\n\n\npenguins |&gt;\n  filter(is.na(culmen_length_mm)) |&gt; \n# ADD individual id into group_by arguments\n  group_by(species, sex, year, island, individual_id) |&gt;                 \n  summarise(n_missing = n())    \n\npenguins |&gt;\n  filter(is.na(culmen_depth_mm)) |&gt;         \n  group_by(species, sex, year, island, individual_id) |&gt;               \n  summarise(n_missing = n())    \n\n\n\n\nspecies\nsex\nyear\nisland\nindividual_id\nn_missing\n\n\n\nAdelie\nNA\n2007\nTorgersen\nN2A2\n1\n\n\nGentoo\nNA\n2009\nBiscoe\nN38A2\n1\n\n\n\n\n\n\n\nspecies\nsex\nyear\nisland\nindividual_id\nn_missing\n\n\n\nAdelie\nNA\n2007\nTorgersen\nN2A2\n1\n\n\nGentoo\nNA\n2009\nBiscoe\nN38A2\n1\n\n\n\n\n\n\n\nAgain here we could safely drop these from our data and regard these as missing at random.\n\n4.3.1 remove na\nThere are a few different ways we can deal with missing data:\n\n\ndrop_na() on everything before we start.\n\nThis runs the risk that we lose a lot of data as every row, with an NA in any column will be removed\n\n\ndrop_na() on a particular variable.\n\nThis is fine, but we should approach this cautiously - if we do this in a way where we write this data into a new object e.g. penguins &lt;- penguins |&gt;  drop_na(body_mass_g) then we have removed this data forever - perhaps we only want to drop those rows for a specific calculation - again they might contain useful information in other variables.\n\nUse arguments inside functions\n\nmean(x, na.rm = T) Many summary functions have the argument to include or exclude missingness, by default mean() is set to na.rm = F and will produce an NA value if there is any missingness, once we have investigated this we could simply set na.rm = T and remove NA from the calculations",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data insights</span>"
    ]
  },
  {
    "objectID": "07-data-insights.html#continuous-distributions",
    "href": "07-data-insights.html#continuous-distributions",
    "title": "4  Data insights",
    "section": "\n4.4 Continuous distributions",
    "text": "4.4 Continuous distributions\nVariation is the tendency of the values of a variable to change from measurement to measurement. You can see variation easily in real life; if you measure any continuous variable twice, you will get two different results. This is true even if you measure quantities that are constant, like the speed of light. Each of your measurements will include a small amount of error that varies from measurement to measurement. Every variable has its own pattern of variation, which can reveal interesting information. The best way to understand that pattern is to visualise the distribution of the variable’s values.\n\n\n\n\n\n\nImportant\n\n\n\nIn the examples below I will look at the distributions of culmen length, you should modify and duplicate the code so that you check both culmen length and culmen depth.\n\n\n\n4.4.1 Histograms\nThis is the script to plot a frequency distribution, we only specify an x variable, because we intend to plot a histogram, and the y variable is always the count of observations. Here we ask the data to be presented in 10 equally sized bins of data. In this case chopping the x axis range into 10 equal parts and counting the number of observations that fall within each one.\nHistograms are helpful because they show the distribution of a single numerical variable. They divide the data into “bins” (ranges of values) and count how many data points fall into each bin. This helps you:\nSee the shape of the data: You can easily spot if the data is normally distributed, skewed, or has multiple peaks (modes). Identify data spread: Histograms help you understand the spread or range of your data values. Detect outliers: Unusually high or low values become more noticeable in a histogram.\n\npenguins |&gt; \n  ggplot()+\n  geom_histogram(aes(x=culmen_length_mm),\n                 bins=10)\n\n\n\n\n\n\n\n\n\n\n\n\n\nChange the bin argument\n\n\n\nChange the value specified to the bins argument and observe how the figure changes. It is usually a very good idea to try more than one set of bins in order to have better insights into the data\n\n\n\n4.4.2 Boxplots\n\npenguins |&gt; \n  ggplot()+\n  geom_boxplot(aes(x=culmen_length_mm))\n\n\n\n\n\n\n\nBoxplots are useful because they provide a summary of the distribution of a numerical variable in a compact visual form. They help you see:\n\nCentral tendency: The middle line in the box shows the median (middle value) of the data.\nSpread and variability: The length of the box (interquartile range) shows how spread out the data is.\nOutliers: Boxplots clearly show outliers as points outside the “whiskers,” making them great for detecting extreme values.\nComparison between groups: You can easily compare the distribution of a variable across different groups (e.g., species) by using multiple boxplots side by side.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data insights</span>"
    ]
  },
  {
    "objectID": "07-data-insights.html#continuous-and-categorical",
    "href": "07-data-insights.html#continuous-and-categorical",
    "title": "4  Data insights",
    "section": "\n4.5 Continuous and categorical",
    "text": "4.5 Continuous and categorical\nIt’s common to want to explore the distribution of a continuous variable broken down by a categorical variable.\nThe best and simplest place to start exploring these possible relationships is by producing simple figures.\nLet’s start by looking at the distribution of culmen length by species\n\npenguins %&gt;% \n    ggplot(aes(x = species,\n               y = body_mass_g,\n               fill = species))+\n    geom_boxplot(width = 0.2)+\n  coord_flip()\n\n\n\n\n\n\n\n\npenguins %&gt;% \n  ggplot(aes(fill = species))+\n  geom_density(aes(x = culmen_length_mm),\n                   position = \"identity\",\n                   alpha = 0.6)\n\n\n\n\n\n\n\n\n4.5.1 GGridges\nThe package ggridges (Wilke (2021)) provides some excellent extra geoms to supplement ggplot. One if its most useful features is to to allow different groups to be mapped to the y axis, so that histograms are more easily viewed.\n\nlibrary(ggridges)\nggplot(penguins, aes(x = culmen_length_mm, \n                     y = species)) + \n  ggridges::geom_density_ridges()\n\n\n\n\n\n\n\n\npenguins |&gt; \n  drop_na() |&gt; \nggplot(aes(x = culmen_length_mm, \n                     y = species, fill = sex)) + \n    ggridges::geom_density_ridges()",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data insights</span>"
    ]
  },
  {
    "objectID": "07-data-insights.html#normality",
    "href": "07-data-insights.html#normality",
    "title": "4  Data insights",
    "section": "\n4.6 Normality",
    "text": "4.6 Normality\nIf our data follows a normal distribution, then we can predict the spread of our data, and the likelihood of observing a datapoint of any given value with only the mean and standard deviation.\n\n4.6.1 QQplot\nA QQ plot is a classic way of checking whether a sample distribution is the same as another (or theoretical distribution). They look a bit odd at first, but they are actually fairly easy to understand, and very useful! The qqplot distributes your data on the y-axis, and a theoretical normal distribution on the x-axis. If the residuals follow a normal distribution, they should meet to produce a perfect diagonal line across the plot.\nWatch this video to see QQ plots explained\n\nlibrary(qqplotr)\nggplot(penguins, aes(sample = culmen_length_mm))+\n    stat_qq_band() +\n    stat_qq_line() +\n    stat_qq_point() \n\n\n\n\n\n\n\n\nlibrary(rstatix)\n\npenguins %&gt;% \n  shapiro_test(culmen_length_mm)\n\n\n\n\nvariable\nstatistic\np\n\n\nculmen_length_mm\n0.9748548\n1.12e-05\n\n\n\n\n\n\nlibrary(qqplotr)\nggplot(penguins, aes(sample = culmen_length_mm))+\n    stat_qq_band() +\n    stat_qq_line() +\n    stat_qq_point() +\n  facet_wrap(~species)\n\n\n\n\n\n\n\n\npenguins %&gt;% \n  group_by(species) |&gt; \n  shapiro_test(culmen_length_mm)\n\n\n\n\nspecies\nvariable\nstatistic\np\n\n\n\nAdelie\nculmen_length_mm\n0.9933618\n0.7166005\n\n\nChinstrap\nculmen_length_mm\n0.9752496\n0.1940926\n\n\nGentoo\nculmen_length_mm\n0.9727224\n0.0134914",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data insights</span>"
    ]
  },
  {
    "objectID": "07-data-insights.html#summary-statistics",
    "href": "07-data-insights.html#summary-statistics",
    "title": "4  Data insights",
    "section": "\n4.7 Summary statistics",
    "text": "4.7 Summary statistics\n\n4.7.1 Mean and standard deviation\nstandard deviation (or s) is a measure of how dispersed the data is in relation to the mean. Low standard deviation means data are clustered around the mean, and high standard deviation indicates data are more spread out. As such it makes sense only to use this when the mean is a good measure of our central tendency.\n\npenguins |&gt; \n  group_by(species) |&gt; \n  summarise(mean = mean(culmen_length_mm),\n            sd = sd(culmen_length_mm))\n\n\n\n\nspecies\nmean\nsd\n\n\n\nAdelie\nNA\nNA\n\n\nChinstrap\n48.83382\n3.339256\n\n\nGentoo\nNA\nNA\n\n\n\n\n\n\n\n\nSolution\n\n\npenguins |&gt; \n  group_by(species) |&gt; \n  summarise(mean = mean(culmen_length_mm, na.rm = T),\n            sd = sd(culmen_length_mm, na.rm =T))\n\n\n\n\nspecies\nmean\nsd\n\n\n\nAdelie\n38.79139\n2.663405\n\n\nChinstrap\n48.83382\n3.339256\n\n\nGentoo\n47.50488\n3.081857\n\n\n\n\n\n\n\n\n4.7.2 Median and quartiles\nWhen dealing with data that does not fit a normal distribution, using summary statistics like max, min, median, and interquartile range (IQR) provides a robust way to describe the data’s spread and central tendency. Unlike the mean and standard deviation, which are sensitive to outliers and skewed data, the median and IQR give a more accurate representation of the distribution’s center and spread in non-normal data.\n\nMedian: This is the middle value and provides a better measure of central tendency than the mean when data is skewed. IQR (Interquartile Range): This measures the spread of the middle 50% of the data (between the 25th and 75th percentiles) and is less affected by extreme values.\nMin and Max: These values show the range of the data, highlighting any extreme values or outliers.\n\nThese summary statistics directly correspond to the boxplot: the median is the line inside the box, the IQR defines the box’s edges, and the min/max (after removing outliers) are represented by the ends of the whiskers.\n\npenguins |&gt; \n  group_by(species) |&gt; \n  summarise(median = median(culmen_length_mm, na.rm = T),\n            quantile = quantile(culmen_length_mm, c(0.25, 0.5, 0.75), na.rm=TRUE),\n            max = max(culmen_length_mm, na.rm = T),\n            min = min(culmen_length_mm), na.rm = T)\n\n\n\n\nspecies\nmedian\nquantile\nmax\nmin\nna.rm\n\n\n\nAdelie\n38.80\n36.750\n46.0\nNA\nTRUE\n\n\nAdelie\n38.80\n38.800\n46.0\nNA\nTRUE\n\n\nAdelie\n38.80\n40.750\n46.0\nNA\nTRUE\n\n\nChinstrap\n49.55\n46.350\n58.0\n40.9\nTRUE\n\n\nChinstrap\n49.55\n49.550\n58.0\n40.9\nTRUE\n\n\nChinstrap\n49.55\n51.075\n58.0\n40.9\nTRUE\n\n\nGentoo\n47.30\n45.300\n59.6\nNA\nTRUE\n\n\nGentoo\n47.30\n47.300\n59.6\nNA\nTRUE\n\n\nGentoo\n47.30\n49.550\n59.6\nNA\nTRUE",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data insights</span>"
    ]
  },
  {
    "objectID": "07-data-insights.html#collinearity",
    "href": "07-data-insights.html#collinearity",
    "title": "4  Data insights",
    "section": "\n4.8 Collinearity",
    "text": "4.8 Collinearity\n\nlibrary(GGally)\n\npenguins |&gt; \n  select(species, \n         island, \n         culmen_length_mm, \n         culmen_depth_mm, \n         flipper_length_mm, \n         body_mass_g, \n         sex) |&gt; \n  ggpairs()\n\n\n\n\n\n\n\n\npenguins |&gt; \n  ggpairs(columns = c(\n         \"island\", \n         \"culmen_length_mm\", \n         \"culmen_depth_mm\", \n         \"flipper_length_mm\", \n         \"body_mass_g\", \n         \"sex\"), \n         ggplot2::aes(colour = species))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data insights</span>"
    ]
  },
  {
    "objectID": "07-data-insights.html#correlation",
    "href": "07-data-insights.html#correlation",
    "title": "4  Data insights",
    "section": "\n4.9 Correlation",
    "text": "4.9 Correlation\nA common measure of association between two numerical variables is the correlation coefficient. The correlation metric is a numerical measure of the strength of an association\nThere are several measures of correlation including:\nPearson’s correlation coefficient : good for describing linear associations\nSpearman’s rank correlation coefficient: a rank ordered correlation - good for when the assumptions for Pearson’s correlation is not met.\nPearson’s correlation coefficient r is designed to measure the strength of a linear (straight line) association. Pearson’s takes a value between -1 and 1.\nA value of 0 means there is no linear association between the variables\nA value of 1 means there is a perfect positive association between the variables\nA value of -1 means there is a perfect negative association between the variables\nA perfect association is one where we can predict the value of one variable with complete accuracy, just by knowing the value of the other variable.\nWe can use the cor function in R to calculate Pearson’s correlation coefficient.\n\nlibrary(rstatix)\n\npenguins %&gt;% \n  cor_test(culmen_length_mm, \n           culmen_depth_mm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar1\nvar2\ncor\nstatistic\np\nconf.low\nconf.high\nmethod\n\n\nculmen_length_mm\nculmen_depth_mm\n-0.24\n-4.459093\n1.12e-05\n-0.3328072\n-0.1323004\nPearson\n\n\n\n\n\nThis tells us two features of the association. It’s sign and magnitude. The coefficient is negative, so as bill length increases, bill depth decreases. The value -0.22 indicates that only about 22% of the variation in bill length can be explained by changes in bill depth (and vice-versa), suggesting that the variables are not closely related.\nBecause Pearson’s coefficient is designed to summarise the strength of a linear relationship, this can be misleading if the relationship is not linear e.g. curved or humped. This is why it’s always a good idea to plot the relationship first (see above).\nEven when the relationship is linear, it doesn’t tell us anything about the steepness of the association (see above). It only tells us how often a change in one variable can predict the change in the other not the value of that change.\nThis can be difficult to understand at first, so carefully consider the figure above.\nThe first row above shows differing levels of the strength of association. If we drew a perfect straight line between two variables, how closely do the data points fit around this line.\nThe second row shows a series of perfect linear relationships. We can accurately predict the value of one variable just by knowing the value of the other variable, but the steepness of the relationship in each example is very different. This is important because it means a perfect association can still have a small effect.\nThe third row shows a series of associations where there is clearly a relationship between the two variables, but it is also not linear so would be inappropriate for a Pearson’s correlation.\nSo what should we do if the relationship between our variables is non-linear or does not follow a normal distribution? Instead of using Pearson’s correlation coefficient we can calculate something called a rank correlation.\nInstead of working with the raw values of our two variables we can use rank ordering instead. The idea is pretty simple if we start with the lowest vaule in a variable and order it as ‘1’, then assign labels ‘2’, ‘3’ etc. as we ascend in rank order. We can see a way that this could be applied manually with the function dense_rank from dplyr below:\n\nlibrary(rstatix)\n\npenguins %&gt;% \n  cor_test(culmen_length_mm, \n           culmen_depth_mm,\n           method = \"spearman\")\n\n\n\n\n\n\n\n\n\n\n\n\nvar1\nvar2\ncor\nstatistic\np\nmethod\n\n\nculmen_length_mm\nculmen_depth_mm\n-0.22\n8145268\n3.51e-05\nSpearman\n\n\n\n\n\nGraphical summaries between numeric variables\nCorrelation coefficients are a quick and simple way to attach a metric to the level of association between two variables. They are limited however in that a single number can never capture the every aspect of their relationship. This is why we visualise our data.\n\nscatterplot &lt;- ggplot(penguins, aes(x= culmen_length_mm, \n                                    y= culmen_depth_mm)) +\n  geom_point()\n\nscatterplot\n\n\n\n\n\n\n\n\nlibrary(patchwork) # package calls should be placed at the TOP of your script\n\nbill_depth_marginal &lt;- penguins %&gt;% \n  ggplot()+\n  geom_density(aes(x=culmen_depth_mm), fill=\"darkgrey\")+\n  theme_void()+\n  coord_flip() # this graph needs to be rotated\n\nbill_length_marginal &lt;- penguins %&gt;% \n  ggplot()+\n  geom_density(aes(x=culmen_length_mm), fill=\"darkgrey\")+\n  theme_void()\n\nlayout &lt;- \"\nAA#\nBBC\nBBC\"\n# layout is easiest to organise using a text distribution, where ABC equal the three plots in order, and the grid is how much space they take up. We could easily make the main plot bigger and marginals smaller with\n\nscatterplot &lt;- scatterplot +\n  geom_smooth(method = \"lm\",\n              se = FALSE)\n\nbill_length_marginal+scatterplot+bill_depth_marginal+ # order of plots is important\n  plot_layout(design=layout) # uses the layout argument defined above to arrange the size and position of plots",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data insights</span>"
    ]
  },
  {
    "objectID": "07-data-insights.html#important-variables",
    "href": "07-data-insights.html#important-variables",
    "title": "4  Data insights",
    "section": "\n4.10 Important variables",
    "text": "4.10 Important variables\n\ncolours &lt;- c(\"cyan\",\n             \"darkorange\",\n             \"purple\")\n\nscatterplot_2 &lt;- ggplot(penguins, aes(x= culmen_length_mm, \n                     y= culmen_depth_mm,\n                     colour=species)) +\n    geom_point()+\n  geom_smooth(method=\"lm\",\n              se=FALSE)+\n  scale_colour_manual(values=colours)+\n  theme_classic()+\n  theme(legend.position=\"none\")+\n    labs(x=\"Bill length (mm)\",\n         y=\"Bill depth (mm)\")\n\nbill_depth_marginal_2 &lt;- penguins %&gt;% \n  ggplot()+\n  geom_density(aes(x=culmen_depth_mm,\n                   fill=species),\n               alpha=0.5)+\n  scale_fill_manual(values=colours)+\n  theme_void()+\n  coord_flip() # this graph needs to be rotated\n\nbill_length_marginal_2 &lt;- penguins %&gt;% \n  ggplot()+\n  geom_density(aes(x=culmen_length_mm,\n                   fill=species),\n               alpha=0.5)+\n  scale_fill_manual(values=colours)+\n  theme_void()+\n  theme(legend.position=\"none\")\n\nlayout2 &lt;- \"\nAAA#\nBBBC\nBBBC\nBBBC\"\n\nbill_length_marginal_2+scatterplot_2+bill_depth_marginal_2+ # order of plots is important\n  plot_layout(design=layout2) # uses the layout argument defined above to arrange the size and position of plots\n\n\n\n\n\n\n\nWe now clearly see a striking reversal of our previous trend, that in fact within each species of penguin there is an overall positive association between bill length and depth.\nThis should prompt us to re-evaluate our correlation metrics:\n\npenguins %&gt;% \n  group_by(species) %&gt;% \n  cor_test(culmen_length_mm, \n           culmen_depth_mm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nspecies\nvar1\nvar2\ncor\nstatistic\np\nconf.low\nconf.high\nmethod\n\n\n\nAdelie\nculmen_length_mm\nculmen_depth_mm\n0.39\n5.193285\n7e-07\n0.2472226\n0.5187796\nPearson\n\n\nChinstrap\nculmen_length_mm\nculmen_depth_mm\n0.65\n7.014647\n0e+00\n0.4917326\n0.7717134\nPearson\n\n\nGentoo\nculmen_length_mm\nculmen_depth_mm\n0.64\n9.244703\n0e+00\n0.5262952\n0.7365271\nPearson",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data insights</span>"
    ]
  },
  {
    "objectID": "r-basics.html",
    "href": "r-basics.html",
    "title": "Appendix A — R Basics",
    "section": "",
    "text": "A.1 Using Posit cloud\nAll of our sessions will run on cloud-based software. All you have to do is make a free account, and join our Workspace.\nOnce you are signed up - you will see that there are two spaces:\nMake sure you are working in the classroom workspace - so that I can distribute project work and ‘visit’ your projects if needed.\nPosit cloud works in exactly the same way as RStudio, but means you don’t have to download any software. You can access the hosted cloud server and your projects through any browser connection (Chrome works best), from any computer.\nHere is a good reference guide to Posit cloud",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#using-posit-cloud",
    "href": "r-basics.html#using-posit-cloud",
    "title": "Appendix A — R Basics",
    "section": "",
    "text": "Your workspace - for personal use (20hrs/month)\nOur shared classroom - educational licence (no limit)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#getting-to-know-rstudio",
    "href": "r-basics.html#getting-to-know-rstudio",
    "title": "Appendix A — R Basics",
    "section": "\nA.2 Getting to know RStudio",
    "text": "A.2 Getting to know RStudio\nR Studio has a console that you can try out code in (appearing as the bottom left window), there is a script editor (top left), a window showing functions and objects you have created in the “Environment” tab (top right window in the figure), and a window that shows plots, files packages, and help documentation (bottom right).\n\n\n\n\nRStudio interface\n\n\n\nYou will learn more about how to use the features included in R Studio throughout this course, however, I highly recommend watching RStudio Essentials 1 at some point.\nThe video lasts ~30 minutes and gives a tour of the main parts of R Studio.\n\nA.2.1 Consoles vs. scripts\n\nThe script window is the place to enter and run code so that it is easily edited and saved for future use. Usually the Script Window is shown at the top left in RStudio. If this window is not shown, it will be visible if you open a previously saved R script, or if you create a new R Script. You create new R Script by clicking on File &gt; New File &gt; R Script in the RStudio menu bar.\nTo execute your code in the R script, you can either highlight the code and click on Run, or you can highlight the code and press CTRL + Enter on your keyboard.\nThe console: you can enter code directly in the Console Window and click Enter. The commands that you run will be shown in the History Window on the top right of RStudio. Though it is much more difficult to keep track of your work this way.\n\nA.2.2 Environment\nThe Environment tab (top right) allows you to see what objects are in the workspace. If you create variables or data frames, you have a visual listing of everything in the current workspace. When you start a new project this should be completely empty.\n\nA.2.3 Plots, files, packages, help\n\nPlots - The Plots panel, shows all your plots. There are buttons for opening the plot in a separate window and exporting the plot as a pdf or jpeg (though you can also do this with code.)\nFiles - The files panel gives you access to the file directory on your hard drive.\nPackages - Shows a list of all the R packages installed on your harddrive and indicates whether or not they are currently loaded. Packages that are loaded in the current session are checked while those that are installed but not yet loaded are unchecked. We will discuss packages more later.\nHelp - Help menu for R functions. You can either type the name of a function in the search window, or use the code to search for a function with the name\n\n\n\n\n\nRStudio interface labelled\n\n\n\n\nA.2.4 Make RStudio your own\nYou can personalise the RStudio GUI as much as you like.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#get-help",
    "href": "r-basics.html#get-help",
    "title": "Appendix A — R Basics",
    "section": "\nA.3 Get Help!",
    "text": "A.3 Get Help!\nThere are a lot of sources of information about using R out there. Here are a few helpful places to get help when you have an issue, or just to learn more\n\nThe R help system itself - type help() and put the name of the package or function you are querying inside the brackets\nVignettes - type browseVignettes() into the console and hit Enter, a list of available vignettes for all the packages we have will be displayed\nCheat Sheets - available at RStudio.com. Most common packages have an associate cheat sheet covering the basics of how to use them. Download/bookmark ones we will use commonly such as ggplot2, data transformation with dplyr, Data tidying with tidyr & Data import.\nGoogle - I use Google constantly, because I continually forget how to do even basic tasks. If I want to remind myself how to round a number, I might type something like R round number - if I am using a particular package I should include that in the search term as well\nAsk for help - If you are stuck, getting an error message, can’t think what to do next, then ask someone. It could be me, it could be a classmate. When you do this it is very important that you show the code, include the error message. “This doesn’t work” is not helpful. “Here is my code, this is the data I am using, I want it to do X, and here’s the problem I get.”\n\n\n\n\nIt may be daunting to send your code to someone for help.\n\n\nIt is natural and common to feel apprehensive, or to think that your code is really bad. I still feel the same! But we learn when we share our mistakes, and eventually you will find it funny when you look back on your early mistakes, or laugh about the mistakes you still occasionally make!",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#r",
    "href": "r-basics.html#r",
    "title": "Appendix A — R Basics",
    "section": "\nA.4 R",
    "text": "A.4 R\nGo to Posit cloud and enter the Project labelled Day One - this will clone the project and provide you with your own project workspace.\nFollow the instructions below to get used to the R command line, and how R works as a language.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#your-first-r-command",
    "href": "r-basics.html#your-first-r-command",
    "title": "Appendix A — R Basics",
    "section": "\nA.5 Your first R command",
    "text": "A.5 Your first R command\nIn the RStudio pane, navigate to the console (bottom left) and type or copy the below it should appear at the &gt;\nHit Enter on your keyboard.\n\n10 + 20\n\n\nWhat answer did you get?\n\n\n\nSolution\n\n\n30\n\n\nThe first line shows the request you made to R, the next line is R’s response\nYou didn’t type the &gt; symbol: that’s just the R command prompt and isn’t part of the actual command.\nWhen a complete expression is entered at the prompt, it is evaluated and the result of the evaluated expression is returned. The result may be auto-printed.\n\nprint(10 + 20) ## explicit printing\n\n10 + 20 ## autoprinting\n\nUsually, with interactive work, we do not explicitly print objects with the print function; it is much easier to auto-print them by typing the name of the object and hitting return/enter. However, when writing scripts, functions, or more extended programs, there is sometimes a need to explicitly print objects.\nWhen an R vector is printed, you will notice that an index for the vector is printed in square brackets [] on the side. For example, see this integer sequence\n\n1:30\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\n[26] 26 27 28 29 30\n\n\nThe numbers in the square brackets are not part of the vector itself; they are merely part of the printed output.\n\nNote that the : operator is used to create integer sequences\n\n\nA.5.1 Operators\nThere are a few different types of operators to consider in R\n\nA.5.1.1 Assignment Operator\n\n\nOperator\nDescription\n\n\n&lt;-\nused to assign values to variables\n\n\nA.5.1.2 Arithmetic Operators\n\n\nOperator\nDescription\n\n\n\n+\naddition\n\n\n-\nsubtraction\n\n\n*\nmultiplication\n\n\n/\ndivision\n\n\n^\nexponentiation\n\n\n\nA.5.1.3 Relational Operators\n\n\nOperator\nDescription\n\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngreater than or equal to\n\n\n==\nexactly equal to\n\n\n!=\nnot equal to\n\n\n\nA.5.1.4 Logical Operators\n\n\nOperator\nDescription\n\n\n\n!\nnot\n\n\n&\nAND\n\n\n⎮\nOR\n\n\n\nA.5.1.5 Membership Operators\n\n\nOperator\nDescription\n\n\n%in%\nused to check if an element is in a vector or list\n\n\nA.5.2 Typos\n\n\n\nBefore we go on to talk about other types of calculations that we can do with R, there’s a few other things I want to point out. The first thing is that, while R is good software, it’s still software. It’s pretty stupid, and because it’s stupid it can’t handle typos. It takes it on faith that you meant to type exactly what you did type.\n\n\n\nSuppose you forget to hit the shift key when trying to type +, and as a result your command ended up being 10 = 20 rather than 10 + 20. Try it for yourself and replicate this error message:\n\n10 = 20\n\n\n\nWhat answer did you get?\n\n\nError in 10 = 20 : invalid (do_set) left-hand side to assignment\n\n\nWhat’s going on: R tries to interpret 10 = 20 as a command, but it doesn’t make sense, so it gives you an error message.\nWhen a person sees this, they might realize it’s a typo because the + and = keys are right next to each other on the keyboard. But R doesn’t have that insight, so it just gets confused.\nWhat’s even trickier is that some typos won’t create errors because they accidentally form valid R commands. For example, if I meant to type 10 + 20 but mistakenly pressed a neighboring key, I’d end up with 10 - 20. Now, R can’t read your mind to know you wanted to add, not subtract, so something different happens:\n\n10 - 20\n\n[1] -10\n\n\nIn this case, R produces the right answer, but to the the wrong question.\n\nA.5.3 More simple arithmetic\nOne of the best ways to get familiar with R is to experiment with it. The good news is that it’s quite hard to mess things up, so don’t stress too much. Just type whatever you like into the console and see what happens.\nNow, if your console’s last line looks like this:\n&gt; 10+\n+ \nAnd there’s a blinking cursor next to that plus sign, it means R is patiently waiting for you to complete your command. It believes you’re still typing, so it hasn’t tried to run anything yet. This plus sign is a bit different from the usual prompt (the &gt; symbol). It’s there to nudge you that R is ready to “add” what you’re typing now to what you typed before. For example, type 20 and hit enter, and then R will complete the command like this:\n&gt; 10 +\n+ 20\n[1] 30\nAlternatively hit the escape key, and R will forget what you were trying to do and return to a blank line.\n\nA.5.4 Try some simple maths\n\n1+7\n\n\n13-10\n\n\n4*6\n\n\n12/3\n\nRaise a number to the power of another\n\n5^4\n\nMultiplying a number \\(x\\) by itself \\(n\\) times is called “raising \\(x\\) to the \\(n\\)-th power”. Mathematically, this is written as \\(x^n\\). Some values of \\(n\\) have special names: in particular \\(x^2\\) is called \\(x\\)-squared, and \\(x^3\\) is called \\(x\\)-cubed. So, the 4th power of 5 is calculated like this:\n\\[5^4 = 5 \\times 5 \\times 5 \\times 5 \\]\n\nA.5.5 Perform some combos\nR follows the standard order of operations (BODMAS/BIDMAS), which means it first calculates within brackets, then deals with exponents, followed by division and multiplication, and finally addition and subtraction.\nLet’s look at two examples to see how the order of operations affects the results:\n\n3^2-5/2\n\n\n(3^2-5)/2\n\nSimilarly if we want to raise a number to a fraction, we need to surround the fraction with parentheses ()\n\n16^1/2\n\n\n16^(1/2)\n\nThe first one calculates 16 raised to the power of 1, then divided this answer by two. The second one raises 16 to the power of a half. A big difference in the output.\n\n\n\nWhile the cursor is in the console, you can press the up arrow to see all your previous commands.\n\n\nYou can run them again, or edit them. Later on we will look at scripts, as an essential way to re-use, store and edit commands.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#true-or-false-data",
    "href": "r-basics.html#true-or-false-data",
    "title": "Appendix A — R Basics",
    "section": "\nA.6 “TRUE or FALSE” data",
    "text": "A.6 “TRUE or FALSE” data\nTime to make a sidebar onto another kind of data. Many concepts in programming rely on the idea of a logical value. A logical value is an assertion about whether something is true or false. This is implemented in R in a pretty straightforward way. There are two logical values, namely TRUE and FALSE. Despite the simplicity, logical values are very useful things. Let’s see how they work.\n\nA.6.1 Assessing mathematical truths\nTime to explore a different kind of data. In programming, many concepts rely on logical values. A logical value is a statement about whether something is true or false. In R, this is pretty straightforward. There are two logical values: TRUE and FALSE. Despite their simplicity, these logical values are incredibly useful. Let’s dive into how they work.\nIn R, basic mathematics is solid, and there’s no room for manipulation. When you ask R to calculate 2 + 2, it always provides the same answer,\n\n2 + 2\n\n[1] 4\n\n\nup to this point, R has been performing calculations without explicitly asserting whether \\(2 + 2 = 4\\) is a true statement. If I want R to make an explicit judgment, I can use a command like this:\n\n2 + 2 == 4\n\n\n\nSolution\n\n\nTRUE\n\n\nWhat I’ve done here is use the equality operator, ==, to force R to make a “true or false” judgement.\n\n\n\nThis is a very different operator to the assignment operator = you saw previously.\n\n\nA common typo that people make when trying to write logical commands in R (or other languages, since the “= versus ==” distinction is important in most programming languages) is to accidentally type = when you really mean ==.\n\n\n\nOkay, let’s see what R thinks of 2 +2 ==5:\n\n2+2 == 5\n\n[1] FALSE\n\n\nNow, let’s see what happens when I attempt to make R believe that two plus two equals five by using an assignment statement like 2 + 2 = 5 or 2 + 2 &lt;- 5. Here’s the outcome:\n\n2 + 2 = 5\n\nError in 2 + 2 = 5 : target of assignment expands to non-language object\nIndeed, R isn’t too fond of this idea. It quickly realizes that 2 + 2 is not a variable (that’s what the “non-language object” part is saying), and it refuses to let you “reassign” it. While R can be quite flexible and allows you to do some remarkable things to redefine parts of itself, there are fundamental truths it simply won’t budge on. It won’t tamper with the laws of addition, and it won’t redefine the number 2.\nThat’s probably for the best.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#storing-outputs",
    "href": "r-basics.html#storing-outputs",
    "title": "Appendix A — R Basics",
    "section": "\nA.7 Storing outputs",
    "text": "A.7 Storing outputs\nWhen dealing with more complex questions, it’s often helpful to store our answers and use them in later steps. Fortunately, this is quite easy to do in R. We can assign the results to a name with the assignment operator:\n\na &lt;- 1+2\n\nThis literally means please assign the value of 1+2 to the name a. We use the assignment operator &lt;- to make this assignment.\n\n\n\nNote the shortcut key for &lt;- is Alt + - (Windows) or Option + - (Mac)\n\n\n\nBy performing this action, you’ll achieve two things:\nYou will notice in the top right-hand pane within the Environment tab that there is now an object labeled a with a value of 3.\n\n\n\n\nobject a is now visible withe a value of 3 in the Environment Pane\n\n\n\n\nYou can check what the variable a contains by typing it into your Console and pressing Enter.\nKeep in mind that you won’t see the result of your operations until you type the object into the R console and press Enter.\n\n\na  ## autoprinting\n\nprint(a) ## explicit printing\n\n\n\nWhat output do you get when you type a into your console?\n\n\n3\n\n\nYou can now call this object at any time during your R session and perform calculations with it.\n\n2 * a\n\n\n\nSolution\n\n\n6\n\n\nWhat happens if we assign a value to a named object that already exists in our R environment??? for example\n\na &lt;- 10\na\n\nThe value of a is now 10.\nYou should see that the previous assignment is lost, gone forever and has been replaced by the new value.\nWe can assign lots of things to objects, and use them in calculations to build more objects.\n\nb &lt;- 5\nc &lt;- a + b\n\n\n\n\nRemember: If you now change the value of b, the value of c does not change.\n\n\nObjects are totally independent from each other once they are made.\n\n\nOverwriting objects with new values means the old value is lost.\n\n\n\n\nb &lt;- 7\nb\nc\n\n\nWhat is the value of c?\n\n\n\nWhat is the value of c ?\n\n\n[1] 15\n\nWhen c was created it was a product of a and b having values of 10 and 15 respectively. If we re-ran the command c &lt;- a + b after changing the value of b then we would get a value of 17.\n\nLook at the environment tab again - you should see it’s starting to fill up now!\n\n\n\nRStudio will by default save the objects in its memory when you close a session.\n\n\nThese will then be there the next time you logon. It might seem nice to be able to close things down and pick up where you left off, but its actually quite dangerous. It’s messy, and can cause lots of problems when we work with scripts later, so don’t do this!\n\n\nTo stop RStudio from saving objects by default go to Tools &gt; Project Options option and change “Save workspace to .RData on exit” to “No” or “Never”.\n\n\nInstead we are going to learn how to use scripts to quickly re-run analyses we have been working on.\n\n\n\n\nA.7.1 Choosing names\n\nUse informative variable names. As a general rule, using meaningful names like orange and apple is preferred over arbitrary ones like variable1 and variable2. Otherwise it’s very hard to remember what the contents of different variables actually are.\nUse short variable names. Typing is a pain and no-one likes doing it. So we much prefer to use a name like apple over a name like pink_lady_apple.\nUse one of the conventional naming styles for multi-word variable names. R only lets you use certain things as legal names. Legal names must start with a letter not a number, which can then be followed by a sequence of letters, numbers, ., or _. R does not like using spaces. Upper and lower case names are allowed, but R is case sensitive so Apple and apple are different.\nMy favourite naming convention is snake_case short, lower case only, spaces between words are separated with a _. It’s easy to read and easy to remember.\n\n\n\n\n\ncourtesy of Allison Horst",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#r-objects",
    "href": "r-basics.html#r-objects",
    "title": "Appendix A — R Basics",
    "section": "\nA.8 R objects",
    "text": "A.8 R objects\nIn R, there are five fundamental or “atomic” classes of objects:\n\nCharacter: These represent text or character strings.\nNumeric (num) or Double (dbl): These are used for real numbers (e.g., decimal numbers).\nInteger: Used for whole numbers.\nComplex: For complex numbers.\nLogical: Represented as True or False, these are used for logical values.\n\nThe most basic type of R object is a vector. You can create empty vectors using the vector() function. The primary rule regarding vectors in R is that a vector can only contain objects of the same class.\nHowever, as with any good rule, there’s an exception, which is the “list.” Lists are represented as vectors but can hold objects of different classes, which is why they’re often used.\n\nA.8.1 Numbers\nIn R, both “dbl” and “num” refer to numeric data types, but there is a subtle difference between them:\n\ndbl (“double”): This refers to double-precision floating-point numbers, which are capable of storing real numbers with high precision. Double-precision numbers have more decimal places of accuracy and can represent a wider range of values without loss of precision. When you perform arithmetic operations, R typically returns results as “dbl” values by default.\nnum (“numeric”): “Num” is a more general term that includes not only double-precision floating-point numbers but also integer values. In R, integers are a subtype of numeric data. Numeric data can include both integers and double-precision floating-point numbers, depending on the specific data and how it is represented.\n\nSo, “dbl” specifically denotes double-precision floating-point numbers, while “num” encompasses a broader range of numeric data, including both integers and double-precision numbers. In most cases, you can use “num” to work with numeric data in a more general sense, while “dbl” focuses on the higher-precision representation of real numbers.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#attributes",
    "href": "r-basics.html#attributes",
    "title": "Appendix A — R Basics",
    "section": "\nA.9 Attributes",
    "text": "A.9 Attributes\nR objects can come with attributes, which are essentially metadata for the object. These metadata are handy because they help describe the object. For instance, in a data frame, column names serve as attributes, clarifying the data contained in each column. Here are a few examples of R object attributes:\n\nnames() and dimnames()\ndimensions (e.g., for matrices and arrays) dim()\nclass() (e.g., integer, numeric)\nlength()\nOther user-defined attributes or metadata\n\nYou can access the attributes of an object, if it has any, by using the attributes() function. If an R object doesn’t have any attributes, the attributes() function will return NULL.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#vectors",
    "href": "r-basics.html#vectors",
    "title": "Appendix A — R Basics",
    "section": "\nA.10 Vectors",
    "text": "A.10 Vectors\nWe have been working with R objects containing a single element of data (the technical term is scalar), but we will more commonly work with vectors. A vector is a sequence of elements, all of the same data type. These could be logical, numerical, character etc.\n\nnumeric_vector &lt;- c(1,2,3)\n\ncharacter_vector &lt;- c(\"fruits\", \"vegetables\", \"seeds\")\n\nlogical_vector &lt;- c(TRUE, TRUE, FALSE)\n\ninteger_vector &lt;- 1:10\n\n\nA.10.1 Coercion\nIn R, when different classes of objects are mixed together in a vector, coercion occurs to ensure that every element in the vector belongs to the same class. Coercion is the process of converting objects to a common class to make the combination reasonable. Let’s see the effects of implicit coercion in the provided examples:\n\ny &lt;- c(2.3, \"a\") # Here, we're mixing a numeric value (1.7) with a character value (\"a\"). To make them compatible, R coerces both elements into character values. So, y becomes a character vector.\n\ny &lt;- c(TRUE, 2) # In this case, we're combining a logical value (TRUE) with a numeric value (2). R coerces the logical value into 1, so y becomes a numeric vector.\n\ny &lt;- c(\"a\", TRUE) # We're mixing a character value (\"a\") with a logical value (TRUE). In this scenario, R coerces the logical value into a character value, resulting in y becoming a character vector.\n\nSo, the outcome depends on how R can reasonably represent all the objects in the vector. It aims to create a vector of the most inclusive class to accommodate the mixed objects. Keep in mind that this coercion can lead to unexpected results, so it’s essential to be aware of the implicit type conversion when mixing different data types in R.\nObjects can also be explicitly coerced from one class to another using the as.* functions, if available.\n\nA.10.2 Task\nCreate the following vector and check its class, then note what happens when you attempt to coerce to numeric, logical and character\n\nx &lt;- 0:5\n\n\n\nSolution\n\n\nas.numeric(x)\n\nas.logical(x)\n\nas.character(x)\n\n[1] 0 1 2 3 4 5\n[1] FALSE  TRUE  TRUE  TRUE  TRUE  TRUE\n[1] \"0\" \"1\" \"2\" \"3\" \"4\" \"5\"\n\n\nr unhide()\nSometimes, R can’t figure out how to coerce an object and this can result in NAs being produced\n\nA.10.3 Subsetting vectors\nWith numerical indexing, you enter a vector of integers corresponding to the values in the vector you want to access in the form a[index], where a is the vector, and index is a vector of index values. For example, let’s use numerical indexing to get values from our character_vector\n\ncharacter_vector[2]\n# [1] \"vegetables\"\n\n\ncharacter_vector[1:2]\n# [1] \"fruits\"     \"vegetables\"\n\ncharacter_vector[c(1,3)]\n# [1] \"fruits\" \"seeds\" \n\nWe can also use logical indexing\n\nnumeric_vector &lt;=2\n# [1]  TRUE  TRUE FALSE\n\ncharacter_vector == \"fruits\"\n#[1]  TRUE FALSE FALSE\n\n\nA.10.4 Operations on vectors\nWe can run the same basic operations on vectors as we did on scalars\n\nx &lt;- c(1,2,3)\ny &lt;- c(2,3,4)\n\n# Operations will happen between vectors\nx*y\n\n[1]  2  6 12\n\n\nA very super-wickedly, important, concept: R likes to operate on vectors of the same length, so if it encounters two vectors of different lengths in a binary operation, it merely replicates (recycles) the smaller vector until it is the same length as the longest vector, then it does the operation.\n\nx &lt;- c(1,2,3)\ny &lt;- c(1,2)\n\n# Operations will happen between vectors\nx*y\n\n[1] 1 4 3\n\nWarning: longer object length is not a multiple of shorter object length[1] 1 4 3\n\n\nA.11 Matrices\nMatrices can be thought of as vectors with an added dimension attribute. This dimension attribute is a two-element integer vector specifying the number of rows and columns, which defines the shape and structure of the matrix.\n\n\n\nData frames are also two-dimensional but can store columns of different data types - matrices are simpler as they consist of elements of the same data type.\n\n\n\nMatrices are constructed “columns-first” so entries start in the “upper left” and and run down columns.\n\nm &lt;- matrix(1:6, nrow = 2, ncol = 3) \nm\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n\n\nattributes(m)\n\n$dim\n[1] 2 3\n\n\nWe can create matrices in several ways:\n\nAdding a dim() to existing vectors\nColumn/row-binding vectors with cbind() and rbind()\n\n\nm &lt;- 1:6\n\ndim(m) &lt;- c(2,3)\n\nm\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n\n\na &lt;- 1:2\nb &lt;- 3:4\nc &lt;- 5:6\n\nm &lt;- cbind(a,b,c)\nm\n\n     a b c\n[1,] 1 3 5\n[2,] 2 4 6\n\n\nYou will see how in this last operation column names were added to the matrix, we can add, change or remove column and rownames on a matrix with colnames() and rownames()\n\nrownames(m) &lt;- c(\"y\",\"z\")\nm\n\n  a b c\ny 1 3 5\nz 2 4 6\n\n\n\nA.12 Lists\nLists are a versatile and fundamental data type in R. They set themselves apart from regular vectors by allowing you to store elements of different classes within the same list. This flexibility is what makes lists so powerful for various data structures and data manipulation tasks.\nYou can create lists explicitly using the list() function, which can take an arbitrary number of arguments. Lists, when combined with functions like the “apply” family, enable you to perform complex and versatile data manipulations and analyses in R. Lists are often used to represent heterogeneous data structures, such as datasets where different columns can have different data types and structures.\n\nl &lt;- list(1, \"apple\", TRUE )\nl\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] \"apple\"\n\n[[3]]\n[1] TRUE\n\n\nWe can also create empty lists of set lengths with the vector() function, this can be useful for preallocating memory for iterations - as we will see later\n\nl &lt;- vector(\"list\", length = 3)\nl\n\n[[1]]\nNULL\n\n[[2]]\nNULL\n\n[[3]]\nNULL\n\n\nLists can also have names\n\nnames(l) &lt;- c(\"apple\",\"orange\",\"pear\")\n\n\nA.13 Dataframes\nData frames are essential for storing tabular data in R and find extensive use in various statistical modeling and data analysis applications. They offer a structured way to manage and work with data in R, and packages like dplyr, developed by Hadley Wickham, provide optimized functions for efficient data manipulation with data frames.\nHere are some key characteristics and advantages of data frames:\n\nTabular Structure: Data frames are a type of list, where each element in the list represents a column. The number of rows in each column is the same, and this tabular structure makes them suitable for working with datasets.\nMixed Data Types: Unlike matrices, data frames can contain columns with different classes of objects. This flexibility allows you to handle real-world datasets that often include variables of different data types.\nColumn and Row Names: Data frames include column names, which describe the variables or predictors. Additionally, they have a special attribute called “row.names” that provides information about each row in the data frame.\nCreation and Conversion: Data frames can be created in various ways, such as reading data from files using functions like read.table() and read.csv(). You can also create data frames explicitly with data.frame().\nWorking with Data: Data frames are especially useful when working with datasets that require data cleaning, transformation, or merging. They provide a high level of data organization, and many R packages are designed to work seamlessly with data frames.\ndplyr: The dplyr package is optimized for efficient data manipulation with data frames. It offers a set of functions to perform data operations quickly and intuitively.\n\nData frames are a fundamental structure for managing tabular data in R. They excel in handling datasets with mixed data types and are essential for various data analysis and modeling tasks.\nTo create a dataframe from vectors we use the data.frame() function\n\nsurvey &lt;- data.frame(\"index\" = c(1, 2, 3, 4, 5),\n                     \"sex\" = c(\"m\", \"m\", \"m\", \"f\", \"f\"),\n                     \"age\" = c(99, 46, 23, 54, 23))\n\nThere is one key argument to data.frame() and similar functions called stringsAsFactors. By default, the data.frame() function will automatically convert any string columns to a specific type of object called a factor in R. A factor is a nominal variable that has a well-specified possible set of values that it can take on. For example, one can create a factor sex that can only take on the values “male” and “female”.\n\n\n\nSince R ver 4.0 release, stringsAsFactors is set FALSE by default!\n\n\n\nHowever, as I’m sure you’ll discover, having R automatically convert your string data to factors can lead to lots of strange results. For example: if you have a factor of sex data, but then you want to add a new value called other, R will yell at you and return an error. I hate, hate, HATE when this happens. While there are very, very rare cases when I find factors useful, I almost always don’t want or need them. For this reason, I avoid them at all costs.\nTo tell R to not convert your string columns to factors, you need to include the argument stringsAsFactors = FALSE when using functions such as data.frame()\n\nstr(survey)\n\n'data.frame':   5 obs. of  3 variables:\n $ index: num  1 2 3 4 5\n $ sex  : chr  \"m\" \"m\" \"m\" \"f\" ...\n $ age  : num  99 46 23 54 23\n\n\nTo access a specific column in a dataframe by name, you use the $ operator in the form df$name where df is the name of the dataframe, and name is the name of the column you are interested in. This operation will then return the column you want as a vector.\n\nsurvey$sex\n\n[1] \"m\" \"m\" \"m\" \"f\" \"f\"\n\n\nBecause the $ operator returns a vector, you can easily calculate descriptive statistics on columns of a dataframe by applying your favorite vector function (like mean()).\n\nmean(survey$age)\n\n[1] 49\n\n\nWe can also use the $ to add new vectors to a dataframe\n\nsurvey$follow_up &lt;- c(T,F,T,F,F)\nsurvey\n\n\n\n\nindex\nsex\nage\nfollow_up\n\n\n\n1\nm\n99\nTRUE\n\n\n2\nm\n46\nFALSE\n\n\n3\nm\n23\nTRUE\n\n\n4\nf\n54\nFALSE\n\n\n5\nf\n23\nFALSE\n\n\n\n\n\n\nChanging column names is easy with a combination of names() and indexing\n\nnames(survey)[1] &lt;- \"ID\"\n\nsurvey\n\n\n\n\nID\nsex\nage\nfollow_up\n\n\n\n1\nm\n99\nTRUE\n\n\n2\nm\n46\nFALSE\n\n\n3\nm\n23\nTRUE\n\n\n4\nf\n54\nFALSE\n\n\n5\nf\n23\nFALSE\n\n\n\n\n\n\n\nA.13.1 Slice dataframes\nMatrices and dataframes can be sliced with [,]\n# Return row 1\ndf[1, ]\n\n\n# Return column 5 as vector\ndf[, 5]\n\n# Return column as data.frame\ndf[5]\n\n# Rows 1:5 and column 2\ndf[1:5, 2]\n\n# Single element\ndf[[1,2]]\n\nOr slice with subset\n\nsurvey_slice &lt;- subset(x = survey,\n      subset = age &lt; 50 &\n               sex == \"m\")\n\nsurvey_slice\n\n\n\n\n\nID\nsex\nage\nfollow_up\n\n\n\n2\n2\nm\n46\nFALSE\n\n\n3\n3\nm\n23\nTRUE\n\n\n\n\n\n\n\nA.13.2 Tibbles\n“Tibbles” are a new modern data frame. It keeps many important features of the original data frame\n\nA tibble never changes the input type.\nA tibble can have columns that are lists.\n\nA tibble can have non-standard variable names.\n\ncan start with a number or contain spaces. -to use this refer to these in a backtick.\n\n\nTibbles only print the first 10 rows and all the columns that fit on a screen. - Each column displays its data type\n\nThe way we make tibbles is very similar to making dataframes\n\nsurvey_tibble &lt;- tibble(\"index\" = c(1, 2, 3, 4, 5),\n                     \"sex\" = c(\"m\", \"m\", \"m\", \"f\", \"f\"),\n                     \"age\" = c(99, 46, 23, 54, 23))\n\n\n# Some R functions for looking at tibbles and dataframes\n\nhead(survey_tibble, n=2)\ntail(survey_tibble, n=1)\nnrow(survey_tibble)\nncol(survey_tibble)\ncolnames(survey_tibble)\nview(survey_tibble)\nglimpse(survey_tibble)\nstr(survey_tibble)\n\n\nA.13.3 Brackets with tibbles\nThe behaviour of single [] indexing with tibbles is slightly different.\nIn a dataframe [,1] extracts a single column as a vector, but with a tibble this conversion does not occur. Instead it returns as a tibble with a single column, not a vector.\nTo extract a vector we must use:\n\n# pull function\npull(survey_tibble, sex)\n\n# double brackets\nsurvey_tibble[[2]]\n\nhttps://tibble.tidyverse.org/\nhttps://cran.r-project.org/web/packages/tibble/vignettes/tibble.html\n\nA.14 Matrix, dataframe, tibble functions\nImportant functions for understanding matrices and dataframes.\n\n\n\n\n\n\nFunction\nDescription\n\n\n\nhead(x), tail(x)\nPrint the first few rows (or last few rows).\n\n\nView(x)\nOpen the entire object in a new window.\n\n\nnrow(x), ncol(x), dim(x)\nCount the number of rows and columns.\n\n\nrownames(), colnames(), names()\nShow the row (or column) names.\n\n\nstr(x), summary(x)\nShow the structure of the dataframe (i.e., dimensions and classes) and summary statistics.\n\n\n\nA.15 Functions\nFunctions are the tools of R. Each one helps us to do a different task.\nTake for example the function that we use to round a number to a certain number of digits - this function is called round\nHere’s an example:\n\nround(x  = 2.4326782647, digits = 2)\n\nWe start the command with the function name round. The name is followed by parentheses (). Within these we place the arguments for the function, each of which is separated by a comma.\nThe arguments:\n\nx = 2.4326782647 (the number we would like to round)\ndigits = 2 (the number of decimal places we would like to round to)\n\nArguments are the inputs we give to a function. These arguments are in the form name = value the name specifies the argument, and the value is what we are providing to define the input. That is the first argument x is the number we would like to round, it has a value of 2.4326782647. The second argument digits is how we would like the number to be rounded and we specify 2. There is no limit to how many arguments a function could have.\n\n\n\nCopy and paste the following code into the console.\n\n\n\n\nhelp(round)\n\nThe help documentation for round()should appear in the bottom right help panel. In the usage section, we see that round()takes the following form:\n\nround(x, digits = 0)\n\nIn the arguments section, there are explanations for each of the arguments. xis the number or vector where we wish to round values. digits is the number of decimal places to be used. In the description we can see that if no value is supplied for digits it will default to 0 or whole number rounding.\nRead the ‘Details’ section to find out what happens when rounding when the last digit is a 5.\nLet’s try an example and just change the required argument digits\n\n\n\nCopy and paste the following code into the console.\n\n\n\n\nround(x  = 2.4326782647)\n\n[1] 2\n\n\nNow we can change the additional arguments to produce a different set of numbers.\n\nround(x  = 2.4326782647, digits = 2)\n\n[1] 2.43\n\n\nThis time R has still rounded the number, but it has done so to a set number of ‘decimal places’.\nAlways remember to use the help documentation to help you understand what arguments a function requires.\n\nA.15.1 Storing the output of functions\nWhat if we need the answer from a function in a later calculation. The answer is to use the assignment operator again &lt;-.\nIn this example we assign values to two R objects that we can then call inside our R function as though we were putting numbers in directly.\n\n\n\nCopy and paste the following code into the console.\n\n\n\n\nnumber_of_digits &lt;- 3\n\nmy_number &lt;- 2.4326782647\n\nrounded_number &lt;- round(x  = my_number, \n                        digits = number_of_digits)\n\nWhat value is assigned to the R object rounded_number ?\n\n\nSolution\n\n\n[1] 2.433\n\n\n\nA.15.2 More fun with functions\nCopy and paste this:\n\nround(2.4326782647, 2)\n\nLooks like we don’t even have to give the names of arguments for a function to still work. This works because the function round expects us to give the number value first, and the argument for rounding digits second. But this assumes we know the expected ordering within a function, this might be the case for functions we use a lot. If you give arguments their proper names then you can actually introduce them in any order you want.\nTry this:\n\nround(digits = 2, x  = 2.4326782647)\n\nBut this gives a different answer\n\nround(2, 2.4326782647)\n\n\n\n\nRemember naming arguments overrides the position defaults\n\n\n\nHow do we know the argument orders and defaults? Well we get to know how a lot of functions work through practice, but we can also use help() .\n\nA.16 Packages\nWhen you install R you will have access to a range of functions including options for data wrangling and statistical analysis. The functions that are included in the default installation are typically referred to as Base R and there is a useful cheat sheet that shows many Base R functions here\nHowever, the power of R is that it is extendable and open source - anyone can create a new package that extends the functions of R.\nAn R package is a container for various things including functions and data. These make it easy to do very complicated protocols by using custom-built functions. Later we will see how we can write our own simple functions. Packages are a lot like new apps extending the functionality of what your phone can do.\n\nA.16.1 Loading packages\nTo use the functions from a package in our script they must be loaded before we call on the functions or data they contain. So the most sensible place to put library calls for packages is at the very top of our script.\n\nlibrary(package_name)\n\n\nA.16.2 Calling Functions from Packages\nAfter loading a package, you can call its functions using either function() or the full package_name::function_name() syntax. This allows you to specify the package explicitly when using a particular function.\n\nlibrary(dplyr)\n\nfilter(dataframe, condition)\n\ndplyr::filter(dataframe, conditions)\n\nCalling a function explicitly via its package can be useful for\n\nAvoiding Conflicts:\n\nSometimes, multiple packages may have functions with the same name. By explicitly specifying the package with package_name::, you avoid naming conflicts and ensure that R uses the function from the intended package.\n\nClarity:\n\nIt can make your code more transparent and easier to understand, especially in cases where the function’s origin is not immediately obvious. This is helpful for both yourself and others who read your code.\n\nThough it is still good practice to comment at the top of your script that this package is required even if you don’t include library(package)\n\n\nDebugging:\n\nWhen troubleshooting issues or debugging code, specifying the package source of a function can help pinpoint problems and ensure that the correct function is being used.\n\nA.17 Error\nThings will go wrong eventually, they always do…\nR is very pedantic, even the smallest typo can result in failure and typos are impossilbe to avoid. So we will make mistakes. One type of mistake we will make is an error. The code fails to run. The most common causes for an error are:\n\ntypos\nmissing commas\nmissing brackets\n\nThere’s nothing wrong with making lots of errors. The trick is not to panic or get frustrated, but to read the error message and our script carefully and start to debug (more on this later)…\n… and sometimes we need to walk away and come back later!\n\n\n\nTry typing the command help() into the R console, it should open a new tab on the bottom right.\n\n\nPut a function or package into the brackets to get help with a specific topic\n\n\n\n\n\n\n\ncourtesy of Allison Horst\n\n\n\nTo load packages we use the function library(). Typically you would start any analysis script by loading all of the packages you need.\nThe tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. This means the functions across the tidyverse are all designed to work together and make the process of data science easier.\n\nA.18 Using packages\nRun the below code to load the tidyverse package. You can do this regardless of whether you are using your own computer or the cloud.\n\nlibrary(tidyverse)\n\nYou will get what looks like an error message - it’s not. It’s just R telling you what it’s done. You should read this it gives you a full list of the packages it has made available to you.\nNow that we’ve loaded the tidyverse package we can use any of the functions it contains but remember, you need to run the library() function every time you start R.\n\n\nInstall the tidyverse. You DO NOT need to do this on RStudio Cloud.\n\nIn order to use a package, you must first install it. The following code installs the package tidyverse, a package we will use very frequently.\nIf you are working on your own computer, use the below code to install the tidyverse.\n\ninstall.packages(\"tidyverse\")\n\nYou only need to install a package once, however, each time you start R you need to load the packages you want to use, in a similar way that you need to install an app on your phone once, but you need to open it every time you want to use it.\n\n\n\n\n\nIf you get an error message that says something like “WARNING: Rtools is required to build R packages” you may need to download and install an extra bit of software called Rtools.\n\n\n\n\nA.19 Package updates\nIn addition to updates to R and R Studio, the creators of packages also sometimes update their code. This can be to add functions to a package, or it can be to fix errors. One thing to avoid is unintentionally updating an installed package. When you run install.packages() it will always install the latest version of the package and it will overwrite any older versions you may have installed. Sometimes this isn’t a problem, however, sometimes you will find that the update means your code no longer works as the package has changed substantially. It is possible to revert back to an older version of a package but try to avoid this anyway.\n\n\n\nTo avoid accidentally overwriting a package with a later version, you should never include install.packages() in your analysis scripts in case you, or someone else runs the code by mistake. Remember, the server will already have all of the packages you need for this course so you only need to install packages if you are using your own machine.\n\n\n\n\nA.20 Package conflicts\nThere are thousands of different R packages with even more functions. Unfortunately, sometimes different packages have the same function names. For example, the packages dplyr and MASS both have a function named select(). If you load both of these packages, R will produce a warning telling you that there is a conflict.\n\nlibrary(dplyr)\nlibrary(MASS)\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    survey\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\npackage �dplyr� was built under R version 3.6.3\nAttaching package: �dplyr�\n\nThe following objects are masked from �package:stats�:\n\n    filter, lag\n\nThe following objects are masked from �package:base�:\n\n    intersect, setdiff, setequal, union\n\n\nAttaching package: �MASS�\n\nThe following object is masked from �package:dplyr�:\n\n    select\nIn this case, R is telling you that the function select() in the dplyr package is being hidden (or ‘masked’) by another function with the same name. If you were to try and use select(), R would use the function from the package that was loaded most recently - in this case it would use the function from MASS.\nIf you want to specify which package you want to use for a particular function you can use code in the format package::function, for example:\n\ndplyr::select()\nMASS::select()\n\n\n\n\nWhy do we get naming conflicts?\n\n\nThis is because R is open source software. Anyone can write and submit useful R packages. As a result it is impossible to make sure that there are NEVER any functions with identical names.\n\n\n\n\nA.21 Objects\nA large part of your coding will involve creating and manipulating objects. Objects contain stuff, and we made our first R objects in the previous chapter. The values contained in an object can be numbers, words, or the result of operations and analyses.You assign content to an object using &lt;-.\n\nA.21.1 Activity 1: Create some objects\nCopy and paste the following code into the console, change the code so that it uses your own name and age and run it. You should see that name, age, today, new_year, and data appear in the environment pane.\n\nname &lt;- \"emily\"\nage &lt;- 16 + 19 \ntoday &lt;- Sys.Date()\nnew_year &lt;- as.Date(\"2022-01-01\")\ndata &lt;- rnorm(n = 10, mean = 15, sd = 3)\n\nWhat command should we use if you need help to understand the function rnorm()?\n\n`\n\n\n\n\nObjects in the environment\n\n\n\nNote that in these examples, name,age, and new_year would always contain the values emily, 35, and the date of New Year’s Day 2021, however, today will draw the date from the operating system and data will be a randomly generated set of data so the values of these objects will not be static.\nAs a side note, if you ever have to teach programming and statistics, don’t use your age as an example because every time you have to update your teaching materials you get a reminder of the fragility of existence and your advancing age. 2021 update: I have now given up updating my age, I will remain forever 35.\nImportantly, objects can be involved in calculations and can interact with each other. For example:\n\nage + 10\nnew_year - today\nmean(data)\n\n[1] 45\nTime difference of -999 days\n[1] 15.31317\n\n\nFinally, you can store the result of these operations in a new object:\n\ndecade &lt;- age + 10\n\n\n\n\nYou may find it helpful to read &lt;- as contains, e.g., name contains the text emily.\n\n\n\nYou will constantly be creating objects throughout this course and you will learn more about them and how they behave as we go along, however, for now it is enough to understand that they are a way of saving values, that these values can be numbers, text, or the result of operations, and that they can be used in further operations to create new variables.\n\n\n\nYou may also see objects referred to as ‘variables’. There is a difference between the two in programming terms, however, they are used synonymously very frequently.\n\n\n\n\nA.22 Vectors\nWe have been working with R objects containing a single element of data, but we will more commonly work with vectors. A vector is a sequence of elements, all of the same data type. These could be logical, numerical, character etc.\n\nnumeric_vector &lt;- c(1,2,3)\n\ncharacter_vector &lt;- c(\"fruits\", \"vegetables\", \"seeds\")\n\nlogical_vector &lt;- c(TRUE, TRUE, FALSE)\n\nThe function c lets you ‘concatenate’ or link each of these separate elements together into a single vector.\n\nA.23 Dataframes and tibbles\nNo we have looked at R objects that contain:\n\nsingle elements of data\nmultiple elements of the same data type - vectors\n\nBut most often when we import data into R it is put into an object called a tibble which is a type of dataframe.\n\n\n\nA dataframe is data structure that organises data into a table. Dataframes can have a mix of different types of data in them. Each column in a dataframe is a different vector, and each row is a different element within the vectors.\n\n\n\nLet’s have a quick go at making our own tibble from scratch.\n\n# make some variables/ vectors\nperson &lt;- c(\"Mark\", \"Phil\", \"Becky\", \"Tony\")\n\nhobby &lt;- c(\"kickboxing\", \"coding\", \"dog walking\", \"car boot sales\")\n\nawesomeness &lt;- c(1,100,1,1)\n\n\n\n\nUse str() on an object or vector to find out important information, like the data type of each vector and how many elements it contains.\n\n\n\nNow we put these vectors together, where they become the variables in a new tibble using the function tibble()\n\n# make a tibble\nmy_data &lt;- tibble(person, hobby, awesomeness)\nmy_data\n\n# A tibble: 4 x 3\n  person hobby          awesomeness\n  &lt;chr&gt;  &lt;chr&gt;                &lt;dbl&gt;\n1 Mark   kickboxing               1\n2 Phil   coding                 100\n3 Becky  dog walking              1\n4 Tony   car boot sales           1\nHave a go at messing about with your script and figure out what each of the functions below does.\n\n# Some R functions for looking at tibbles and dataframes\n\nhead(my_data, n=2)\ntail(my_data, n=1)\nnrow(my_data)\nncol(my_data)\ncolnames(my_data)\nview(my_data)\nglimpse(my_data)\nstr(my_data)\n\n\nA.24 Organising data in wide and long formats\nThere are two main conventions for dataframes in R, these are wide and long formats.\n\nA wide data format does not repeat values in the first column, data relating to the same “measured thing” are found in different columns\nA long data format is where we have a different column for each type of thing we have measures in our data. Each variable has a unique column.\n\n\n\n\n\nA visual representation of long and wide format data shapes\n\n\n\nWhile neither wide or long data is more correct than the other, we will work with long data as it is clearer how many distinct types of variables there are in our data and the tools we will be using from the tidyverse are designed to work with long data.\n\nA.25 How to cite R and RStudio\nYou may be some way off writing a scientific report where you have to cite and reference R, however, when the time comes it is important to do so to the people who built it (most of them for free!) credit. You should provide separate citations for R, RStudio, and the packages you use.\nTo get the citation for the version of R you are using, simply run the citation() function which will always provide you with he most recent citation.\n\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2024). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  &lt;https://www.R-project.org/&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2024},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\nTo generate the citation for any packages you are using, you can also use the citation() function with the name of the package you wish to cite.\n\ncitation(\"tidyverse\")\n\nTo cite package 'tidyverse' in publications use:\n\n  Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R,\n  Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller\n  E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V,\n  Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to\n  the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686.\n  doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {Welcome to the {tidyverse}},\n    author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D'Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},\n    year = {2019},\n    journal = {Journal of Open Source Software},\n    volume = {4},\n    number = {43},\n    pages = {1686},\n    doi = {10.21105/joss.01686},\n  }\n\n\nTo generate the citation for the version of RStudio you are using, you can use the RStudio.Version() function:\n\nRStudio.Version()\n\nFinally, here’s an example of how that might look in the write-up of your method section:\n\nAnalysis was conducted using R ver 4.0.0 (R Core Team, 2020), RStudio (Rstudio Team, 2020), and the tidyverse range of packages (Wickham, 2017).\n\nAs noted, you may not have to do this for a while, but come back to this when you do as it’s important to give the open-source community credit for their work.\n\nA.26 Help and additional resources\n\n\n\n\nThe truth about programming\n\n\n\nGetting good at programming really means getting good trying stuff out, searching for help online, and finding examples of code to copy. If you are having difficulty with any of the exercises contained in this book then you can ask for help on Teams, however, learning to problem-solve effectively is a key skill that you need to develop throughout this course.\n\nUse the help documentation. If you’re struggling to understand how a function works, remember the ?function and help() command.\nIf you get an error message, copy and paste it in to Google - it’s very likely someone else has had the same problem.\nIf you are struggling to produce a particular output or process - try organising your google searches to include key terms such as “in R” or “tidyverse”. - e.g. “how to change character strings into NA values with tidyverse”\nThe official Cheatsheets are a great resource to keep bookmarked.\nRemember to ask for help\n\nIn addition to these course materials there are a number of excellent resources for learning R:\n\nStackOverflow\nR for Data Science\nSearch or use the #rstats hashtag on Twitter\n\n\n\nA.27 Debugging tips\nA large part of coding is trying to figure why your code doesn’t work and this is true whether you are a novice or an expert. As you progress through this course you should keep a record of mistakes you make and how you fixed them. In each chapter we will provide a number of common mistakes to look out for but you will undoubtedly make (and fix!) new mistakes yourself.\n\nA.27.1 Prevent errors\nRead console outputs as you go\nCheck that functions are producing the output you expect\nBuild complex code in simple stages\n\nA.27.2 Fix errors\n\nHave you loaded the correct packages for the functions you are trying to use? One very common mistake is to write the code to load the package, e.g., library(tidyverse) but then forget to run it.\nHave you made a typo? Remember data is not the same as DATA and t.test is not the same as t_test.\nIs there a package conflict? Have you tried specifying the package and function with package::function?\nIs it definitely an error? Not all red text in R means an error - sometimes it is just giving you a message with information.\n\nA.28 Activity 7: Test yourself\nQuestion 1. Why should you never include the code install.packages() in your analysis scripts? \nYou should use library() instead\nPackages are already part of Base R\nYou (or someone else) may accidentally install a package update that stops your code working\nYou already have the latest version of the package\n\n\nExplain This Answer\n\n\nRemember, when you run install.packages() it will always install the latest version of the package and it will overwrite any older versions of the package you may have installed.\n\n\nQuestion 2. What will the following code produce?\n\nrnorm(6, 50, 10)\n\n\nA dataset with 10 numbers that has a mean of 6 and an SD of 50\nA dataset with 6 numbers that has a mean of 50 and an SD of 10\nA dataset with 50 numbers that has a mean of 10 and an SD of 6\nA dataset with 50 numbers that has a mean of 10 and an SD of 6\n\n\nExplain This Answer\n\n\nThe default form for rnorm() is rnorm(n, mean, sd). If you need help remembering what each argument of a function does, look up the help documentation by running ?rnorm\n\n\nQuestion 3. If you have two packages that have functions with the same name and you want to specify exactly which package to use, what code would you use?\n\npackage::function\nfunction::package\nlibrary(package)\ninstall.packages(package)\n\n\nExplain This Answer\n\n\nYou should use the form package::function, for example dplyr::select. Remember that when you first load your packages R will warn you if any functions have the same name - remember to look out for this!\n\n\nQuestion 4. Which of the following is most likely to be an argument? \n&lt;-\nread_csv()\n35\nQuestion 5. An easy way to spot functions is to look for \nnumbers\ncomputers\nbrackets.\nQuestion 6. The job of &lt;- is to send the output from the function to a/an \nargument\nobject\nassignment.\nQuestion 7. A vector must always contain elements of the same data type (e.g logical, character, numeric) \nTRUE\nFALSE.\nQuestion 8. A dataframe/tibble must always contain elements of the same data t",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#matrices",
    "href": "r-basics.html#matrices",
    "title": "Appendix A — R Basics",
    "section": "\nA.11 Matrices",
    "text": "A.11 Matrices\nMatrices can be thought of as vectors with an added dimension attribute. This dimension attribute is a two-element integer vector specifying the number of rows and columns, which defines the shape and structure of the matrix.\n\n\n\nData frames are also two-dimensional but can store columns of different data types - matrices are simpler as they consist of elements of the same data type.\n\n\n\nMatrices are constructed “columns-first” so entries start in the “upper left” and and run down columns.\n\nm &lt;- matrix(1:6, nrow = 2, ncol = 3) \nm\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n\n\nattributes(m)\n\n$dim\n[1] 2 3\n\n\nWe can create matrices in several ways:\n\nAdding a dim() to existing vectors\nColumn/row-binding vectors with cbind() and rbind()\n\n\nm &lt;- 1:6\n\ndim(m) &lt;- c(2,3)\n\nm\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n\n\na &lt;- 1:2\nb &lt;- 3:4\nc &lt;- 5:6\n\nm &lt;- cbind(a,b,c)\nm\n\n     a b c\n[1,] 1 3 5\n[2,] 2 4 6\n\n\nYou will see how in this last operation column names were added to the matrix, we can add, change or remove column and rownames on a matrix with colnames() and rownames()\n\nrownames(m) &lt;- c(\"y\",\"z\")\nm\n\n  a b c\ny 1 3 5\nz 2 4 6",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#lists",
    "href": "r-basics.html#lists",
    "title": "Appendix A — R Basics",
    "section": "\nA.12 Lists",
    "text": "A.12 Lists\nLists are a versatile and fundamental data type in R. They set themselves apart from regular vectors by allowing you to store elements of different classes within the same list. This flexibility is what makes lists so powerful for various data structures and data manipulation tasks.\nYou can create lists explicitly using the list() function, which can take an arbitrary number of arguments. Lists, when combined with functions like the “apply” family, enable you to perform complex and versatile data manipulations and analyses in R. Lists are often used to represent heterogeneous data structures, such as datasets where different columns can have different data types and structures.\n\nl &lt;- list(1, \"apple\", TRUE )\nl\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] \"apple\"\n\n[[3]]\n[1] TRUE\n\n\nWe can also create empty lists of set lengths with the vector() function, this can be useful for preallocating memory for iterations - as we will see later\n\nl &lt;- vector(\"list\", length = 3)\nl\n\n[[1]]\nNULL\n\n[[2]]\nNULL\n\n[[3]]\nNULL\n\n\nLists can also have names\n\nnames(l) &lt;- c(\"apple\",\"orange\",\"pear\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#dataframes",
    "href": "r-basics.html#dataframes",
    "title": "Appendix A — R Basics",
    "section": "\nA.13 Dataframes",
    "text": "A.13 Dataframes\nData frames are essential for storing tabular data in R and find extensive use in various statistical modeling and data analysis applications. They offer a structured way to manage and work with data in R, and packages like dplyr, developed by Hadley Wickham, provide optimized functions for efficient data manipulation with data frames.\nHere are some key characteristics and advantages of data frames:\n\nTabular Structure: Data frames are a type of list, where each element in the list represents a column. The number of rows in each column is the same, and this tabular structure makes them suitable for working with datasets.\nMixed Data Types: Unlike matrices, data frames can contain columns with different classes of objects. This flexibility allows you to handle real-world datasets that often include variables of different data types.\nColumn and Row Names: Data frames include column names, which describe the variables or predictors. Additionally, they have a special attribute called “row.names” that provides information about each row in the data frame.\nCreation and Conversion: Data frames can be created in various ways, such as reading data from files using functions like read.table() and read.csv(). You can also create data frames explicitly with data.frame().\nWorking with Data: Data frames are especially useful when working with datasets that require data cleaning, transformation, or merging. They provide a high level of data organization, and many R packages are designed to work seamlessly with data frames.\ndplyr: The dplyr package is optimized for efficient data manipulation with data frames. It offers a set of functions to perform data operations quickly and intuitively.\n\nData frames are a fundamental structure for managing tabular data in R. They excel in handling datasets with mixed data types and are essential for various data analysis and modeling tasks.\nTo create a dataframe from vectors we use the data.frame() function\n\nsurvey &lt;- data.frame(\"index\" = c(1, 2, 3, 4, 5),\n                     \"sex\" = c(\"m\", \"m\", \"m\", \"f\", \"f\"),\n                     \"age\" = c(99, 46, 23, 54, 23))\n\nThere is one key argument to data.frame() and similar functions called stringsAsFactors. By default, the data.frame() function will automatically convert any string columns to a specific type of object called a factor in R. A factor is a nominal variable that has a well-specified possible set of values that it can take on. For example, one can create a factor sex that can only take on the values “male” and “female”.\n\n\n\nSince R ver 4.0 release, stringsAsFactors is set FALSE by default!\n\n\n\nHowever, as I’m sure you’ll discover, having R automatically convert your string data to factors can lead to lots of strange results. For example: if you have a factor of sex data, but then you want to add a new value called other, R will yell at you and return an error. I hate, hate, HATE when this happens. While there are very, very rare cases when I find factors useful, I almost always don’t want or need them. For this reason, I avoid them at all costs.\nTo tell R to not convert your string columns to factors, you need to include the argument stringsAsFactors = FALSE when using functions such as data.frame()\n\nstr(survey)\n\n'data.frame':   5 obs. of  3 variables:\n $ index: num  1 2 3 4 5\n $ sex  : chr  \"m\" \"m\" \"m\" \"f\" ...\n $ age  : num  99 46 23 54 23\n\n\nTo access a specific column in a dataframe by name, you use the $ operator in the form df$name where df is the name of the dataframe, and name is the name of the column you are interested in. This operation will then return the column you want as a vector.\n\nsurvey$sex\n\n[1] \"m\" \"m\" \"m\" \"f\" \"f\"\n\n\nBecause the $ operator returns a vector, you can easily calculate descriptive statistics on columns of a dataframe by applying your favorite vector function (like mean()).\n\nmean(survey$age)\n\n[1] 49\n\n\nWe can also use the $ to add new vectors to a dataframe\n\nsurvey$follow_up &lt;- c(T,F,T,F,F)\nsurvey\n\n\n\n\nindex\nsex\nage\nfollow_up\n\n\n\n1\nm\n99\nTRUE\n\n\n2\nm\n46\nFALSE\n\n\n3\nm\n23\nTRUE\n\n\n4\nf\n54\nFALSE\n\n\n5\nf\n23\nFALSE\n\n\n\n\n\n\nChanging column names is easy with a combination of names() and indexing\n\nnames(survey)[1] &lt;- \"ID\"\n\nsurvey\n\n\n\n\nID\nsex\nage\nfollow_up\n\n\n\n1\nm\n99\nTRUE\n\n\n2\nm\n46\nFALSE\n\n\n3\nm\n23\nTRUE\n\n\n4\nf\n54\nFALSE\n\n\n5\nf\n23\nFALSE\n\n\n\n\n\n\n\nA.13.1 Slice dataframes\nMatrices and dataframes can be sliced with [,]\n# Return row 1\ndf[1, ]\n\n\n# Return column 5 as vector\ndf[, 5]\n\n# Return column as data.frame\ndf[5]\n\n# Rows 1:5 and column 2\ndf[1:5, 2]\n\n# Single element\ndf[[1,2]]\n\nOr slice with subset\n\nsurvey_slice &lt;- subset(x = survey,\n      subset = age &lt; 50 &\n               sex == \"m\")\n\nsurvey_slice\n\n\n\n\n\nID\nsex\nage\nfollow_up\n\n\n\n2\n2\nm\n46\nFALSE\n\n\n3\n3\nm\n23\nTRUE\n\n\n\n\n\n\n\nA.13.2 Tibbles\n“Tibbles” are a new modern data frame. It keeps many important features of the original data frame\n\nA tibble never changes the input type.\nA tibble can have columns that are lists.\n\nA tibble can have non-standard variable names.\n\ncan start with a number or contain spaces. -to use this refer to these in a backtick.\n\n\nTibbles only print the first 10 rows and all the columns that fit on a screen. - Each column displays its data type\n\nThe way we make tibbles is very similar to making dataframes\n\nsurvey_tibble &lt;- tibble(\"index\" = c(1, 2, 3, 4, 5),\n                     \"sex\" = c(\"m\", \"m\", \"m\", \"f\", \"f\"),\n                     \"age\" = c(99, 46, 23, 54, 23))\n\n\n# Some R functions for looking at tibbles and dataframes\n\nhead(survey_tibble, n=2)\ntail(survey_tibble, n=1)\nnrow(survey_tibble)\nncol(survey_tibble)\ncolnames(survey_tibble)\nview(survey_tibble)\nglimpse(survey_tibble)\nstr(survey_tibble)\n\n\nA.13.3 Brackets with tibbles\nThe behaviour of single [] indexing with tibbles is slightly different.\nIn a dataframe [,1] extracts a single column as a vector, but with a tibble this conversion does not occur. Instead it returns as a tibble with a single column, not a vector.\nTo extract a vector we must use:\n\n# pull function\npull(survey_tibble, sex)\n\n# double brackets\nsurvey_tibble[[2]]\n\nhttps://tibble.tidyverse.org/\nhttps://cran.r-project.org/web/packages/tibble/vignettes/tibble.html",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#matrix-dataframe-tibble-functions",
    "href": "r-basics.html#matrix-dataframe-tibble-functions",
    "title": "Appendix A — R Basics",
    "section": "\nA.14 Matrix, dataframe, tibble functions",
    "text": "A.14 Matrix, dataframe, tibble functions\nImportant functions for understanding matrices and dataframes.\n\n\n\n\n\n\nFunction\nDescription\n\n\n\nhead(x), tail(x)\nPrint the first few rows (or last few rows).\n\n\nView(x)\nOpen the entire object in a new window.\n\n\nnrow(x), ncol(x), dim(x)\nCount the number of rows and columns.\n\n\nrownames(), colnames(), names()\nShow the row (or column) names.\n\n\nstr(x), summary(x)\nShow the structure of the dataframe (i.e., dimensions and classes) and summary statistics.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#functions",
    "href": "r-basics.html#functions",
    "title": "Appendix A — R Basics",
    "section": "\nA.15 Functions",
    "text": "A.15 Functions\nFunctions are the tools of R. Each one helps us to do a different task.\nTake for example the function that we use to round a number to a certain number of digits - this function is called round\nHere’s an example:\n\nround(x  = 2.4326782647, digits = 2)\n\nWe start the command with the function name round. The name is followed by parentheses (). Within these we place the arguments for the function, each of which is separated by a comma.\nThe arguments:\n\nx = 2.4326782647 (the number we would like to round)\ndigits = 2 (the number of decimal places we would like to round to)\n\nArguments are the inputs we give to a function. These arguments are in the form name = value the name specifies the argument, and the value is what we are providing to define the input. That is the first argument x is the number we would like to round, it has a value of 2.4326782647. The second argument digits is how we would like the number to be rounded and we specify 2. There is no limit to how many arguments a function could have.\n\n\n\nCopy and paste the following code into the console.\n\n\n\n\nhelp(round)\n\nThe help documentation for round()should appear in the bottom right help panel. In the usage section, we see that round()takes the following form:\n\nround(x, digits = 0)\n\nIn the arguments section, there are explanations for each of the arguments. xis the number or vector where we wish to round values. digits is the number of decimal places to be used. In the description we can see that if no value is supplied for digits it will default to 0 or whole number rounding.\nRead the ‘Details’ section to find out what happens when rounding when the last digit is a 5.\nLet’s try an example and just change the required argument digits\n\n\n\nCopy and paste the following code into the console.\n\n\n\n\nround(x  = 2.4326782647)\n\n[1] 2\n\n\nNow we can change the additional arguments to produce a different set of numbers.\n\nround(x  = 2.4326782647, digits = 2)\n\n[1] 2.43\n\n\nThis time R has still rounded the number, but it has done so to a set number of ‘decimal places’.\nAlways remember to use the help documentation to help you understand what arguments a function requires.\n\nA.15.1 Storing the output of functions\nWhat if we need the answer from a function in a later calculation. The answer is to use the assignment operator again &lt;-.\nIn this example we assign values to two R objects that we can then call inside our R function as though we were putting numbers in directly.\n\n\n\nCopy and paste the following code into the console.\n\n\n\n\nnumber_of_digits &lt;- 3\n\nmy_number &lt;- 2.4326782647\n\nrounded_number &lt;- round(x  = my_number, \n                        digits = number_of_digits)\n\nWhat value is assigned to the R object rounded_number ?\n\n\nSolution\n\n\n[1] 2.433\n\n\n\nA.15.2 More fun with functions\nCopy and paste this:\n\nround(2.4326782647, 2)\n\nLooks like we don’t even have to give the names of arguments for a function to still work. This works because the function round expects us to give the number value first, and the argument for rounding digits second. But this assumes we know the expected ordering within a function, this might be the case for functions we use a lot. If you give arguments their proper names then you can actually introduce them in any order you want.\nTry this:\n\nround(digits = 2, x  = 2.4326782647)\n\nBut this gives a different answer\n\nround(2, 2.4326782647)\n\n\n\n\nRemember naming arguments overrides the position defaults\n\n\n\nHow do we know the argument orders and defaults? Well we get to know how a lot of functions work through practice, but we can also use help() .",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#packages",
    "href": "r-basics.html#packages",
    "title": "Appendix A — R Basics",
    "section": "\nA.16 Packages",
    "text": "A.16 Packages\nWhen you install R you will have access to a range of functions including options for data wrangling and statistical analysis. The functions that are included in the default installation are typically referred to as Base R and there is a useful cheat sheet that shows many Base R functions here\nHowever, the power of R is that it is extendable and open source - anyone can create a new package that extends the functions of R.\nAn R package is a container for various things including functions and data. These make it easy to do very complicated protocols by using custom-built functions. Later we will see how we can write our own simple functions. Packages are a lot like new apps extending the functionality of what your phone can do.\n\nA.16.1 Loading packages\nTo use the functions from a package in our script they must be loaded before we call on the functions or data they contain. So the most sensible place to put library calls for packages is at the very top of our script.\n\nlibrary(package_name)\n\n\nA.16.2 Calling Functions from Packages\nAfter loading a package, you can call its functions using either function() or the full package_name::function_name() syntax. This allows you to specify the package explicitly when using a particular function.\n\nlibrary(dplyr)\n\nfilter(dataframe, condition)\n\ndplyr::filter(dataframe, conditions)\n\nCalling a function explicitly via its package can be useful for\n\nAvoiding Conflicts:\n\nSometimes, multiple packages may have functions with the same name. By explicitly specifying the package with package_name::, you avoid naming conflicts and ensure that R uses the function from the intended package.\n\nClarity:\n\nIt can make your code more transparent and easier to understand, especially in cases where the function’s origin is not immediately obvious. This is helpful for both yourself and others who read your code.\n\nThough it is still good practice to comment at the top of your script that this package is required even if you don’t include library(package)\n\n\nDebugging:\n\nWhen troubleshooting issues or debugging code, specifying the package source of a function can help pinpoint problems and ensure that the correct function is being used.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#error",
    "href": "r-basics.html#error",
    "title": "Appendix A — R Basics",
    "section": "\nA.17 Error",
    "text": "A.17 Error\nThings will go wrong eventually, they always do…\nR is very pedantic, even the smallest typo can result in failure and typos are impossilbe to avoid. So we will make mistakes. One type of mistake we will make is an error. The code fails to run. The most common causes for an error are:\n\ntypos\nmissing commas\nmissing brackets\n\nThere’s nothing wrong with making lots of errors. The trick is not to panic or get frustrated, but to read the error message and our script carefully and start to debug (more on this later)…\n… and sometimes we need to walk away and come back later!\n\n\n\nTry typing the command help() into the R console, it should open a new tab on the bottom right.\n\n\nPut a function or package into the brackets to get help with a specific topic\n\n\n\n\n\n\n\ncourtesy of Allison Horst\n\n\n\nTo load packages we use the function library(). Typically you would start any analysis script by loading all of the packages you need.\nThe tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. This means the functions across the tidyverse are all designed to work together and make the process of data science easier.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#using-packages",
    "href": "r-basics.html#using-packages",
    "title": "Appendix A — R Basics",
    "section": "\nA.18 Using packages",
    "text": "A.18 Using packages\nRun the below code to load the tidyverse package. You can do this regardless of whether you are using your own computer or the cloud.\n\nlibrary(tidyverse)\n\nYou will get what looks like an error message - it’s not. It’s just R telling you what it’s done. You should read this it gives you a full list of the packages it has made available to you.\nNow that we’ve loaded the tidyverse package we can use any of the functions it contains but remember, you need to run the library() function every time you start R.\n\n\nInstall the tidyverse. You DO NOT need to do this on RStudio Cloud.\n\nIn order to use a package, you must first install it. The following code installs the package tidyverse, a package we will use very frequently.\nIf you are working on your own computer, use the below code to install the tidyverse.\n\ninstall.packages(\"tidyverse\")\n\nYou only need to install a package once, however, each time you start R you need to load the packages you want to use, in a similar way that you need to install an app on your phone once, but you need to open it every time you want to use it.\n\n\n\n\n\nIf you get an error message that says something like “WARNING: Rtools is required to build R packages” you may need to download and install an extra bit of software called Rtools.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#package-updates",
    "href": "r-basics.html#package-updates",
    "title": "Appendix A — R Basics",
    "section": "\nA.19 Package updates",
    "text": "A.19 Package updates\nIn addition to updates to R and R Studio, the creators of packages also sometimes update their code. This can be to add functions to a package, or it can be to fix errors. One thing to avoid is unintentionally updating an installed package. When you run install.packages() it will always install the latest version of the package and it will overwrite any older versions you may have installed. Sometimes this isn’t a problem, however, sometimes you will find that the update means your code no longer works as the package has changed substantially. It is possible to revert back to an older version of a package but try to avoid this anyway.\n\n\n\nTo avoid accidentally overwriting a package with a later version, you should never include install.packages() in your analysis scripts in case you, or someone else runs the code by mistake. Remember, the server will already have all of the packages you need for this course so you only need to install packages if you are using your own machine.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#package-conflicts",
    "href": "r-basics.html#package-conflicts",
    "title": "Appendix A — R Basics",
    "section": "\nA.20 Package conflicts",
    "text": "A.20 Package conflicts\nThere are thousands of different R packages with even more functions. Unfortunately, sometimes different packages have the same function names. For example, the packages dplyr and MASS both have a function named select(). If you load both of these packages, R will produce a warning telling you that there is a conflict.\n\nlibrary(dplyr)\nlibrary(MASS)\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked _by_ '.GlobalEnv':\n\n    survey\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\n\npackage �dplyr� was built under R version 3.6.3\nAttaching package: �dplyr�\n\nThe following objects are masked from �package:stats�:\n\n    filter, lag\n\nThe following objects are masked from �package:base�:\n\n    intersect, setdiff, setequal, union\n\n\nAttaching package: �MASS�\n\nThe following object is masked from �package:dplyr�:\n\n    select\nIn this case, R is telling you that the function select() in the dplyr package is being hidden (or ‘masked’) by another function with the same name. If you were to try and use select(), R would use the function from the package that was loaded most recently - in this case it would use the function from MASS.\nIf you want to specify which package you want to use for a particular function you can use code in the format package::function, for example:\n\ndplyr::select()\nMASS::select()\n\n\n\n\nWhy do we get naming conflicts?\n\n\nThis is because R is open source software. Anyone can write and submit useful R packages. As a result it is impossible to make sure that there are NEVER any functions with identical names.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#objects",
    "href": "r-basics.html#objects",
    "title": "Appendix A — R Basics",
    "section": "\nA.21 Objects",
    "text": "A.21 Objects\nA large part of your coding will involve creating and manipulating objects. Objects contain stuff, and we made our first R objects in the previous chapter. The values contained in an object can be numbers, words, or the result of operations and analyses.You assign content to an object using &lt;-.\n\nA.21.1 Activity 1: Create some objects\nCopy and paste the following code into the console, change the code so that it uses your own name and age and run it. You should see that name, age, today, new_year, and data appear in the environment pane.\n\nname &lt;- \"emily\"\nage &lt;- 16 + 19 \ntoday &lt;- Sys.Date()\nnew_year &lt;- as.Date(\"2022-01-01\")\ndata &lt;- rnorm(n = 10, mean = 15, sd = 3)\n\nWhat command should we use if you need help to understand the function rnorm()?\n\n`\n\n\n\n\nObjects in the environment\n\n\n\nNote that in these examples, name,age, and new_year would always contain the values emily, 35, and the date of New Year’s Day 2021, however, today will draw the date from the operating system and data will be a randomly generated set of data so the values of these objects will not be static.\nAs a side note, if you ever have to teach programming and statistics, don’t use your age as an example because every time you have to update your teaching materials you get a reminder of the fragility of existence and your advancing age. 2021 update: I have now given up updating my age, I will remain forever 35.\nImportantly, objects can be involved in calculations and can interact with each other. For example:\n\nage + 10\nnew_year - today\nmean(data)\n\n[1] 45\nTime difference of -999 days\n[1] 15.31317\n\n\nFinally, you can store the result of these operations in a new object:\n\ndecade &lt;- age + 10\n\n\n\n\nYou may find it helpful to read &lt;- as contains, e.g., name contains the text emily.\n\n\n\nYou will constantly be creating objects throughout this course and you will learn more about them and how they behave as we go along, however, for now it is enough to understand that they are a way of saving values, that these values can be numbers, text, or the result of operations, and that they can be used in further operations to create new variables.\n\n\n\nYou may also see objects referred to as ‘variables’. There is a difference between the two in programming terms, however, they are used synonymously very frequently.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#vectors-1",
    "href": "r-basics.html#vectors-1",
    "title": "Appendix A — R Basics",
    "section": "\nA.22 Vectors",
    "text": "A.22 Vectors\nWe have been working with R objects containing a single element of data, but we will more commonly work with vectors. A vector is a sequence of elements, all of the same data type. These could be logical, numerical, character etc.\n\nnumeric_vector &lt;- c(1,2,3)\n\ncharacter_vector &lt;- c(\"fruits\", \"vegetables\", \"seeds\")\n\nlogical_vector &lt;- c(TRUE, TRUE, FALSE)\n\nThe function c lets you ‘concatenate’ or link each of these separate elements together into a single vector.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#dataframes-and-tibbles",
    "href": "r-basics.html#dataframes-and-tibbles",
    "title": "Appendix A — R Basics",
    "section": "\nA.23 Dataframes and tibbles",
    "text": "A.23 Dataframes and tibbles\nNo we have looked at R objects that contain:\n\nsingle elements of data\nmultiple elements of the same data type - vectors\n\nBut most often when we import data into R it is put into an object called a tibble which is a type of dataframe.\n\n\n\nA dataframe is data structure that organises data into a table. Dataframes can have a mix of different types of data in them. Each column in a dataframe is a different vector, and each row is a different element within the vectors.\n\n\n\nLet’s have a quick go at making our own tibble from scratch.\n\n# make some variables/ vectors\nperson &lt;- c(\"Mark\", \"Phil\", \"Becky\", \"Tony\")\n\nhobby &lt;- c(\"kickboxing\", \"coding\", \"dog walking\", \"car boot sales\")\n\nawesomeness &lt;- c(1,100,1,1)\n\n\n\n\nUse str() on an object or vector to find out important information, like the data type of each vector and how many elements it contains.\n\n\n\nNow we put these vectors together, where they become the variables in a new tibble using the function tibble()\n\n# make a tibble\nmy_data &lt;- tibble(person, hobby, awesomeness)\nmy_data\n\n# A tibble: 4 x 3\n  person hobby          awesomeness\n  &lt;chr&gt;  &lt;chr&gt;                &lt;dbl&gt;\n1 Mark   kickboxing               1\n2 Phil   coding                 100\n3 Becky  dog walking              1\n4 Tony   car boot sales           1\nHave a go at messing about with your script and figure out what each of the functions below does.\n\n# Some R functions for looking at tibbles and dataframes\n\nhead(my_data, n=2)\ntail(my_data, n=1)\nnrow(my_data)\nncol(my_data)\ncolnames(my_data)\nview(my_data)\nglimpse(my_data)\nstr(my_data)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#organising-data-in-wide-and-long-formats",
    "href": "r-basics.html#organising-data-in-wide-and-long-formats",
    "title": "Appendix A — R Basics",
    "section": "\nA.24 Organising data in wide and long formats",
    "text": "A.24 Organising data in wide and long formats\nThere are two main conventions for dataframes in R, these are wide and long formats.\n\nA wide data format does not repeat values in the first column, data relating to the same “measured thing” are found in different columns\nA long data format is where we have a different column for each type of thing we have measures in our data. Each variable has a unique column.\n\n\n\n\n\nA visual representation of long and wide format data shapes\n\n\n\nWhile neither wide or long data is more correct than the other, we will work with long data as it is clearer how many distinct types of variables there are in our data and the tools we will be using from the tidyverse are designed to work with long data.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#how-to-cite-r-and-rstudio",
    "href": "r-basics.html#how-to-cite-r-and-rstudio",
    "title": "Appendix A — R Basics",
    "section": "\nA.25 How to cite R and RStudio",
    "text": "A.25 How to cite R and RStudio\nYou may be some way off writing a scientific report where you have to cite and reference R, however, when the time comes it is important to do so to the people who built it (most of them for free!) credit. You should provide separate citations for R, RStudio, and the packages you use.\nTo get the citation for the version of R you are using, simply run the citation() function which will always provide you with he most recent citation.\n\ncitation()\n\nTo cite R in publications use:\n\n  R Core Team (2024). _R: A Language and Environment for Statistical\n  Computing_. R Foundation for Statistical Computing, Vienna, Austria.\n  &lt;https://www.R-project.org/&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {R: A Language and Environment for Statistical Computing},\n    author = {{R Core Team}},\n    organization = {R Foundation for Statistical Computing},\n    address = {Vienna, Austria},\n    year = {2024},\n    url = {https://www.R-project.org/},\n  }\n\nWe have invested a lot of time and effort in creating R, please cite it\nwhen using it for data analysis. See also 'citation(\"pkgname\")' for\nciting R packages.\n\n\nTo generate the citation for any packages you are using, you can also use the citation() function with the name of the package you wish to cite.\n\ncitation(\"tidyverse\")\n\nTo cite package 'tidyverse' in publications use:\n\n  Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R,\n  Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller\n  E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V,\n  Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to\n  the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686.\n  doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {Welcome to the {tidyverse}},\n    author = {Hadley Wickham and Mara Averick and Jennifer Bryan and Winston Chang and Lucy D'Agostino McGowan and Romain François and Garrett Grolemund and Alex Hayes and Lionel Henry and Jim Hester and Max Kuhn and Thomas Lin Pedersen and Evan Miller and Stephan Milton Bache and Kirill Müller and Jeroen Ooms and David Robinson and Dana Paige Seidel and Vitalie Spinu and Kohske Takahashi and Davis Vaughan and Claus Wilke and Kara Woo and Hiroaki Yutani},\n    year = {2019},\n    journal = {Journal of Open Source Software},\n    volume = {4},\n    number = {43},\n    pages = {1686},\n    doi = {10.21105/joss.01686},\n  }\n\n\nTo generate the citation for the version of RStudio you are using, you can use the RStudio.Version() function:\n\nRStudio.Version()\n\nFinally, here’s an example of how that might look in the write-up of your method section:\n\nAnalysis was conducted using R ver 4.0.0 (R Core Team, 2020), RStudio (Rstudio Team, 2020), and the tidyverse range of packages (Wickham, 2017).\n\nAs noted, you may not have to do this for a while, but come back to this when you do as it’s important to give the open-source community credit for their work.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#help-and-additional-resources",
    "href": "r-basics.html#help-and-additional-resources",
    "title": "Appendix A — R Basics",
    "section": "\nA.26 Help and additional resources",
    "text": "A.26 Help and additional resources\n\n\n\n\nThe truth about programming\n\n\n\nGetting good at programming really means getting good trying stuff out, searching for help online, and finding examples of code to copy. If you are having difficulty with any of the exercises contained in this book then you can ask for help on Teams, however, learning to problem-solve effectively is a key skill that you need to develop throughout this course.\n\nUse the help documentation. If you’re struggling to understand how a function works, remember the ?function and help() command.\nIf you get an error message, copy and paste it in to Google - it’s very likely someone else has had the same problem.\nIf you are struggling to produce a particular output or process - try organising your google searches to include key terms such as “in R” or “tidyverse”. - e.g. “how to change character strings into NA values with tidyverse”\nThe official Cheatsheets are a great resource to keep bookmarked.\nRemember to ask for help\n\nIn addition to these course materials there are a number of excellent resources for learning R:\n\nStackOverflow\nR for Data Science\nSearch or use the #rstats hashtag on Twitter",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#debugging-tips",
    "href": "r-basics.html#debugging-tips",
    "title": "Appendix A — R Basics",
    "section": "\nA.27 Debugging tips",
    "text": "A.27 Debugging tips\nA large part of coding is trying to figure why your code doesn’t work and this is true whether you are a novice or an expert. As you progress through this course you should keep a record of mistakes you make and how you fixed them. In each chapter we will provide a number of common mistakes to look out for but you will undoubtedly make (and fix!) new mistakes yourself.\n\nA.27.1 Prevent errors\nRead console outputs as you go\nCheck that functions are producing the output you expect\nBuild complex code in simple stages\n\nA.27.2 Fix errors\n\nHave you loaded the correct packages for the functions you are trying to use? One very common mistake is to write the code to load the package, e.g., library(tidyverse) but then forget to run it.\nHave you made a typo? Remember data is not the same as DATA and t.test is not the same as t_test.\nIs there a package conflict? Have you tried specifying the package and function with package::function?\nIs it definitely an error? Not all red text in R means an error - sometimes it is just giving you a message with information.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "r-basics.html#activity-7-test-yourself",
    "href": "r-basics.html#activity-7-test-yourself",
    "title": "Appendix A — R Basics",
    "section": "\nA.28 Activity 7: Test yourself",
    "text": "A.28 Activity 7: Test yourself\nQuestion 1. Why should you never include the code install.packages() in your analysis scripts? \nYou should use library() instead\nPackages are already part of Base R\nYou (or someone else) may accidentally install a package update that stops your code working\nYou already have the latest version of the package\n\n\nExplain This Answer\n\n\nRemember, when you run install.packages() it will always install the latest version of the package and it will overwrite any older versions of the package you may have installed.\n\n\nQuestion 2. What will the following code produce?\n\nrnorm(6, 50, 10)\n\n\nA dataset with 10 numbers that has a mean of 6 and an SD of 50\nA dataset with 6 numbers that has a mean of 50 and an SD of 10\nA dataset with 50 numbers that has a mean of 10 and an SD of 6\nA dataset with 50 numbers that has a mean of 10 and an SD of 6\n\n\nExplain This Answer\n\n\nThe default form for rnorm() is rnorm(n, mean, sd). If you need help remembering what each argument of a function does, look up the help documentation by running ?rnorm\n\n\nQuestion 3. If you have two packages that have functions with the same name and you want to specify exactly which package to use, what code would you use?\n\npackage::function\nfunction::package\nlibrary(package)\ninstall.packages(package)\n\n\nExplain This Answer\n\n\nYou should use the form package::function, for example dplyr::select. Remember that when you first load your packages R will warn you if any functions have the same name - remember to look out for this!\n\n\nQuestion 4. Which of the following is most likely to be an argument? \n&lt;-\nread_csv()\n35\nQuestion 5. An easy way to spot functions is to look for \nnumbers\ncomputers\nbrackets.\nQuestion 6. The job of &lt;- is to send the output from the function to a/an \nargument\nobject\nassignment.\nQuestion 7. A vector must always contain elements of the same data type (e.g logical, character, numeric) \nTRUE\nFALSE.\nQuestion 8. A dataframe/tibble must always contain elements of the same data t",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>R Basics</span>"
    ]
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Appendix B — Project workflows",
    "section": "",
    "text": "B.1 Setting up a new project\nYou should start a new R project when you begin working on a distinct task, research project, or analysis. This ensures that your work is well-organized, and it’s especially beneficial when you need to collaborate, share, or revisit the project later.\nTo create and open an R project in RStudio:\nThe new project will be created with a .Rproj file. You can open it by double-clicking on this file or by using the “File” menu in RStudio.\nThis will set up a dedicated workspace for your project, ensuring that the working directory and file paths are appropriately managed.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "projects.html#setting-up-a-new-project",
    "href": "projects.html#setting-up-a-new-project",
    "title": "Appendix B — Project workflows",
    "section": "",
    "text": "Go to “File” in the RStudio menu.\nSelect “New Project…”\nChoose a project type or create a new directory for the project.\nClick “Create Project.”\n\n\n\n\n\n\n\n\n\nAvoiding setwd() and Promoting Safe File Paths:\n\n\n\nTo maintain a clean and efficient workflow in R, it’s advisable to avoid using setwd() at the beginning of each script. This practice promotes the use of safe file paths and is particularly important for projects with multiple collaborators or when working across different computers.\n\n\n\nB.1.1 Absolute vs. Relative Paths:\nWhile absolute file paths provide an explicit way to locate resources, they have significant drawbacks, such as incompatibility and reduced reproducibility. Relative file paths, on the other hand, are relative to the current working directory, making them shorter, more portable, and more reproducible.\nAn Absolute file path is a path that contains the entire path to a file or directory starting from your Home directory and ending at the file or directory you wish to access e.g.\n/home/your-username/project/data/penguins_raw.csv\n\nIf you share files, another user won’t have the same directory structure as you, so they will need to recreate the file paths\nIf you alter your directory structure, you’ll need to rewrite the paths\nAn absolute file path will likely be longer than a relative path, more of the backslashes will need to be edited, so there is more scope for error.\n\nA Relative filepath is the path that is relative to the working directory location on your computer.\nWhen you use RStudio Projects, wherever the .Rproj file is located is set to the working directory. This means that if the .Rproj file is located in your project folder then the relative path to your data is:\ndata/penguins_raw.csv\nThis filepath is shorter and it means you could share your project with someone else and the script would run without any editing.\n\nB.1.2 Organizing Projects:\nA key aspect of this workflow is organizing each logical project into a separate folder on your computer. This ensures that files and scripts are well-structured, making it easier to manage your work.\n\nB.1.3 The here Package:\nTo further enhance this organization and ensure that file paths are independent of specific working directories, the here package comes into play. The here::here() function provided by this package builds file paths relative to the top-level directory of your project.\nmy_project.RProj/\n    |- data/\n    |   |- raw/\n    |       |- penguins_raw.csv\n    |   |- processed/\n    |- scripts/\n    |   |- analysis.R\n    |- results/\n\n\nIn the above project example you have raw data files in the data/raw directory, scripts in the scripts directory, and you want to save processed data in the data/processed directory.\nTo access this data using a relative filepath we need:\n\nraw_data &lt;- read.csv(\"data/raw/penguins_raw.csv\")\n\nTo access this data with here we provide the directories and desired file, and here() builds the required filepath starting at the top level of our project each time\n\nlibrary(here)\n\nraw_data &lt;- read.csv(here(\"data\", \"raw\", \"penguins.csv\"))\n\n\n\n\n\n\n\nhere and Rmarkdown\n\n\n\nOne quirk of working in a .Rmd Rmarkdown file is that when you “knit” all code is compiled with the working directory as the folder that .Rmd file lives in, but if you are working in a script .R or in a live session then the default working directory is the top level of the project file. This frustrating and confusing process can lead to errors when attempting to compile documents.\nBUT if you use the here package then this default behaviour is overridden. The working directory when knitting will be the top-level .Rproj location again!",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "projects.html#blank-slates",
    "href": "projects.html#blank-slates",
    "title": "Appendix B — Project workflows",
    "section": "\nB.2 Blank slates",
    "text": "B.2 Blank slates\nWhen working on data analysis and coding projects in R, it’s crucial to ensure that your analysis remains clean, reproducible, and free from hidden dependencies.\nHidden dependencies are elements in your R session that might not be immediately apparent but can significantly impact the reliability and predictability of your work.\nFor example many data analysis scripts start with the command rm(list = ls()). While this command clears user-created objects from the workspace, it leaves hidden dependencies as it does not reset the R session, and can cause issues such as:\n\nHidden Dependencies: Users might unintentionally rely on packages or settings applied in the current session.\nIncomplete Reset: Package attachments made with library() persist, and customized options remain set.\nWorking Directory: The working directory is not affected, potentially causing path-related problems in future scripts.\n\n\nB.2.1 Restart R sessions\nRestarting R sessions and using scripts as your history is a best practice for maintaining a clean, reproducible, and efficient workflow. It addresses the limitations of rm(list = ls()) by ensuring a complete reset and minimizing hidden dependencies, enhancing code organization, and ensuring your analysis remains robust and predictable across sessions and when shared with others.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "projects.html#export",
    "href": "projects.html#export",
    "title": "Appendix B — Project workflows",
    "section": "\nC.1 Export",
    "text": "C.1 Export\nEach of these packages and functions has the inverse “write” function to produce files in a variety of formats from R objects.\n\n\n\n\n\n\nFunction\nDescription\n\n\n\nwrite_csv()\nCSV file format\n\n\nwrite_tsv()\nTSV (Tab-Separated Values) file format\n\n\nwrite_delim()\nUser-specified delimited files",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "projects.html#scripts",
    "href": "projects.html#scripts",
    "title": "Appendix B — Project workflows",
    "section": "\nC.2 Scripts",
    "text": "C.2 Scripts\nTo ensure clarity and understanding, begin your script with a brief description of its purpose. This description will serve as a reference point for anyone who accesses your script. Even if you make updates later on, having this initial description will help maintain clarity and context, preventing confusion when revisiting the code in the future.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "projects.html#organised-scripts",
    "href": "projects.html#organised-scripts",
    "title": "Appendix B — Project workflows",
    "section": "\nC.3 Organised scripts",
    "text": "C.3 Organised scripts\nLoad all necessary packages at the beginning of your script. It’s common to start with basic packages and then add more specialized libraries as your analysis progresses. However, it’s crucial to load all required packages at the beginning of your script. This practice ensures that when you or someone else needs to run the script again, all necessary libraries are readily available, preventing issues in the middle of execution due to unrecognized functions. Small coding details matter.\nName your code sections and use them for quick navigation. As your code grows, it may become extensive and challenging to manage. To keep it organized, divide your code into sections, each with a specific name, which can be folded or unfolded for easy navigation. You can also use the ‘drop-up’ menu at the bottom of the script screen to move between sections.\nTo create a new code section, insert “####” or “—-” at the end of a comment that marks the beginning of a new section.\n\n\n\n\n\n\n\n\nI understand, we all have good intentions, but we often neglect the task of thoroughly commenting our code. I’ve made that promise to myself many times, but even now, I struggle to do it consistently. Why, you ask? Here are a few reasons:\n\nI often tell myself that the analysis itself is more crucial.\nI believe I understand my own code.\nI usually don’t have immediate collaborators who need to use my code.\n\nHowever, these arguments are somewhat shortsighted. The reality is that:\n\nThe most valuable and relevant analysis loses its value if neither you nor others can understand it. (More on this below)\nWhile you may know what you’re doing at the moment, it won’t feel the same way in a month or two when you’ve moved on to another project, and someone innocently asks you about how you defined a critical variable. Our memory is unreliable. It’s important not to rely on it for every piece of code you produce.\nEven if you don’t have active collaborators at the time of your analysis, someone will eventually need to use your code. You won’t be in the same position forever. You’re creating a legacy that, someday, someone will rely on, no matter how distant that day may seem right now.\n\nSo, what makes code good and reproducible?\n\nThoughtful and clear comments.\nCode that is logical and efficient.\nCode that has been appropriately timed and tested.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "projects.html#use-style-guides",
    "href": "projects.html#use-style-guides",
    "title": "Appendix B — Project workflows",
    "section": "\nC.4 Use style guides",
    "text": "C.4 Use style guides\nConsider using a style guide, such as the tidyverse style guide, is a beneficial practice for several reasons:\nConsistency: A style guide enforces consistent code formatting and naming conventions throughout your project. This consistency improves code readability and makes it easier for you and others to understand the code. When you have multiple people working on a project, a shared style guide ensures that everyone’s code looks similar, reducing confusion and errors.\nReadability: Following a style guide leads to more readable code. Code is often read more frequently than it is written, so making it easy to understand is crucial. The tidyverse style guide, for example, emphasizes clear and self-explanatory code, improving comprehension for both current and future users. Good coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread\nCollaboration: When working with a team, adhering to a common style guide makes it easier to collaborate. It reduces the friction associated with different team members using varying coding styles and preferences. This streamlines code reviews and simplifies the process of maintaining and extending the codebase.\nError Reduction: A style guide can help identify and prevent common coding errors. It promotes best practices and can include guidelines for avoiding pitfalls and potential issues. This reduces the likelihood of bugs and enhances the overall quality of the code.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "projects.html#separate-your-scripts",
    "href": "projects.html#separate-your-scripts",
    "title": "Appendix B — Project workflows",
    "section": "\nC.5 Separate your scripts",
    "text": "C.5 Separate your scripts\nSeparating your analysis into distinct scripts for different steps is a sound practice in data analysis. Each script can focus on a specific task or step, making your work more organized and understandable.\nYou can use the source() function in R to run previous dependencies, ensuring that you can reproduce your work easily. Additionally, for computationally intensive processes or when dealing with large datasets, you can save and load intermediate results in RDS format. This approach not only conserves memory but also saves time when re-running your analysis.\nproject_folder/\n│\n├── data/\n│   ├── data.csv\n│   ├── processed_data.rds\n│\n├── scripts/\n│   ├── data_preparation.R\n│   ├── data_analysis.R\n│   ├── visualization.R\n│   ├── helper_functions.R\n│\n├── output/\n│   ├── result.csv\n│\n├── README.md\n│\n├── project.Rproj",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "projects.html#activity",
    "href": "projects.html#activity",
    "title": "Appendix B — Project workflows",
    "section": "\nC.6 Activity",
    "text": "C.6 Activity\nUsing the Tidyverse style guide for help, how could you improve the layout and readability of this script?\n\n# Install and load necessary packages\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(palmerpenguins)\n\npenguins_clean &lt;- janitor::clean_names(penguins_raw)\n\n\n## Data is selected by species, island, culmen length and depth and flipper, then NAs are dropped and a new column is made of length/depth and the mean is summaries for flipper length and length/depth ratio\npenguins_clean |&gt; select(species, island, culmen_length_mm, culmen_depth_mm, flipper_length_mm)  |&gt; drop_na(culmen_length_mm, culmen_depth_mm, flipper_length_mm) |&gt; mutate(culmen_ratio = culmen_length_mm / culmen_depth_mm) |&gt; group_by(species, island) |&gt; summarise(mean_flipper_length = mean(flipper_length_mm), mean_culmen_ratio = mean(culmen_ratio)) |&gt; arrange(species, island) -&gt; penguins_culmen_ratio\n\n## View summary table\nprint(penguins_culmen_ratio)\n\n\n### Data visualization \npenguins_clean |&gt;\n  ggplot(aes(x = culmen_length_mm, y = culmen_depth_mm, color = species)) +\n          geom_point() +\n                labs(x = \"Culmen Length (mm)\", y = \"Culmen Depth (mm)\") +\n                      theme_minimal()\n\n\n\nCheck your script\n\n\n# Packages ----\n# Install and load necessary packages\nlibrary(tidyverse)\nlibrary(janitor)\n# Loads the penguins dataset\nlibrary(palmerpenguins)\n\n\n# Clean the data ----\npenguins_raw &lt;- janitor::clean_names(penguins_raw)\n\n# Analysis----\n# Data exploration and manipulation to make culmen ratio\npenguins_culmen_ratio &lt;- penguins_raw |&gt; \n  select(species, island, \n         culmen_length_mm, \n         culmen_depth_mm, \n         flipper_length_mm)  |&gt; \n  drop_na(culmen_length_mm, \n          culmen_depth_mm, \n          flipper_length_mm) |&gt; \n  mutate(culmen_ratio = culmen_length_mm / culmen_depth_mm) |&gt;\n  group_by(species, island) |&gt;\n  summarise(mean_flipper_length = mean(flipper_length_mm), \n            mean_culmen_ratio = mean(culmen_ratio)) |&gt;\n  arrange(species, island)\n\n# View summary table\nprint(penguins_culmen_ratio)\n\n# Plots----\n# Data visualization using ggplot2\npenguins_clean |&gt;\n  ggplot(aes(x = culmen_length_mm, \n             y = culmen_depth_mm, \n             color = species)) +\n  geom_point() +\n  labs(x = \"Culmen Length (mm)\", \n       y = \"Culmen Depth (mm)\") +\n  theme_minimal()",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "projects.html#naming-things",
    "href": "projects.html#naming-things",
    "title": "Appendix B — Project workflows",
    "section": "\nC.7 Naming things",
    "text": "C.7 Naming things\nSo as we are reading things into and out of our environment we come to filenames.\nSo, what makes a good file name? Well, there are a few key principles to keep in mind:\n1. Machine Readable: Your file names should be machine-readable, meaning they work well with regular expressions and globbing. This allows you to search for files using keywords, with the help of regex and the stringr package. To achieve this, avoid spaces, punctuation, accented characters, and case sensitivity. This makes searching for files and filtering lists based on names easier in the future.\n\n\n\n\n\n\n\n\n2. Easy to Compute On: File names should be structured consistently, with each part of the name serving a distinct purpose and separated by delimiters. This structure makes it easy to extract information from file names, such as splitting them into meaningful components.\n\n\n\n\n\n\n\n\n3. Human Readable: A good file name should be human-readable. It should provide a clear indication of what the file contains, just by looking at its name. It’s important that even someone unfamiliar with your work can easily understand the file’s content.\n\n\n\n\n\n\n\n\n4. Compatible with Default Ordering: Your computer will automatically sort your files, whether you like it or not. To ensure files are sorted sensibly, consider the following:\n\nPut something numeric at the beginning of the file name. If the order of sourcing files matters, state when the file was created. If not, indicate the logical order of the files.\nUse the YYYY-MM-DD format for dates (it’s an ISO 8601 standard). This format helps maintain chronological order, even for Americans.\nLeft-pad numbers with zeroes to avoid incorrect sorting (e.g., 01 not 1).\n\n\n\n\n\n\n\n\n\nTaking these simple but effective steps can significantly enhance your workflow and help your colleagues as well. Remember, good file names are a small change that can make a big difference in your productivity.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "projects.html#reading",
    "href": "projects.html#reading",
    "title": "Appendix B — Project workflows",
    "section": "\nC.8 Reading",
    "text": "C.8 Reading\n\nUsing the here package\nData Organisation in Spreadsheets",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "tidy-data.html",
    "href": "tidy-data.html",
    "title": "Appendix C — Tidy data",
    "section": "",
    "text": "C.1 Why tidy data?",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Tidy data</span>"
    ]
  },
  {
    "objectID": "tidy-data.html#why-tidy-data",
    "href": "tidy-data.html#why-tidy-data",
    "title": "Appendix C — Tidy data",
    "section": "",
    "text": "The data cleaning and analysis tools in R work best with data that is “tidy”\n“Tidy” data has a clear and consistent structure, untidy data can be “messy” in lots of different ways",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Tidy data</span>"
    ]
  },
  {
    "objectID": "tidy-data.html#using-pivot-functions",
    "href": "tidy-data.html#using-pivot-functions",
    "title": "Appendix C — Tidy data",
    "section": "\nC.2 Using pivot functions",
    "text": "C.2 Using pivot functions\nWhat do we do if the data we are working with in R isn’t “tidy”?\nThere are functions found as part of the tidyverse that can help us to reshape data.\n\ntidyr::pivot_wider() - from long to wide format\ntidyr::pivot_longer() - from wide to long format\n\n\n\n\n\nReshaping data with pivot\n\n\n\n\n country &lt;- c(\"x\", \"y\", \"z\")\n yr1960 &lt;-  c(10, 20, 30)\n yr1970 &lt;-  c(13, 23, 33)\n yr2010 &lt;-  c(15, 25, 35)\n\ncountry_data &lt;- tibble(country, yr1960, yr1970, yr2010)\ncountry_data\n\n\n\n\ncountry\nyr1960\nyr1970\nyr2010\n\n\n\nx\n10\n13\n15\n\n\ny\n20\n23\n25\n\n\nz\n30\n33\n35\n\n\n\n\n\n\n\npivot_longer(data = country_data,\n             cols = yr1960:yr2010,\n             names_to = \"year\",\n             names_prefix = \"yr\",\n             values_to = \"metric\")\n\n\n\n\n\nReshaping data with pivot\n\n\n\nTo save these changes to your data format, you must assign this to an object, and you have two options\n\nUse the same name as the original R object, this will overwrite the original with the new format\nUse a new name for the reformatted data both R objects will exist in your Environment\n\nNeither is more correct than the other but be aware of what you are doing.\n\nC.2.1 Overwrite the original object\n\ncountry_data &lt;- pivot_longer(data = country_data,\n             cols = yr1960:yr2010,\n             names_to = \"year\",\n             names_prefix = \"yr\",\n             values_to = \"metric\")\n\n\nC.2.2 Create a new r object\n\nlong_country_data &lt;- pivot_longer(data = country_data,\n             cols = yr1960:yr2010,\n             names_to = \"year\",\n             names_prefix = \"yr\",\n             values_to = \"metric\")",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Tidy data</span>"
    ]
  },
  {
    "objectID": "tidy-data.html#reading",
    "href": "tidy-data.html#reading",
    "title": "Appendix C — Tidy data",
    "section": "\nC.3 Reading",
    "text": "C.3 Reading\n\nTidy data\n\n\n\n\n\nWickham, H. (2023). Tidyverse: Easily install and load the tidyverse. https://tidyverse.tidyverse.org",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Tidy data</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Gorman, K., Williams, T., & Fraser, W. (2014). Ecological sexual\ndimorphism and environmental variability within a community of antarctic\npenguins (genus pygoscelis). PLos One, 9(3), e90081.\nhttps://doi.org/10.1371/journal.pone.0090081\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer\narchipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nWickham, H. (2023). Tidyverse: Easily install and load the\ntidyverse. https://tidyverse.tidyverse.org",
    "crumbs": [
      "Appendices",
      "References"
    ]
  }
]