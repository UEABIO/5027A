[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "5027A",
    "section": "",
    "text": "Overview\nThis course will introduce scientists and practitioners interested in applying statistical approaches in their daily routine using R as a working environment. Participants will be introduced into R and R Studio while learning how to perform common statistical analyses. After a short introduction on R and its principles, the focus will be on questions that could be addressed using common statistical analyses, both for descriptive statistics and for statistical inference.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#learning-outcomes",
    "href": "index.html#learning-outcomes",
    "title": "5027A",
    "section": "Learning outcomes",
    "text": "Learning outcomes\n\nUnderstand how to read, interpret and write scripts in R.\nLearn how to check and clean data\nLearn statistical tools to address common questions in research activities.\nAn introduction to efficient, readable and reproducible analyses\nBeing comfortable with using R when performing both descriptive and inferential statistics.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#how-to-use-this-book",
    "href": "index.html#how-to-use-this-book",
    "title": "5027A",
    "section": "How to use this book",
    "text": "How to use this book\nFor many of the chapters, we will provide the code you need to use. You can copy and paste from the book using the clipboard in the top-right corner.\nWe also provide the solutions to many of the activities. No-one is going to check whether you tried to figure it out yourself rather than going straight to the solution but remember this: if you copy and paste without thinking, you will learn nothing.\nFinally, on occasion we will make updates to the book such as fixing typos and including additional detail or activities and as such this book should be considered a living document. Please tell me if you find any mistakes.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#course-structure",
    "href": "index.html#course-structure",
    "title": "5027A",
    "section": "Course Structure",
    "text": "Course Structure\nWe have:\n\n\nOne workshop per week, these both timetabled in-person sessions, and you should check Timetabler for up to-date information on scheduling. However, everything you need to complete workshops will be available on this site.\n\nIf you feel unwell, or cannot attend a session in-person don’t worry you can access everything, and follow along in real time, or work at your own pace.\n\n\nOne assignment per week - this will be in the form of quizzes or short assignments, each assignment is worth 2% of your module grade (to a maximum of 15%) and there will be 10 assignments total.\nOne data analysis project - this will be a single piece of coursework (details after reading week) worth 20% of the the module grade",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "02-projects.html",
    "href": "02-projects.html",
    "title": "1  Project workflows",
    "section": "",
    "text": "1.1 Setting up a new project\nYou should start a new R project when you begin working on a distinct task, research project, or analysis. This ensures that your work is well-organized, and it’s especially beneficial when you need to collaborate, share, or revisit the project later.\nTo create and open an R project in RStudio:\nThe new project will be created with a .Rproj file. You can open it by double-clicking on this file or by using the “File” menu in RStudio.\nThis will set up a dedicated workspace for your project, ensuring that the working directory and file paths are appropriately managed.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "02-projects.html#setting-up-a-new-project",
    "href": "02-projects.html#setting-up-a-new-project",
    "title": "1  Project workflows",
    "section": "",
    "text": "Go to “File” in the RStudio menu.\nSelect “New Project…”\nChoose a project type or create a new directory for the project.\nClick “Create Project.”\n\n\n\n\n\n\n\n\n\nAvoiding setwd() and Promoting Safe File Paths:\n\n\n\nTo maintain a clean and efficient workflow in R, it’s advisable to avoid using setwd() at the beginning of each script. This practice promotes the use of safe file paths and is particularly important for projects with multiple collaborators or when working across different computers.\n\n\n\n1.1.1 Absolute vs. Relative Paths:\nWhile absolute file paths provide an explicit way to locate resources, they have significant drawbacks, such as incompatibility and reduced reproducibility. Relative file paths, on the other hand, are relative to the current working directory, making them shorter, more portable, and more reproducible.\nAn Absolute file path is a path that contains the entire path to a file or directory starting from your Home directory and ending at the file or directory you wish to access e.g.\n/home/your-username/project/data/penguins_raw.csv\n\nIf you share files, another user won’t have the same directory structure as you, so they will need to recreate the file paths\nIf you alter your directory structure, you’ll need to rewrite the paths\nAn absolute file path will likely be longer than a relative path, more of the backslashes will need to be edited, so there is more scope for error.\n\nA Relative filepath is the path that is relative to the working directory location on your computer.\nWhen you use RStudio Projects, wherever the .Rproj file is located is set to the working directory. This means that if the .Rproj file is located in your project folder then the relative path to your data is:\ndata/penguins_raw.csv\nThis filepath is shorter and it means you could share your project with someone else and the script would run without any editing.\n\n1.1.2 Organizing Projects:\nA key aspect of this workflow is organizing each logical project into a separate folder on your computer. This ensures that files and scripts are well-structured, making it easier to manage your work.\n\n1.1.3 The here Package:\nTo further enhance this organization and ensure that file paths are independent of specific working directories, the here package comes into play. The here::here() function provided by this package builds file paths relative to the top-level directory of your project.\nmy_project.RProj/\n    |- data/\n    |   |- raw/\n    |       |- penguins_raw.csv\n    |   |- processed/\n    |- scripts/\n    |   |- analysis.R\n    |- results/\n\n\nIn the above project example you have raw data files in the data/raw directory, scripts in the scripts directory, and you want to save processed data in the data/processed directory.\nTo access this data using a relative filepath we need:\n\nraw_data &lt;- read.csv(\"data/raw/penguins_raw.csv\")\n\nTo access this data with here we provide the directories and desired file, and here() builds the required filepath starting at the top level of our project each time\n\nlibrary(here)\n\nraw_data &lt;- read.csv(here(\"data\", \"raw\", \"penguins.csv\"))\n\n\n\n\n\n\n\nhere and Rmarkdown\n\n\n\nOne quirk of working in a .Rmd Rmarkdown file is that when you “knit” all code is compiled with the working directory as the folder that .Rmd file lives in, but if you are working in a script .R or in a live session then the default working directory is the top level of the project file. This frustrating and confusing process can lead to errors when attempting to compile documents.\nBUT if you use the here package then this default behaviour is overridden. The working directory when knitting will be the top-level .Rproj location again!",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "02-projects.html#blank-slates",
    "href": "02-projects.html#blank-slates",
    "title": "1  Project workflows",
    "section": "\n1.2 Blank slates",
    "text": "1.2 Blank slates\nWhen working on data analysis and coding projects in R, it’s crucial to ensure that your analysis remains clean, reproducible, and free from hidden dependencies.\nHidden dependencies are elements in your R session that might not be immediately apparent but can significantly impact the reliability and predictability of your work.\nFor example many data analysis scripts start with the command rm(list = ls()). While this command clears user-created objects from the workspace, it leaves hidden dependencies as it does not reset the R session, and can cause issues such as:\n\nHidden Dependencies: Users might unintentionally rely on packages or settings applied in the current session.\nIncomplete Reset: Package attachments made with library() persist, and customized options remain set.\nWorking Directory: The working directory is not affected, potentially causing path-related problems in future scripts.\n\n\n1.2.1 Restart R sessions\nRestarting R sessions and using scripts as your history is a best practice for maintaining a clean, reproducible, and efficient workflow. It addresses the limitations of rm(list = ls()) by ensuring a complete reset and minimizing hidden dependencies, enhancing code organization, and ensuring your analysis remains robust and predictable across sessions and when shared with others.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "02-projects.html#export",
    "href": "02-projects.html#export",
    "title": "1  Project workflows",
    "section": "\n2.1 Export",
    "text": "2.1 Export\nEach of these packages and functions has the inverse “write” function to produce files in a variety of formats from R objects.\n\n\n\n\n\n\nFunction\nDescription\n\n\n\nwrite_csv()\nCSV file format\n\n\nwrite_tsv()\nTSV (Tab-Separated Values) file format\n\n\nwrite_delim()\nUser-specified delimited files",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "02-projects.html#scripts",
    "href": "02-projects.html#scripts",
    "title": "1  Project workflows",
    "section": "\n2.2 Scripts",
    "text": "2.2 Scripts\nTo ensure clarity and understanding, begin your script with a brief description of its purpose. This description will serve as a reference point for anyone who accesses your script. Even if you make updates later on, having this initial description will help maintain clarity and context, preventing confusion when revisiting the code in the future.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "02-projects.html#organised-scripts",
    "href": "02-projects.html#organised-scripts",
    "title": "1  Project workflows",
    "section": "\n2.3 Organised scripts",
    "text": "2.3 Organised scripts\nLoad all necessary packages at the beginning of your script. It’s common to start with basic packages and then add more specialized libraries as your analysis progresses. However, it’s crucial to load all required packages at the beginning of your script. This practice ensures that when you or someone else needs to run the script again, all necessary libraries are readily available, preventing issues in the middle of execution due to unrecognized functions. Small coding details matter.\nName your code sections and use them for quick navigation. As your code grows, it may become extensive and challenging to manage. To keep it organized, divide your code into sections, each with a specific name, which can be folded or unfolded for easy navigation. You can also use the ‘drop-up’ menu at the bottom of the script screen to move between sections.\nTo create a new code section, insert “####” or “—-” at the end of a comment that marks the beginning of a new section.\n\n\n\n\n\n\n\n\nI understand, we all have good intentions, but we often neglect the task of thoroughly commenting our code. I’ve made that promise to myself many times, but even now, I struggle to do it consistently. Why, you ask? Here are a few reasons:\n\nI often tell myself that the analysis itself is more crucial.\nI believe I understand my own code.\nI usually don’t have immediate collaborators who need to use my code.\n\nHowever, these arguments are somewhat shortsighted. The reality is that:\n\nThe most valuable and relevant analysis loses its value if neither you nor others can understand it. (More on this below)\nWhile you may know what you’re doing at the moment, it won’t feel the same way in a month or two when you’ve moved on to another project, and someone innocently asks you about how you defined a critical variable. Our memory is unreliable. It’s important not to rely on it for every piece of code you produce.\nEven if you don’t have active collaborators at the time of your analysis, someone will eventually need to use your code. You won’t be in the same position forever. You’re creating a legacy that, someday, someone will rely on, no matter how distant that day may seem right now.\n\nSo, what makes code good and reproducible?\n\nThoughtful and clear comments.\nCode that is logical and efficient.\nCode that has been appropriately timed and tested.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "02-projects.html#use-style-guides",
    "href": "02-projects.html#use-style-guides",
    "title": "1  Project workflows",
    "section": "\n2.4 Use style guides",
    "text": "2.4 Use style guides\nConsider using a style guide, such as the tidyverse style guide, is a beneficial practice for several reasons:\nConsistency: A style guide enforces consistent code formatting and naming conventions throughout your project. This consistency improves code readability and makes it easier for you and others to understand the code. When you have multiple people working on a project, a shared style guide ensures that everyone’s code looks similar, reducing confusion and errors.\nReadability: Following a style guide leads to more readable code. Code is often read more frequently than it is written, so making it easy to understand is crucial. The tidyverse style guide, for example, emphasizes clear and self-explanatory code, improving comprehension for both current and future users. Good coding style is like correct punctuation: you can manage without it, butitsuremakesthingseasiertoread\nCollaboration: When working with a team, adhering to a common style guide makes it easier to collaborate. It reduces the friction associated with different team members using varying coding styles and preferences. This streamlines code reviews and simplifies the process of maintaining and extending the codebase.\nError Reduction: A style guide can help identify and prevent common coding errors. It promotes best practices and can include guidelines for avoiding pitfalls and potential issues. This reduces the likelihood of bugs and enhances the overall quality of the code.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "02-projects.html#separate-your-scripts",
    "href": "02-projects.html#separate-your-scripts",
    "title": "1  Project workflows",
    "section": "\n2.5 Separate your scripts",
    "text": "2.5 Separate your scripts\nSeparating your analysis into distinct scripts for different steps is a sound practice in data analysis. Each script can focus on a specific task or step, making your work more organized and understandable.\nYou can use the source() function in R to run previous dependencies, ensuring that you can reproduce your work easily. Additionally, for computationally intensive processes or when dealing with large datasets, you can save and load intermediate results in RDS format. This approach not only conserves memory but also saves time when re-running your analysis.\nproject_folder/\n│\n├── data/\n│   ├── data.csv\n│   ├── processed_data.rds\n│\n├── scripts/\n│   ├── data_preparation.R\n│   ├── data_analysis.R\n│   ├── visualization.R\n│   ├── helper_functions.R\n│\n├── output/\n│   ├── result.csv\n│\n├── README.md\n│\n├── project.Rproj",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "02-projects.html#activity",
    "href": "02-projects.html#activity",
    "title": "1  Project workflows",
    "section": "\n2.6 Activity",
    "text": "2.6 Activity\nUsing the Tidyverse style guide for help, how could you improve the layout and readability of this script?\n\n# Install and load necessary packages\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(palmerpenguins)\n\npenguins_clean &lt;- janitor::clean_names(penguins_raw)\n\n\n## Data is selected by species, island, culmen length and depth and flipper, then NAs are dropped and a new column is made of length/depth and the mean is summaries for flipper length and length/depth ratio\npenguins_clean |&gt; select(species, island, culmen_length_mm, culmen_depth_mm, flipper_length_mm)  |&gt; drop_na(culmen_length_mm, culmen_depth_mm, flipper_length_mm) |&gt; mutate(culmen_ratio = culmen_length_mm / culmen_depth_mm) |&gt; group_by(species, island) |&gt; summarise(mean_flipper_length = mean(flipper_length_mm), mean_culmen_ratio = mean(culmen_ratio)) |&gt; arrange(species, island) -&gt; penguins_culmen_ratio\n\n## View summary table\nprint(penguins_culmen_ratio)\n\n\n### Data visualization \npenguins_clean |&gt;\n  ggplot(aes(x = culmen_length_mm, y = culmen_depth_mm, color = species)) +\n          geom_point() +\n                labs(x = \"Culmen Length (mm)\", y = \"Culmen Depth (mm)\") +\n                      theme_minimal()\n\n\n\nCheck your script\n\n\n# Packages ----\n# Install and load necessary packages\nlibrary(tidyverse)\nlibrary(janitor)\n# Loads the penguins dataset\nlibrary(palmerpenguins)\n\n\n# Clean the data ----\npenguins_raw &lt;- janitor::clean_names(penguins_raw)\n\n# Analysis----\n# Data exploration and manipulation to make culmen ratio\npenguins_culmen_ratio &lt;- penguins_raw |&gt; \n  select(species, island, \n         culmen_length_mm, \n         culmen_depth_mm, \n         flipper_length_mm)  |&gt; \n  drop_na(culmen_length_mm, \n          culmen_depth_mm, \n          flipper_length_mm) |&gt; \n  mutate(culmen_ratio = culmen_length_mm / culmen_depth_mm) |&gt;\n  group_by(species, island) |&gt;\n  summarise(mean_flipper_length = mean(flipper_length_mm), \n            mean_culmen_ratio = mean(culmen_ratio)) |&gt;\n  arrange(species, island)\n\n# View summary table\nprint(penguins_culmen_ratio)\n\n# Plots----\n# Data visualization using ggplot2\npenguins_clean |&gt;\n  ggplot(aes(x = culmen_length_mm, \n             y = culmen_depth_mm, \n             color = species)) +\n  geom_point() +\n  labs(x = \"Culmen Length (mm)\", \n       y = \"Culmen Depth (mm)\") +\n  theme_minimal()",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "02-projects.html#naming-things",
    "href": "02-projects.html#naming-things",
    "title": "1  Project workflows",
    "section": "\n2.7 Naming things",
    "text": "2.7 Naming things\nSo as we are reading things into and out of our environment we come to filenames.\nSo, what makes a good file name? Well, there are a few key principles to keep in mind:\n1. Machine Readable: Your file names should be machine-readable, meaning they work well with regular expressions and globbing. This allows you to search for files using keywords, with the help of regex and the stringr package. To achieve this, avoid spaces, punctuation, accented characters, and case sensitivity. This makes searching for files and filtering lists based on names easier in the future.\n\n\n\n\n\n\n\n\n2. Easy to Compute On: File names should be structured consistently, with each part of the name serving a distinct purpose and separated by delimiters. This structure makes it easy to extract information from file names, such as splitting them into meaningful components.\n\n\n\n\n\n\n\n\n3. Human Readable: A good file name should be human-readable. It should provide a clear indication of what the file contains, just by looking at its name. It’s important that even someone unfamiliar with your work can easily understand the file’s content.\n\n\n\n\n\n\n\n\n4. Compatible with Default Ordering: Your computer will automatically sort your files, whether you like it or not. To ensure files are sorted sensibly, consider the following:\n\nPut something numeric at the beginning of the file name. If the order of sourcing files matters, state when the file was created. If not, indicate the logical order of the files.\nUse the YYYY-MM-DD format for dates (it’s an ISO 8601 standard). This format helps maintain chronological order, even for Americans.\nLeft-pad numbers with zeroes to avoid incorrect sorting (e.g., 01 not 1).\n\n\n\n\n\n\n\n\n\nTaking these simple but effective steps can significantly enhance your workflow and help your colleagues as well. Remember, good file names are a small change that can make a big difference in your productivity.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "02-projects.html#reading",
    "href": "02-projects.html#reading",
    "title": "1  Project workflows",
    "section": "\n2.8 Reading",
    "text": "2.8 Reading\n\nUsing the here package\nData Organisation in Spreadsheets",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Project workflows</span>"
    ]
  },
  {
    "objectID": "03-tidy-data.html",
    "href": "03-tidy-data.html",
    "title": "2  Tidy data",
    "section": "",
    "text": "2.1 Why tidy data?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Tidy data</span>"
    ]
  },
  {
    "objectID": "03-tidy-data.html#why-tidy-data",
    "href": "03-tidy-data.html#why-tidy-data",
    "title": "2  Tidy data",
    "section": "",
    "text": "The data cleaning and analysis tools in R work best with data that is “tidy”\n“Tidy” data has a clear and consistent structure, untidy data can be “messy” in lots of different ways",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Tidy data</span>"
    ]
  },
  {
    "objectID": "03-tidy-data.html#using-pivot-functions",
    "href": "03-tidy-data.html#using-pivot-functions",
    "title": "2  Tidy data",
    "section": "\n2.2 Using pivot functions",
    "text": "2.2 Using pivot functions\nWhat do we do if the data we are working with in R isn’t “tidy”?\nThere are functions found as part of the tidyverse that can help us to reshape data.\n\ntidyr::pivot_wider() - from long to wide format\ntidyr::pivot_longer() - from wide to long format\n\n\n\n\n\nReshaping data with pivot\n\n\n\n\n country &lt;- c(\"x\", \"y\", \"z\")\n yr1960 &lt;-  c(10, 20, 30)\n yr1970 &lt;-  c(13, 23, 33)\n yr2010 &lt;-  c(15, 25, 35)\n\ncountry_data &lt;- tibble(country, yr1960, yr1970, yr2010)\ncountry_data\n\n\n\n\ncountry\nyr1960\nyr1970\nyr2010\n\n\n\nx\n10\n13\n15\n\n\ny\n20\n23\n25\n\n\nz\n30\n33\n35\n\n\n\n\n\n\n\npivot_longer(data = country_data,\n             cols = yr1960:yr2010,\n             names_to = \"year\",\n             names_prefix = \"yr\",\n             values_to = \"metric\")\n\n\n\n\n\nReshaping data with pivot\n\n\n\nTo save these changes to your data format, you must assign this to an object, and you have two options\n\nUse the same name as the original R object, this will overwrite the original with the new format\nUse a new name for the reformatted data both R objects will exist in your Environment\n\nNeither is more correct than the other but be aware of what you are doing.\n\n2.2.1 Overwrite the original object\n\ncountry_data &lt;- pivot_longer(data = country_data,\n             cols = yr1960:yr2010,\n             names_to = \"year\",\n             names_prefix = \"yr\",\n             values_to = \"metric\")\n\n\n2.2.2 Create a new r object\n\nlong_country_data &lt;- pivot_longer(data = country_data,\n             cols = yr1960:yr2010,\n             names_to = \"year\",\n             names_prefix = \"yr\",\n             values_to = \"metric\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Tidy data</span>"
    ]
  },
  {
    "objectID": "03-tidy-data.html#reading",
    "href": "03-tidy-data.html#reading",
    "title": "2  Tidy data",
    "section": "\n2.3 Reading",
    "text": "2.3 Reading\n\nTidy data\n\n\n\n\n\nWickham, H. (2023). Tidyverse: Easily install and load the tidyverse. https://tidyverse.tidyverse.org",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Tidy data</span>"
    ]
  },
  {
    "objectID": "04-penguin-project.html",
    "href": "04-penguin-project.html",
    "title": "3  Meet the Penguins",
    "section": "",
    "text": "3.1 Meet the Penguins\nThis data, taken from the palmerpenguins (Horst et al. (2022)) package was originally published by Gorman et al. (2014). In our course we will work with real data that has been shared by other researchers.\nThe palmer penguins data contains size measurements, clutch observations, and blood isotope ratios for three penguin species observed on three islands in the Palmer Archipelago, Antarctica over a study period of three years.\nThese data were collected from 2007 - 2009 by Dr. Kristen Gorman with the Palmer Station Long Term Ecological Research Program, part of the US Long Term Ecological Research Network. The data were imported directly from the Environmental Data Initiative (EDI) Data Portal, and are available for use by CC0 license (“No Rights Reserved”) in accordance with the Palmer Station Data Policy. We gratefully acknowledge Palmer Station LTER and the US LTER Network. Special thanks to Marty Downs (Director, LTER Network Office) for help regarding the data license & use. Here is our intrepid package co-author, Dr. Gorman, in action collecting some penguin data:\nHere is a map of the study site",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Meet the Penguins</span>"
    ]
  },
  {
    "objectID": "04-penguin-project.html#activity-1-organising-our-workspace",
    "href": "04-penguin-project.html#activity-1-organising-our-workspace",
    "title": "3  Meet the Penguins",
    "section": "\n3.2 Activity 1: Organising our workspace",
    "text": "3.2 Activity 1: Organising our workspace\nBefore we can begin working with the data, we need to do some set-up.\n\nGo to RStudio Cloud and open the Penguins R project\n\nCreate the following folders using the + New Folder button in the Files tab\n\ndata\noutputs\nscripts\n\n\n\n\n\n\nR is case-sensitive so type everything EXACTLY as printed here\n\n\n\n\ndir.create(\"data\",\n           showWarnings = FALSE)\n\ndir.create(\"outputs\",\n           showWarnings = FALSE)\n\ndir.create(\"scripts\",\n           showWarnings = FALSE)\n\n# or this can be run using apply\nlapply(c(\"data\", \"outputs\", \"scripts\"), function(dir_name) {\n  dir.create(dir_name, showWarnings = FALSE)\n})\n\nHaving these separate subfolders within our project helps keep things tidy, means it’s harder to lose things, and lets you easily tell R exactly where to go to retrieve data.\nThe next step of our workflow is to have a well organised project space. RStudio Cloud does a lot of the hard work for you, each new data project can be set up with its own Project space.\nWe will define a project as a series of linked questions that uses one (or sometimes several) datasets. For example a coursework assignment for a particular module would be its own project, a series of linked experiments or particular research project might be its own project.\nA Project will contain several files, possibly organised into sub-folders containing data, R scripts and final outputs. You might want to keep any information (wider reading) you have gathered that is relevant to your project.\n\n\n\n\nAn example of a typical R project set-up\n\n\n\nWithin this project you will notice there is already one file .Rproj. This is an R project file, this is a very useful feature, it interacts with R to tell it you are working in a very specific place on the computer (in this case the cloud server we have dialed into). It means R will automatically treat the location of your project file as the ‘working directory’ and makes importing and exporting easier1.\n\n\n\nIt is very important to NEVER to move the .Rproj file, this may prevent your workspace from opening properly.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Meet the Penguins</span>"
    ]
  },
  {
    "objectID": "04-penguin-project.html#activity-2-access-our-data",
    "href": "04-penguin-project.html#activity-2-access-our-data",
    "title": "3  Meet the Penguins",
    "section": "\n3.3 Activity 2: Access our data",
    "text": "3.3 Activity 2: Access our data\nNow that we have a project workspace, we are ready to import some data.\n\nUse the link below to open a page in your browser with the data open\nRight-click Save As to download in csv format to your computer (Make a note of where the file is being downloaded to e.g. Downloads)\n\n\n\n\n Download penguin data as csv\n\n\n\n\n\n\n\nTop image: Penguins data viewed in Excel, Bottom image: Penguins data in native csv format\n\n\n\nIn raw format, each line of a CSV is separated by commas for different values. When you open this in a spreadsheet program like Excel it automatically converts those comma-separated values into tables and columns.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Meet the Penguins</span>"
    ]
  },
  {
    "objectID": "04-penguin-project.html#activity-3-upload-our-data",
    "href": "04-penguin-project.html#activity-3-upload-our-data",
    "title": "3  Meet the Penguins",
    "section": "\n3.4 Activity 3: Upload our data",
    "text": "3.4 Activity 3: Upload our data\n\nThe data is now in your Downloads folder on your computer\nWe need to upload the data to our remote cloud-server (RStudio Cloud), select the upload files to server button in the Files tab\nPut your file into the data folder - if you make a mistake select the tickbox for your file, go to the cogs button and choose the option Move.\n\n\n\n\n\nHighlighted the buttons to upload files, and more options\n\n\n\n\n3.4.1 Read data from a url\nIt is also possible to use a url as a filepath\n\nurl &lt;- \"https://raw.githubusercontent.com/UEABIO/data-sci-v1/main/book/files/penguins_raw.csv\"\nread_csv(url)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Meet the Penguins</span>"
    ]
  },
  {
    "objectID": "04-penguin-project.html#activity-4-make-a-script",
    "href": "04-penguin-project.html#activity-4-make-a-script",
    "title": "3  Meet the Penguins",
    "section": "\n3.5 Activity 4: Make a script",
    "text": "3.5 Activity 4: Make a script\nLet’s now create a new R script file in which we will write instructions and store comments for manipulating data, developing tables and figures. Use the File &gt; New Script menu item and select an R Script.\nAdd the following:\n\n#___________________________----\n# SET UP ----\n# An analysis of the bill dimensions of male and female \n# Adelie, Gentoo and Chinstrap penguins\n\n# Data first published in  Gorman, KB, TD Williams, and WR Fraser. \n# 2014. \n# “Ecological Sexual Dimorphism and Environmental Variability \n# Within a Community of Antarctic Penguins (Genus Pygoscelis).” \n# PLos One 9 (3): e90081.\n# https://doi.org/10.1371/journal.pone.0090081. \n#__________________________----\n\nThen load the following add-on package to the R script, just underneath these comments. Tidyverse isn’t actually one package, but a bundle of many different packages that play well together - for example it includes ggplot2 a package for making figures.\nAdd the following to your script:\n\n# PACKAGES ----\nlibrary(tidyverse) # tidy data packages\nlibrary(janitor) # cleans variable names\n#__________________________----\n\nSave this file inside the scripts folder and call it 01_import_penguins_data.R\n\n\n\nClick on the document outline button (top right of script pane). This will show you how the use of the visual outline\n\n\nAllows us to build a series of headers and subheaders, this is very useful when using longer scripts.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Meet the Penguins</span>"
    ]
  },
  {
    "objectID": "04-penguin-project.html#activity-5-read-in-data",
    "href": "04-penguin-project.html#activity-5-read-in-data",
    "title": "3  Meet the Penguins",
    "section": "\n3.6 Activity 5: Read in data",
    "text": "3.6 Activity 5: Read in data\nNow we can read in the data. To do this we will use the function readr::read_csv() that allows us to read in .csv files. There are also functions that allow you to read in .xlsx files and other formats, however in this course we will only use .csv files.\n\nFirst, we will create an object called penguins_data that contains the data in the penguins_raw.csv file.\nAdd the following to your script, and check the document outline:\n\n\n# IMPORT DATA ----\npenguins_raw &lt;- read_csv (\"data/penguins_raw.csv\")\n\n# penguins_raw &lt;- read_csv(here(\"data\", \"penguins_raw.csv\"))\n\n# check the data has loaded\nhead(penguins_raw)\n#__________________________----\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstudyName\nSample Number\nSpecies\nRegion\nIsland\nStage\nIndividual ID\nClutch Completion\nDate Egg\nCulmen Length (mm)\nCulmen Depth (mm)\nFlipper Length (mm)\nBody Mass (g)\nSex\nDelta 15 N (o/oo)\nDelta 13 C (o/oo)\nComments\n\n\n\nPAL0708\n1\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A1\nYes\n11/11/2007\n39.1\n18.7\n181\n3750\nMALE\nNA\nNA\nNot enough blood for isotopes.\n\n\nPAL0708\n2\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A2\nYes\n11/11/2007\n39.5\n17.4\n186\n3800\nFEMALE\n8.94956\n-24.69454\nNA\n\n\nPAL0708\n3\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n16/11/2007\n40.3\n18.0\n195\n3250\nFEMALE\n8.36821\n-25.33302\nNA\n\n\nPAL0708\n4\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A2\nYes\n16/11/2007\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nAdult not sampled.\n\n\nPAL0708\n5\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n16/11/2007\n36.7\n19.3\n193\n3450\nFEMALE\n8.76651\n-25.32426\nNA\n\n\nPAL0708\n6\nAdelie Penguin (Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A2\nYes\n16/11/2007\n39.3\n20.6\n190\n3650\nMALE\n8.66496\n-25.29805\nNA\n\n\n\n\n\n\n\n\n\nNote the differences between read.csv() and read_csv. We covered this in differences between tibbles and dataframes - here most obviously is a difference in column names.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Meet the Penguins</span>"
    ]
  },
  {
    "objectID": "04-penguin-project.html#activity-check-your-script",
    "href": "04-penguin-project.html#activity-check-your-script",
    "title": "3  Meet the Penguins",
    "section": "\n3.7 Activity: Check your script",
    "text": "3.7 Activity: Check your script\n\n\nSolution\n\n\n#___________________________----\n# SET UP ----\n# An analysis of the bill dimensions of male and female \n# Adelie, Gentoo and Chinstrap penguins\n\n# Data first published in  Gorman, KB, TD Williams, and WR Fraser. \n# 2014. \n# “Ecological Sexual Dimorphism and Environmental Variability \n# Within a Community of Antarctic Penguins (Genus Pygoscelis).” \n# PLos One 9 (3): e90081.\n# https://doi.org/10.1371/journal.pone.0090081. \n#__________________________----\n\n# PACKAGES ----\n# tidy data packages\nlibrary(tidyverse) \n# cleans variable names\nlibrary(janitor) \n# make sure dates are processed properly\nlibrary(lubridate) \n#__________________________----\n\n# IMPORT DATA ----\npenguins_raw &lt;- read_csv (\"data/penguins_raw.csv\")\n\n# check the data has loaded, prints first 10 rows of dataframe\nhead(penguins_raw) \n#__________________________----",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Meet the Penguins</span>"
    ]
  },
  {
    "objectID": "04-penguin-project.html#activity-test-yourself",
    "href": "04-penguin-project.html#activity-test-yourself",
    "title": "3  Meet the Penguins",
    "section": "\n3.8 Activity: Test yourself",
    "text": "3.8 Activity: Test yourself\nQuestion 1. In order to make your R project reproducible what filepath should you use?\n\nAbsolute filepath\nRelative filepath\nQuestion 2. Which of these would be acceptable to include in a raw datafile?\n\nHighlighting some blocks of cells\nExcel formulae\nA column of observational notes from the field\na mix of ddmmyy and yymmdd date formats\nQuestion 3. What should always be the first set of functions in our script? ?()\n\nQuestion 4. When reading in data to R we should use\n\nread_csv()\nread.csv()\nQuestion 5. What format is the penguins_raw data in?\n\nmessy data\ntidy data\n\n\nExplain This Answer\n\n\nEach column is a unique variable and each row is a unique observation so this data is in a long (tidy) format\n\n\nQuestion 6. The working directory for your projects is by default set to the location of?\n\nyour data files\nthe .Rproj file\nyour R script\nQuestion 7. Using the filepath \"data/penguins_raw.csv\" is an example of\n\nan absolute filepath\na relative filepath\nQuestion 8. What operator do I need to use if I wish to assign the output of the read_csv function to an R object (rather than just print the dataframe into the console)?\n\n\n\n\n\nGorman, K., Williams, T., & Fraser, W. (2014). Ecological sexual dimorphism and environmental variability within a community of antarctic penguins (genus pygoscelis). PLos One, 9(3), e90081. https://doi.org/10.1371/journal.pone.0090081\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer archipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Meet the Penguins</span>"
    ]
  },
  {
    "objectID": "04-penguin-project.html#footnotes",
    "href": "04-penguin-project.html#footnotes",
    "title": "3  Meet the Penguins",
    "section": "",
    "text": "[More on projects can be found in the R4DS book (https://r4ds.had.co.nz/workflow-projects.html)]↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Meet the Penguins</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html",
    "href": "05-dplyr.html",
    "title": "4  Data cleaning",
    "section": "",
    "text": "4.1 Introduction to dplyr\nIn this section we will be introduced to some of the most commonly used data wrangling functions, these come from the dplyr package (part of the tidyverse). These are functions you are likely to become very familiar with.\nverb\naction\n\n\n\nselect()\nchoose columns by name\n\n\nfilter()\nselect rows based on conditions\n\n\narrange()\nreorder the rows\n\n\nsummarise()\nreduce raw data to user defined summaries\n\n\ngroup_by()\ngroup the rows by a specified column\n\n\nmutate()\ncreate a new variable",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#introduction-to-dplyr",
    "href": "05-dplyr.html#introduction-to-dplyr",
    "title": "4  Data cleaning",
    "section": "",
    "text": "Tip\n\n\n\nTry running the following functions directly in your consoleThe R console is the interactive interface within the R environment where users can type and execute R code. It is the place where you can directly enter commands, see their output, and interact with the R programming language in real-time. or make a scraps.R scrappy file to mess around in.\n\n\n\n\n4.1.1 Select\nIf we wanted to create a dataset that only includes certain variables, we can use the dplyr::select() function from the dplyr package.\nFor example I might wish to create a simplified dataset that only contains species, sex, flipper_length_mm and body_mass_g.\nRun the below code to select only those columns\n\nselect(\n   # the data object\n  .data = penguins_raw,\n   # the variables you want to select\n  `Species`, `Sex`, `Flipper Length (mm)`, `Body Mass (g)`)\n\nAlternatively you could tell R the columns you don’t want e.g. \n\nselect(.data = penguins_raw,\n       -`studyName`, -`Sample Number`)\n\nNote that select() does not change the original penguins tibble. It spits out the new tibble directly into your console.\nIf you don’t save this new tibble, it won’t be stored. If you want to keep it, then you must create a new object.\nWhen you run this new code, you will not see anything in your console, but you will see a new object appear in your Environment pane.\n\nnew_penguins &lt;- select(.data = penguins_raw, \n       `Species, `Sex`, `Flipper Length (mm)`, `Body Mass (g)`)\n\n\n4.1.2 Filter\nHaving previously used dplyr::select() to select certain variables, we will now use dplyr::filter() to select only certain rows or observations. For example only Adelie penguins.\nWe can do this with the equivalence operator ==\n\nfilter(.data = new_penguins, \n       `Species` == \"Adelie Penguin (Pygoscelis adeliae)\")\n\nWe can use several different operators to assess the way in which we should filter our data that work the same in tidyverse or base R.\n\n\n\nBoolean expressions\n\nOperator\nName\n\n\n\nA &lt; B\nless than\n\n\nA &lt;= B\nless than or equal to\n\n\nA &gt; B\ngreater than\n\n\nA &gt;= B\ngreater than or equal to\n\n\nA == B\nequivalence\n\n\nA != B\nnot equal\n\n\nA %in% B\nin\n\n\n\n\n\nIf you wanted to select all the Penguin species except Adelies, you use ‘not equals’.\n\nfilter(.data = new_penguins, \n       `Species` != \"Adelie Penguin (Pygoscelis adeliae)\")\n\nThis is the same as\n\nfilter(.data = new_penguins, \n       `Species` %in% c(\"Chinstrap penguin (Pygoscelis antarctica)\",\n                      \"Gentoo penguin (Pygoscelis papua)\")\n       )\n\nYou can include multiple expressions within filter() and it will pull out only those rows that evaluate to TRUE for all of your conditions.\nFor example the below code will pull out only those observations of Adelie penguins where flipper length was measured as greater than 190mm.\n\nfilter(.data = new_penguins, \n       `Species` == \"Adelie Penguin (Pygoscelis adeliae)\", \n       `Flipper Length (mm)` &gt; 190)\n\n\n4.1.3 Arrange\nThe function arrange() sorts the rows in the table according to the columns supplied. For example\n\narrange(.data = new_penguins, \n        `Sex`)\n\nThe data is now arranged in alphabetical order by sex. So all of the observations of female penguins are listed before males.\nYou can also reverse this with desc()\n\narrange(.data = new_penguins, \n        desc(`Sex`))\n\nYou can also sort by more than one column, what do you think the code below does?\n\narrange(.data = new_penguins,\n        `Sex`,\n        desc(`Species`),\n        desc(`Flipper Length (mm)`))\n\n\n4.1.4 Mutate\nSometimes we need to create a new variable that doesn’t exist in our dataset. For example we might want to figure out what the flipper length is when factoring in body mass.\nTo create new variables we use the function mutate().\nNote that as before, if you want to save your new column you must save it as an object. Here we are mutating a new column and attaching it to the new_penguins data oject.\n\nnew_penguins &lt;- mutate(.data = new_penguins,\n                     body_mass_kg = `Body Mass (g)`/1000)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#pipes",
    "href": "05-dplyr.html#pipes",
    "title": "4  Data cleaning",
    "section": "\n4.2 Pipes",
    "text": "4.2 Pipes\n\n\n\n\n\n\n\n\nPipes look like this: |&gt; , a pipeAn operator that allows you to chain multiple functions together in a sequence allows you to send the output from one function straight into another function. Specifically, they send the result of the function before |&gt; to be the first argument of the function after |&gt;. As usual, it’s easier to show, rather than tell so let’s look at an example.\n\n# this example uses brackets to nest and order functions\narrange(.data = filter(\n  .data = select(\n  .data = penguins_raw, \n  species, `Sex`, `Flipper Length (mm)`), \n  `Sex` == \"MALE\"), \n  desc(`Flipper Length (mm)`))\n\n\n# this example uses sequential R objects \nobject_1 &lt;- select(.data = penguins_raw, \n                   `Species`, `Sex`, `Flipper Length (mm)`)\nobject_2 &lt;- filter(.data = object_1, \n                   `Sex` == \"MALE\")\narrange(object_2, \n        desc(`Flipper Length (mm)`))\n\n\n# this example is human readable without intermediate objects\npenguins_raw |&gt;  \n  select(`Species`, `Sex`, `Flipper Length (mm)`) |&gt;  \n  filter(`Sex` == \"MALE\") |&gt;  \n  arrange(`Flipper Length (mm)`))\n\nThe reason that this function is called a pipe is because it ‘pipes’ the data through to the next function. When you wrote the code previously, the first argument of each function was the dataset you wanted to work on. When you use pipes it will automatically take the data from the previous line of code so you don’t need to specify it again.\n\n4.2.1 Task\nTry and write out as plain English what the |&gt; above is doing? You can read the |&gt; as THEN\n\n\nSolution\n\nTake the penguins data AND THEN Select only the species, sex and flipper length columns AND THEN Filter to keep only those observations labelled as sex equals male AND THEN Arrange the data from HIGHEST to LOWEST flipper lengths.\n\n\n\n\nFrom R version 4 onwards there is now a “native pipe” |&gt;\n\n\nThis doesn’t require the tidyverse magrittr package and the “old pipe” %&gt;% or any other packages to load and use.\n\n\nYou may be familiar with the magrittr pipe or see it in other tutorials, and website usages. The native pipe works equivalntly in most situations but if you want to read about some of the operational differences, this site does a good job of explaining .",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#clean-the-penguin-data",
    "href": "05-dplyr.html#clean-the-penguin-data",
    "title": "4  Data cleaning",
    "section": "\n4.3 Clean the Penguin Data",
    "text": "4.3 Clean the Penguin Data\n\n\n\n\n\n\nWarning\n\n\n\nRe-open your 01_import_penguins_data.R started in Chapter 3 and start to add these commands to your data importing and cleaning script:\n\n\n\n4.3.1 Activity 1: Explore data structure\nBefore working with your data, it’s essential to understand its underlying structure and content. In this section, we’ll use powerful functions like glimpse(), str(), summary(), head(),tail()and the add-on functionskimr::skim()` to thoroughly examine your dataset. These tools provide insights into data types, variable distributions, and sample records, helping you identify initial issues such as missing values or inconsistent data types. By gaining a clear understanding of your data’s structure, you’ll be better equipped to address any problems and proceed confidently with data cleaning and analysis.\nWhen we run glimpse() we get several lines of output. The number of observations “rows”, the number of variables “columns”. Check this against the csv file you have - they should be the same. In the next lines we see variable names and the type of data.\n\nglimpse(penguins_raw)\n\nRows: 344\nColumns: 17\n$ studyName             &lt;chr&gt; \"PAL0708\", \"PAL0708\", \"PAL0708\", \"PAL0708\", \"PAL…\n$ `Sample Number`       &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1…\n$ Species               &lt;chr&gt; \"Adelie Penguin (Pygoscelis adeliae)\", \"Adelie P…\n$ Region                &lt;chr&gt; \"Anvers\", \"Anvers\", \"Anvers\", \"Anvers\", \"Anvers\"…\n$ Island                &lt;chr&gt; \"Torgersen\", \"Torgersen\", \"Torgersen\", \"Torgerse…\n$ Stage                 &lt;chr&gt; \"Adult, 1 Egg Stage\", \"Adult, 1 Egg Stage\", \"Adu…\n$ `Individual ID`       &lt;chr&gt; \"N1A1\", \"N1A2\", \"N2A1\", \"N2A2\", \"N3A1\", \"N3A2\", …\n$ `Clutch Completion`   &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"No\", …\n$ `Date Egg`            &lt;chr&gt; \"11/11/2007\", \"11/11/2007\", \"16/11/2007\", \"16/11…\n$ `Culmen Length (mm)`  &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34…\n$ `Culmen Depth (mm)`   &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18…\n$ `Flipper Length (mm)` &lt;dbl&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190,…\n$ `Body Mass (g)`       &lt;dbl&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 34…\n$ Sex                   &lt;chr&gt; \"MALE\", \"FEMALE\", \"FEMALE\", NA, \"FEMALE\", \"MALE\"…\n$ `Delta 15 N (o/oo)`   &lt;dbl&gt; NA, 8.94956, 8.36821, NA, 8.76651, 8.66496, 9.18…\n$ `Delta 13 C (o/oo)`   &lt;dbl&gt; NA, -24.69454, -25.33302, NA, -25.32426, -25.298…\n$ Comments              &lt;chr&gt; \"Not enough blood for isotopes.\", NA, NA, \"Adult…\n\n\nWe can see a dataset with 345 rows (including the headers) and 17 variables It also provides information on the type of data in each column\n\n&lt;chr&gt; - means character or text data\n&lt;dbl&gt; - means numerical data\n\nWhen we run summary() we get similar information, in addition for any numerical values we get summary statistics such as mean, median, min, max, quartile ranges and any missing (NA) values\n\nsummary(penguins_raw)\n\n  studyName         Sample Number      Species             Region         \n Length:344         Min.   :  1.00   Length:344         Length:344        \n Class :character   1st Qu.: 29.00   Class :character   Class :character  \n Mode  :character   Median : 58.00   Mode  :character   Mode  :character  \n                    Mean   : 63.15                                        \n                    3rd Qu.: 95.25                                        \n                    Max.   :152.00                                        \n                                                                          \n    Island             Stage           Individual ID      Clutch Completion \n Length:344         Length:344         Length:344         Length:344        \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   Date Egg         Culmen Length (mm) Culmen Depth (mm) Flipper Length (mm)\n Length:344         Min.   :32.10      Min.   :13.10     Min.   :172.0      \n Class :character   1st Qu.:39.23      1st Qu.:15.60     1st Qu.:190.0      \n Mode  :character   Median :44.45      Median :17.30     Median :197.0      \n                    Mean   :43.92      Mean   :17.15     Mean   :200.9      \n                    3rd Qu.:48.50      3rd Qu.:18.70     3rd Qu.:213.0      \n                    Max.   :59.60      Max.   :21.50     Max.   :231.0      \n                    NA's   :2          NA's   :2         NA's   :2          \n Body Mass (g)      Sex            Delta 15 N (o/oo) Delta 13 C (o/oo)\n Min.   :2700   Length:344         Min.   : 7.632    Min.   :-27.02   \n 1st Qu.:3550   Class :character   1st Qu.: 8.300    1st Qu.:-26.32   \n Median :4050   Mode  :character   Median : 8.652    Median :-25.83   \n Mean   :4202                      Mean   : 8.733    Mean   :-25.69   \n 3rd Qu.:4750                      3rd Qu.: 9.172    3rd Qu.:-25.06   \n Max.   :6300                      Max.   :10.025    Max.   :-23.79   \n NA's   :2                         NA's   :14        NA's   :13       \n   Comments        \n Length:344        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n\n\nFinally the add-on package skimr provides the function skimr::skim() provides an easy to view set of summaries including column types, completion rate, number of unique variables in each column and similar statistical summaries along with a small histogram for each numeric variable.\n\nlibrary(skimr)\nskim(penguins_raw)\n\n\nData summary\n\n\nName\npenguins_raw\n\n\nNumber of rows\n344\n\n\nNumber of columns\n17\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n10\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\nstudyName\n0\n1.00\n7\n7\n0\n3\n0\n\n\nSpecies\n0\n1.00\n33\n41\n0\n3\n0\n\n\nRegion\n0\n1.00\n6\n6\n0\n1\n0\n\n\nIsland\n0\n1.00\n5\n9\n0\n3\n0\n\n\nStage\n0\n1.00\n18\n18\n0\n1\n0\n\n\nIndividual ID\n0\n1.00\n4\n6\n0\n190\n0\n\n\nClutch Completion\n0\n1.00\n2\n3\n0\n2\n0\n\n\nDate Egg\n0\n1.00\n10\n10\n0\n50\n0\n\n\nSex\n11\n0.97\n4\n6\n0\n2\n0\n\n\nComments\n290\n0.16\n18\n68\n0\n10\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nSample Number\n0\n1.00\n63.15\n40.43\n1.00\n29.00\n58.00\n95.25\n152.00\n▇▇▆▅▃\n\n\nCulmen Length (mm)\n2\n0.99\n43.92\n5.46\n32.10\n39.23\n44.45\n48.50\n59.60\n▃▇▇▆▁\n\n\nCulmen Depth (mm)\n2\n0.99\n17.15\n1.97\n13.10\n15.60\n17.30\n18.70\n21.50\n▅▅▇▇▂\n\n\nFlipper Length (mm)\n2\n0.99\n200.92\n14.06\n172.00\n190.00\n197.00\n213.00\n231.00\n▂▇▃▅▂\n\n\nBody Mass (g)\n2\n0.99\n4201.75\n801.95\n2700.00\n3550.00\n4050.00\n4750.00\n6300.00\n▃▇▆▃▂\n\n\nDelta 15 N (o/oo)\n14\n0.96\n8.73\n0.55\n7.63\n8.30\n8.65\n9.17\n10.03\n▃▇▆▅▂\n\n\nDelta 13 C (o/oo)\n13\n0.96\n-25.69\n0.79\n-27.02\n-26.32\n-25.83\n-25.06\n-23.79\n▆▇▅▅▂\n\n\n\n\n\nQ Based on our summary functions are any variables assigned to the wrong data type (should be character when numeric or vice versa)?\n\nYes\nNo\n\n\nExplanation\n\nAlthough some columns like date might not be correctly treated as character variables, they are not strictly numeric either, all other columns appear correct\n\nQ Based on our summary functions do we have complete data for all variables?\n\nYes\nNo\n\n\nExplanation\n\nNo, they are 2 missing data points for body measurements (culmen, flipper, body mass), 11 missing data points for sex, 13/14 missing data points for blood isotopes (Delta N/C) and 290 missing data points for comments\n\n\n4.3.2 Activity 2: Clean column names\n\n# CHECK DATA----\n# check the data\ncolnames(penguins_raw)\n#__________________________----\n\n [1] \"studyName\"           \"Sample Number\"       \"Species\"            \n [4] \"Region\"              \"Island\"              \"Stage\"              \n [7] \"Individual ID\"       \"Clutch Completion\"   \"Date Egg\"           \n[10] \"Culmen Length (mm)\"  \"Culmen Depth (mm)\"   \"Flipper Length (mm)\"\n[13] \"Body Mass (g)\"       \"Sex\"                 \"Delta 15 N (o/oo)\"  \n[16] \"Delta 13 C (o/oo)\"   \"Comments\"           \n\n\nWhen we run colnames() we get the identities of each column in our dataframe\n\nStudy name: an identifier for the year in which sets of observations were made\nRegion: the area in which the observation was recorded\nIsland: the specific island where the observation was recorded\nStage: Denotes reproductive stage of the penguin\nIndividual ID: the unique ID of the individual\nClutch completion: if the study nest observed with a full clutch e.g. 2 eggs\nDate egg: the date at which the study nest observed with 1 egg\nCulmen length: length of the dorsal ridge of the bird’s bill (mm)\nCulmen depth: depth of the dorsal ridge of the bird’s bill (mm)\nFlipper Length: length of bird’s flipper (mm)\nBody Mass: Bird’s mass in (g)\nSex: Denotes the sex of the bird\nDelta 15N : the ratio of stable Nitrogen isotopes 15N:14N from blood sample\nDelta 13C: the ratio of stable Carbon isotopes 13C:12C from blood sample\n\n\n4.3.2.1 Clean column names\nOften we might want to change the names of our variables. They might be non-intuitive, or too long. Our data has a couple of issues:\n\nSome of the names contain spaces\nSome of the names have capitalised letters\nSome of the names contain brackets\n\nR is case-sensitive and also doesn’t like spaces or brackets in variable names, because of this we have been forced to use backticks `Sample Number` to prevent errors when using these column names\n\n# CLEAN DATA ----\n\n# clean all variable names to snake_case \n# using the clean_names function from the janitor package\n# note we are using assign &lt;- \n# to overwrite the old version of penguins \n# with a version that has updated names\n# this changes the data in our R workspace \n# but NOT the original csv file\n\n# clean the column names\n# assign to new R object\npenguins_clean &lt;- janitor::clean_names(penguins_raw) \n\n# quickly check the new variable names\ncolnames(penguins_clean) \n\n [1] \"study_name\"        \"sample_number\"     \"species\"          \n [4] \"region\"            \"island\"            \"stage\"            \n [7] \"individual_id\"     \"clutch_completion\" \"date_egg\"         \n[10] \"culmen_length_mm\"  \"culmen_depth_mm\"   \"flipper_length_mm\"\n[13] \"body_mass_g\"       \"sex\"               \"delta_15_n_o_oo\"  \n[16] \"delta_13_c_o_oo\"   \"comments\"         \n\n\n\n\nImport and clean names\n\nWe can combine data import and name repair in a single step if we want to:\n\npenguins_clean &lt;- read_csv (\"data/penguins_raw.csv\",\n                      name_repair = janitor::make_clean_names)\n\n\n\n4.3.2.2 Rename columns (manually)\nThe clean_names function quickly converts all variable names into snake caseSnake case is a naming convention in computing that uses underscores to replace spaces between words, and writes words in lowercase. It’s commonly used for variable and subroutine names, filenames, and database table and column names. The N and C blood isotope ratio names are still quite long though, so let’s clean those with dplyr::rename() where “new_name” = “old_name”.\n\n# shorten the variable names for isotope blood samples\n# use rename from the dplyr package\npenguins_clean &lt;- rename(penguins_clean,\n         \"delta_15n\"=\"delta_15_n_o_oo\",  \n         \"delta_13c\"=\"delta_13_c_o_oo\")\n\n\n4.3.2.3 Rename text values manually\nSometimes we may want to rename the values in our variables in order to make a shorthand that is easier to follow. This is changing the values in our columns, not the column names.\n\n# use mutate and case_when \n# for a statement that conditionally changes \n# the names of the values in a variable\npenguins &lt;- penguins_clean |&gt; \n  mutate(species = case_when(\n  species == \"Adelie Penguin (Pygoscelis adeliae)\" ~ \"Adelie\",\n  species == \"Gentoo penguin (Pygoscelis papua)\" ~ \"Gentoo\",\n  species == \"Chinstrap penguin (Pygoscelis antarctica)\" ~ \"Chinstrap\",\n  .default = as.character(species)\n  )\n  )\n\n\n# use mutate and if_else\n# for a statement that conditionally changes \n# the names of the values in a variable\npenguins &lt;- penguins |&gt; \n  mutate(sex = if_else(\n    sex == \"MALE\", \"Male\", \"Female\"\n  )\n  )\n\n\n\n\n\n\n\nWarning\n\n\n\nNotice from here on out I am assigning the output of my code to the R object penguins, this means any new code “overwrites” the old penguins dataframe. This is because I ran out of new names I could think of, its also because my Environment is filling up with lots of data frame variants.\nBe aware that when you run code in this way, it can cause errors if you try to run the same code twice e.g. in the example above once you have changed MALE to Male, running the code again could cause errors as MALE is no longer present!\nIf you make any mistakes running code in this way, re-start your R session and run the code from the start to where you went wrong.\n\n\n\n\n\nHave you checked that the above code block worked? Inspect your new tibble and check the variables have been renamed as you wanted.\n\n\n\n\n4.3.2.4 Rename text values with stringr\nDatasets often contain words, and we call these words “(character) strings”.\nOften these aren’t quite how we want them to be, but we can manipulate these as much as we like. Functions in the package stringr, are fantastic. And the number of different types of manipulations are endless!\nBelow we repeat the outcomes above, but with string matching:\n\n# use mutate and case_when \n# for a statement that conditionally changes \n# the names of the values in a variable\npenguins &lt;- penguins_clean |&gt; \n  mutate(species = stringr::word(species, 1)\n  ) |&gt; \n  mutate(sex = stringr::str_to_title(sex))\n\nAlternatively we could decide we want simpler species names but that we would like to keep the latin name information, but in a separate column. To do this we are using regex. Regular expressions are a concise and flexible tool for describing patterns in strings\n\npenguins_clean |&gt; \n    separate(\n        species,\n        into = c(\"species\", \"full_latin_name\"),\n        sep = \"(?=\\\\()\"\n    ) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstudy_name\nsample_number\nspecies\nfull_latin_name\nregion\nisland\nstage\nindividual_id\nclutch_completion\ndate_egg\nculmen_length_mm\nculmen_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\ndelta_15n\ndelta_13c\ncomments\n\n\n\nPAL0708\n1\nAdelie Penguin\n(Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A1\nYes\n11/11/2007\n39.1\n18.7\n181\n3750\nMALE\nNA\nNA\nNot enough blood for isotopes.\n\n\nPAL0708\n2\nAdelie Penguin\n(Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A2\nYes\n11/11/2007\n39.5\n17.4\n186\n3800\nFEMALE\n8.94956\n-24.69454\nNA\n\n\nPAL0708\n3\nAdelie Penguin\n(Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n16/11/2007\n40.3\n18.0\n195\n3250\nFEMALE\n8.36821\n-25.33302\nNA\n\n\nPAL0708\n4\nAdelie Penguin\n(Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A2\nYes\n16/11/2007\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nAdult not sampled.\n\n\nPAL0708\n5\nAdelie Penguin\n(Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n16/11/2007\n36.7\n19.3\n193\n3450\nFEMALE\n8.76651\n-25.32426\nNA\n\n\nPAL0708\n6\nAdelie Penguin\n(Pygoscelis adeliae)\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A2\nYes\n16/11/2007\n39.3\n20.6\n190\n3650\nMALE\n8.66496\n-25.29805\nNA\n\n\n\n\n\n\n\n4.3.3 Activity 2: Checking for duplications\nIt is very easy when inputting data to make mistakes, copy something in twice for example, or if someone did a lot of copy-pasting to assemble a spreadsheet (yikes!). We can check this pretty quickly\n\n# check for whole duplicate \n# rows in the data\npenguins |&gt; \n  duplicated() |&gt;  \n  sum() \n\n[1] 0\nGreat!\nIf I did have duplications I could investigate further and extract these exact rows:\n\n# Inspect duplicated rows\npenguins |&gt; \n    filter(duplicated(penguins))\n\nA tibble:0 × 17\n0 rows | 1-8 of 17 columns\n\n# Keep only unduplicated data\npenguins |&gt; \n    filter(!duplicated(penguins))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstudy_name\nsample_number\nspecies\nregion\nisland\nstage\nindividual_id\nclutch_completion\ndate_egg\nculmen_length_mm\nculmen_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\ndelta_15n\ndelta_13c\ncomments\n\n\n\nPAL0708\n1\nAdelie\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A1\nYes\n11/11/2007\n39.1\n18.7\n181\n3750\nMale\nNA\nNA\nNot enough blood for isotopes.\n\n\nPAL0708\n2\nAdelie\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN1A2\nYes\n11/11/2007\n39.5\n17.4\n186\n3800\nFemale\n8.94956\n-24.69454\nNA\n\n\nPAL0708\n3\nAdelie\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A1\nYes\n16/11/2007\n40.3\n18.0\n195\n3250\nFemale\n8.36821\n-25.33302\nNA\n\n\nPAL0708\n4\nAdelie\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN2A2\nYes\n16/11/2007\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nAdult not sampled.\n\n\nPAL0708\n5\nAdelie\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A1\nYes\n16/11/2007\n36.7\n19.3\n193\n3450\nFemale\n8.76651\n-25.32426\nNA\n\n\nPAL0708\n6\nAdelie\nAnvers\nTorgersen\nAdult, 1 Egg Stage\nN3A2\nYes\n16/11/2007\n39.3\n20.6\n190\n3650\nMale\n8.66496\n-25.29805\nNA\n\n\n\n\n\n\n\n4.3.4 Activity 3: Checking for typos\nWe can also look for typos by asking R to produce all of the distinct values in a variable. This is more useful for categorical data, where we expect there to be only a few distinct categories\n\n# Print only unique character strings in this variable\npenguins |&gt;  \n  distinct(sex)\n\n\n\n\nsex\n\n\n\nMale\n\n\nFemale\n\n\nNA\n\n\n\n\n\n\nHere if someone had mistyped e.g. ‘FMALE’ it would be obvious. We could do the same thing (and probably should have before we changed the names) for species.\nWe can also trim leading or trailing empty spaces with stringr::str_trim. These are often problematic and difficult to spot e.g.\n\ndf2 &lt;- tibble(label=c(\"penguin\", \" penguin\", \"penguin \")) \ndf2 # make a test dataframe\n\n\n\n\nlabel\n\n\n\npenguin\n\n\npenguin\n\n\npenguin\n\n\n\n\n\n\nWe can easily imagine a scenario where data is manually input, and trailing or leading spaces are left in. These are difficult to spot by eye - but problematic because as far as R is concerned these are different values. We can use the function distinct to return the names of all the different levels it can find in this dataframe.\n\ndf2 |&gt; \n  distinct()\n\n\n\n\nlabel\n\n\n\npenguin\n\n\npenguin\n\n\npenguin\n\n\n\n\n\n\nIf we pipe the data throught the str_trim function to remove any gaps, then pipe this on to distinct again - by removing the whitespace, R now recognises just one level to this data.\n\ndf2 |&gt; \n  mutate(label=str_trim(label, side=\"both\")) |&gt; \n  distinct()\n\n\n\n\nlabel\n\n\npenguin",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#working-with-dates",
    "href": "05-dplyr.html#working-with-dates",
    "title": "4  Data cleaning",
    "section": "\n4.4 Working with dates",
    "text": "4.4 Working with dates\nWorking with dates can be tricky, treating date as strictly numeric is problematic, it won’t account for number of days in months or number of months in a year.\nAdditionally there’s a lot of different ways to write the same date:\n\n13-10-2019\n10-13-2019\n13-10-19\n13th Oct 2019\n2019-10-13\n\nThis variability makes it difficult to tell our software how to read the information, luckily we can use the functions in the lubridate package.\n\n\n\nIf you get a warning that some dates could not be parsed, then you might find the date has been inconsistently entered into the dataset.\n\n\nPay attention to warning and error messages\n\n\n\nDepending on how we interpret the date ordering in a file, we can use ymd(), ydm(), mdy(), dmy()\n\n\nQuestion What is the appropriate function from the above to use on the date_egg variable?\n\n\nymd()ydm()mdy()dmy()\n\n\n\nSolution\n\n\npenguins &lt;- penguins |&gt;\n  mutate(date_egg = lubridate::dmy(date_egg))\n\n\nHere we use the mutate function from dplyr to create a new variable called date_egg_proper based on the output of converting the characters in date_egg to date format. The original variable is left intact, if we had specified the “new” variable was also called date_egg then it would have overwritten the original variable.\nOnce we have established our date data, we are able to perform calculations or extract information. Such as the date range across which our data was collected.\n\n4.4.1 Calculations with dates\n\npenguins |&gt; \n  summarise(min_date=min(date_egg_proper),\n            max_date=max(date_egg_proper))\n\nWe can also extract and make new columns from our date column - such as a simple column of the year when each observation was made:\n\npenguins |&gt; \n  mutate(year = lubridate::year(date_egg))",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#factors",
    "href": "05-dplyr.html#factors",
    "title": "4  Data cleaning",
    "section": "\n4.5 Factors",
    "text": "4.5 Factors\nIn R, factors are a class of data that allow for ordered categories with a fixed set of acceptable values.\nTypically, you would convert a column from character or numeric class to a factor if you want to set an intrinsic order to the values (“levels”) so they can be displayed non-alphabetically in plots and tables, or for use in linear model analyses (more on this later).\nWorking with factors is easy with the forcats package:\nUsing across - we can apply functions to columns based on selected criteria - here within mutate we are changing each column in the .cols argument and applying the function forcats::as_factor()\n\npenguins |&gt; \n  mutate(\n    across(.cols = c(\"species\", \"region\", \"island\", \"stage\", \"sex\"),\n           .fns = forcats::as_factor)\n  ) |&gt; \n  select(where(is.factor)) |&gt; \n  glimpse()\n\nRows: 344\nColumns: 5\n$ species &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adelie…\n$ region  &lt;fct&gt; Anvers, Anvers, Anvers, Anvers, Anvers, Anvers, Anvers, Anvers…\n$ island  &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgersen, Torgers…\n$ stage   &lt;fct&gt; \"Adult, 1 Egg Stage\", \"Adult, 1 Egg Stage\", \"Adult, 1 Egg Stag…\n$ sex     &lt;fct&gt; Male, Female, Female, NA, Female, Male, Female, Male, NA, NA, …\n\n\n\n\n\n\n\n\nImportant\n\n\n\nUnless we assign the output of this code to an R object it will just print into the console, in the above I am demonstrating how to change variables to factors but we aren’t “saving” this change.\n\n\n\n4.5.1 Setting factor levels\nIf we want to specify the correct order for a factor we can use forcats::fct_relevel\n\npenguins &lt;- penguins |&gt; \n  mutate(mass_range = case_when(\n    body_mass_g &lt;= 3500 ~ \"smol penguin\",\n    body_mass_g &gt;3500 & body_mass_g &lt; 4500 ~ \"mid penguin\",\n    body_mass_g &gt;= 4500 ~ \"chonk penguin\",\n    .default = NA)\n  )\n\nIf we make a barplot, the order of the values on the x axis will typically be in alphabetical order for any character data\n\npenguins |&gt; \n  drop_na(mass_range) |&gt; \n  ggplot(aes(x = mass_range))+\n  geom_bar()\n\n\n\n\n\n\n\nTo convert a character or numeric column to class factor, you can use any function from the forcats package. They will convert to class factor and then also perform or allow certain ordering of the levels - for example using forcats::fct_relevel() lets you manually specify the level order.\nThe function as_factor() simply converts the class without any further capabilities.\n\npenguins &lt;- penguins |&gt; \n  mutate(mass_range = as_factor(mass_range))\n\n\nlevels(penguins$mass_range)\n\n[1] \"mid penguin\"   \"smol penguin\"  \"chonk penguin\"\n\n\nBelow we use mutate() and as_factor() to convert the column flipper_range from class character to class factor.\n\n# Correct the code in your script with this version\npenguins &lt;- penguins |&gt; \n  mutate(mass_range = fct_relevel(mass_range, \n                                  \"smol penguin\", \n                                  \"mid penguin\", \n                                  \"chonk penguin\")\n         )\n\nlevels(penguins$mass_range)\n\n[1] \"smol penguin\"  \"mid penguin\"   \"chonk penguin\"\n\n\nNow when we call a plot, we can see that the x axis categories match the intrinsic order we have specified with our factor levels.\n\npenguins |&gt; \n  drop_na(mass_range) |&gt;  \n  ggplot(aes(x = mass_range))+\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\nFactors will also be important when we build linear models a bit later. The reference or intercept for a categorical predictor variable when it is read as a &lt;chr&gt; is set by R as the first one when ordered alphabetically. This may not always be the most appropriate choice, and by changing this to an ordered &lt;fct&gt; we can manually set the intercept.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#summary",
    "href": "05-dplyr.html#summary",
    "title": "4  Data cleaning",
    "section": "\n4.6 Summary",
    "text": "4.6 Summary\nIn this chapter we have successfully imported and checked our data for typos and small errors, we have also been introduce to some of the key functions in the dplyr package for data wrangling. Now that we have confidence in the format and integrity of our data, next time we will start to make insights and understand patterns.\n\n4.6.1 Save scripts\n\nMake sure you have saved your script 💾 and given it the filename 01_import_penguins_data.R it should be saved in your scripts folder\n\n\n\n\nCheck your script\n\n\n#___________________________----\n# SET UP ----\n## An analysis of the bill dimensions of male and female Adelie, Gentoo and Chinstrap penguins ----\n\n### Data first published in  Gorman, KB, TD Williams, and WR Fraser. 2014. “Ecological Sexual Dimorphism and Environmental Variability Within a Community of Antarctic Penguins (Genus Pygoscelis).” PLos One 9 (3): e90081. https://doi.org/10.1371/journal.pone.0090081. ----\n#__________________________----\n\n# PACKAGES ----\nlibrary(tidyverse) # tidy data packages\nlibrary(janitor) # cleans variable names\n#__________________________----\n# IMPORT DATA ----\npenguins_raw &lt;- read_csv (\"data/penguins_raw.csv\")\n\nattributes(penguins_raw) # reads as tibble\n\nhead(penguins_raw) # check the data has loaded, prints first 10 rows of dataframe\n\n# CLEAN DATA ----\n\n# clean all variable names to snake_case \n# using the clean_names function from the janitor package\n# note we are using assign &lt;- \n# to overwrite the old version of penguins \n# with a version that has updated names\n# this changes the data in our R workspace \n# but NOT the original csv file\n\n# clean the column names\n# assign to new R object\npenguins_clean &lt;- janitor::clean_names(penguins_raw) \n\n# quickly check the new variable names\ncolnames(penguins_clean) \n\n# shorten the variable names for N and C isotope blood samples\n\npenguins &lt;- rename(penguins_clean,\n         \"delta_15n\"=\"delta_15_n_o_oo\",  # use rename from the dplyr package\n         \"delta_13c\"=\"delta_13_c_o_oo\")\n\n# use mutate and case_when for a statement that conditionally changes the names of the values in a variable\npenguins &lt;- penguins_clean |&gt; \n  mutate(species = case_when(species == \"Adelie Penguin (Pygoscelis adeliae)\" ~ \"Adelie\",\n                             species == \"Gentoo penguin (Pygoscelis papua)\" ~ \"Gentoo\",\n                             species == \"Chinstrap penguin (Pygoscelis antarctica)\" ~ \"Chinstrap\"))\n\n# use mutate and if_else\n# for a statement that conditionally changes \n# the names of the values in a variable\npenguins &lt;- penguins |&gt; \n  mutate(sex = if_else(\n    sex == \"MALE\", \"Male\", \"Female\"\n  )\n  )\n\n# use lubridate to format date and extract the year\npenguins &lt;- penguins |&gt;\n  mutate(date_egg = lubridate::dmy(date_egg))\n\npenguins |&gt; \n  mutate(year = lubridate::year(date_egg))\n\n# Set body mass ranges\npenguins &lt;- penguins |&gt; \n  mutate(mass_range = case_when(\n    body_mass_g &lt;= 3500 ~ \"smol penguin\",\n    body_mass_g &gt;3500 & body_mass_g &lt; 4500 ~ \"mid penguin\",\n    body_mass_g &gt;= 4500 ~ \"chonk penguin\",\n    .default = NA)\n  )\n\n# Assign these to an ordered factor\n\npenguins &lt;- penguins |&gt; \n  mutate(mass_range = fct_relevel(mass_range, \n                                  \"smol penguin\", \n                                  \"mid penguin\", \n                                  \"chonk penguin\")\n         )\n\n\n\nDoes your workspace look like the below?\n\n\n\n\n\nMy neat project layout\n\n\n\n\n\n\n\nMy scripts and file subdirectory\n\n\n\n\nDoes your script run from a blank slateR projects are set not to store their .Rhistory file which means everything required to recreate your analysis is contained in your scripts blank slate without errors as described in {#sec-workflow}\n\n4.6.2 Checklist for data checking\n\nIs our dataframe in a tidy dataTidy data refers to a specific format for organizing datasets that makes data easier to work with for analysis and visualization in R, especially using the tidyverse. The concept was popularized by Hadley Wickham in his paper “Tidy Data” and is an essential principle for effective data manipulation. format?\n\nIs each column assigned to the correct data type?\n\nAre dates formatted correctly?\nAre factors set where needed, are the levels in the correct order?\n\n\nAre variables consistently named (e.g. using a naming convention such as snake_case)?\nAre text values in an appropriate format?\nDo we have any data duplication?\nAre there any typos or mistakes in character strings?",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#activity-test-yourself",
    "href": "05-dplyr.html#activity-test-yourself",
    "title": "4  Data cleaning",
    "section": "\n4.7 Activity: Test yourself",
    "text": "4.7 Activity: Test yourself\nQuestion 1. In order to subset a data by rows I should use the function \nselect()\nfilter()\ngroup_by()\nQuestion 2. In order to subset a data by columns I should use the function \nselect()\nfilter()\ngroup_by()\nQuestion 3. In order to make a new column I should use the function \ngroup_by()\nselect()\nmutate()\narrange()\nQuestion 4. Which operator should I use to send the output from line of code into the next line? \n+\n&lt;-)\n|&gt;\n%in%\nQuestion 5. What will be the outcome of the following line of code?\n\npenguins |&gt; \n  filter(species == \"Adelie\")\n\n\nThe penguins dataframe object is reduced to include only Adelie penguins from now on\nA new filtered dataframe of only Adelie penguins will be printed into the console\n\n\nExplain this answer\n\nUnless the output of a series of functions is “assigned” to an object using &lt;- it will not be saved, the results will be immediately printed. This code would have to be modified to the below in order to create a new filtered object penguins_filtered\n\npenguins_filtered &lt;- penguins |&gt; \n  filter(species == \"Adelie\")\n\n\n\nQuestion 6. What is the main point of a data “pipe”?\n\nThe code runs faster\nThe code is easier to read\nQuestion 7. The naming convention outputted by the function `janitor::clean_names() is \nsnake_case\ncamelCase\nSCREAMING_SNAKE_CASE\nkebab-case\nQuestion 8. Which package provides useful functions for manipulating character strings?\n\nstringr\nggplot2\nlubridate\nforcats\nQuestion 9. Which package provides useful functions for manipulating dates?\n\nstringr\nggplot2\nlubridate\nforcats\nQuestion 10. If we do not specify a character variable as a factor, then ordering will default to what?\n\nnumerical\nalphabetical\norder in the dataframe",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#glossary",
    "href": "05-dplyr.html#glossary",
    "title": "4  Data cleaning",
    "section": "\n4.8 Glossary",
    "text": "4.8 Glossary\n\n\n\n\nterm\ndefinition\n\n\n\nblank slate\nR projects are set not to store their .Rhistory file which means everything required to recreate your analysis is contained in your scripts\n\n\nconsole\nThe R console is the interactive interface within the R environment where users can type and execute R code. It is the place where you can directly enter commands, see their output, and interact with the R programming language in real-time.\n\n\npipe\nAn operator that allows you to chain multiple functions together in a sequence\n\n\nsnake case\nSnake case is a naming convention in computing that uses underscores to replace spaces between words, and writes words in lowercase. It's commonly used for variable and subroutine names, filenames, and database table and column names\n\n\ntidy data\nTidy data refers to a specific format for organizing datasets that makes data easier to work with for analysis and visualization in R, especially using the tidyverse. The concept was popularized by Hadley Wickham in his paper \"Tidy Data\" and is an essential principle for effective data manipulation.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "05-dplyr.html#reading",
    "href": "05-dplyr.html#reading",
    "title": "4  Data cleaning",
    "section": "\n4.9 Reading",
    "text": "4.9 Reading\n\nDplyr\nLubridate\nStringr",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data cleaning</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Gorman, K., Williams, T., & Fraser, W. (2014). Ecological sexual\ndimorphism and environmental variability within a community of antarctic\npenguins (genus pygoscelis). PLos One, 9(3), e90081.\nhttps://doi.org/10.1371/journal.pone.0090081\n\n\nHorst, A., Hill, A., & Gorman, K. (2022). Palmerpenguins: Palmer\narchipelago (antarctica) penguin data. https://allisonhorst.github.io/palmerpenguins/\n\n\nWickham, H. (2023). Tidyverse: Easily install and load the\ntidyverse. https://tidyverse.tidyverse.org",
    "crumbs": [
      "Appendices",
      "References"
    ]
  }
]