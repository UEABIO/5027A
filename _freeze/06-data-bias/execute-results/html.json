{
  "hash": "f44067c2b36650fc65fcb834858020e0",
  "result": {
    "engine": "knitr",
    "markdown": "# Data bias {#sec-bias}\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n\n## Sampling Bias\n\n### Explanation: \n\nSampling bias occurs when the data collected does not properly represent the population you are studying. This often happens if certain groups are over- or underrepresented. For example, if you survey only college students to understand a city's general population, your data will be biased because it doesn’t capture other demographics like older adults or people who do not attend college.\n\n### Why it matters: \n\nSampling bias leads to incorrect generalisations about the entire population, as conclusions are based on a skewed subset of data.\n\n### Example:\n\nThere are three locations with native foxgloves *Digitalis purpurea* and about 1000 plants in each site.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-data-bias_files/figure-html/unnamed-chunk-2-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\nIf we measured every single plant in each site we might find there is a slightly different average height at each location: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|Group      |     mean|        sd|\n|:----------|--------:|---------:|\n|Location 1 | 50.16128|  9.916950|\n|Location 2 | 60.42465| 10.096742|\n|Location 3 | 69.79887|  9.783575|\n\n</div>\n:::\n:::\n\n\n\n### Sampling\n\nIn a more likely scenario we will \"sample\", measuring a subset of individuals from each location - however if we do this in an unrepresentative way (e.g. not taking 1/3 of our samples from each location) then we may skew or bias our results:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nprob_obs_location <- biased_sample_data %>% \n  group_by(Group) %>% \n  summarise(n = n()) %>% \n  mutate(prob_obs = n/sum(n))\n\n\nbiased_sample_data %>% \n  # set as factor and provide levels\n  ggplot()+\n  geom_bar(aes(x=Group),\n           fill=\"steelblue\",\n           width=0.8)+\n  labs(x=\"\",\n       y = \"Number of observations\")+\n  geom_text(data=prob_obs_location,\n            aes(y=(n+50),\n                x=Group,\n                label=scales::percent(prob_obs)))+\n  coord_flip()+\n  ggtitle(\"Uneven sampling distribution\")\n```\n\n::: {.cell-output-display}\n![](06-data-bias_files/figure-html/unnamed-chunk-4-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\nWhen we compare our results from an even sampling distribution to an uneven sampling distribution  you can see we have biased our findings - in Location 3 the plants are slightly taller, but they are underrepresented in our sampling and so we have a smaller estimate of plant height. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-data-bias_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Missing Not at Random (MNAR) Bias\n\n### 1. Missing Completely at Random (MCAR):\n\nDefinition: Missing values occur entirely by chance, with no relationship to any other data in the dataset.\nExample in Palmer Penguins: Imagine if a researcher accidentally forgot to record the flipper length of some penguins on random days. The missing data isn't related to the penguins’ species, size, or other characteristics. This is MCAR.\n\nWhy it matters: If data is MCAR, the missing values are less of a problem because they are truly random and do not introduce bias into the analysis.\n\n### 2. Missing at Random (MAR):\n\nDefinition: The missingness is related to other observed data, but not to the missing value itself.\nExample in Palmer Penguins: Suppose the flipper length is more likely to be missing for certain species or on specific islands, but within those groups, it's random. For example, maybe the flipper length is more often missing for penguins from the Adelie species. This would be MAR.\n\nWhy it matters: While the missing values aren't completely random, they can be predicted based on other variables. If we know which variables are related to the missingness (e.g., species or island), we can handle it using imputation techniques.\n\n### 3. Missing Not at Random (MNAR):\n\nDefinition: The missingness is related to the actual value of the missing data.\n\nExample in Palmer Penguins: Imagine if the flipper length is missing because the researcher only skipped recording measurements for penguins with very small or very large flippers. This is MNAR because the missing values depend on the value itself (in this case, extreme flipper lengths).\n\n### Why it matters: \n\nThis type of missingness is the hardest to deal with because the missing data is biased and not random. Special techniques or assumptions are required to handle it correctly.\n\n- MCAR: Missing by pure chance, unrelated to any data.\n\n- MAR: Missingness depends on other known variables (e.g., species).\n\n- MNAR: Missingness depends on the value that is missing (e.g., missing small flipper lengths).\n\n### Explanation: \n\nMNAR bias arises when data is systematically missing due to the value of the missing data itself. For instance, if people with extremely high incomes are less likely to report their income in a survey, this creates MNAR bias. The missing data is not random—it's directly related to the variable being measured.\n\n### Why it matters: \n\nMNAR bias distorts conclusions because certain trends are hidden in the missing data. Ignoring this can lead to underestimating the variability or misunderstanding the true patterns in the data.\n\n### Example: \n\nA weather monitoring station cuts out/fails to record at extreme high and low temperatures. This is a good example of MNAR, the missing value temperature, is the thing that causes recording failure. In the example below we have the original, incomplete measurements: \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-data-bias_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\nAnd here we see the difference when the missing data is included, our original trend line was too flat, because it missed some seasonal fluctuations of high and low temperatures - we would have concluded temperature is more stable across the year than it really is. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nweather_data |>\n  filter(Record == \"Temperature_Missing\") |>\nggplot(aes(x = Day,\n           y = Temperature_Celsius)) +\n  geom_line(aes(colour = Colour,\n                alpha = Colour,\n                group = 1))+\n  ggtitle(\"Temperature Data with and without Missing Data\") +\n  ylab(\"Temperature (°C)\") +\n  geom_smooth(method = \"loess\",\n              se = FALSE,\n              colour = \"darkred\")+\n  geom_smooth(data = weather_data |> filter(Record == \"Temperature\"),\n              method = \"loess\",\n              se = FALSE,\n              colour = \"blue\")+\n  scale_colour_identity()+\n  scale_alpha_manual(values = c(.4, .8))+\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output-display}\n![](06-data-bias_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Survivorship Bias\n\n### Explanation: \n\nSurvivorship bias occurs when you focus on the data points that survive a process and ignore those that did not. A famous example is from World War II, where analysts looked at the bullet holes on planes that returned from battle and suggested reinforcing areas where they saw damage. They overlooked the planes that didn’t return, which were hit in critical areas not visible on surviving planes.\n\n### Why it matters: \n\nFocusing only on surviving or successful subjects can lead to false conclusions, as the failure cases (which provide crucial insights) are excluded from the analysis.\n\n### Example \n\nDuring World War II, the military wanted to reinforce fighter planes to reduce the number of planes lost in combat. Engineers examined the planes that returned from battle and noted where the bullet holes were most concentrated. These planes had more damage in areas like the wings, tail, and fuselage, but relatively few bullet holes in the engine or cockpit areas.\n\nAt first, it seemed logical to reinforce the parts of the planes that had the most bullet holes, because that’s where the damage was most common. However, this would have been a mistake.\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-data-bias_files/figure-html/unnamed-chunk-8-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n\nThe Realization (Correct Conclusion):\n\nThe key insight came by realising they were only looking at planes that **survived and returned** from battle. The planes that had been shot in critical areas, such as the engine or cockpit, did not return — they were shot down. Therefore, the fact that the returning planes had little damage in those areas indicated that hits to these parts were fatal and led to planes being lost.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-data-bias_files/figure-html/unnamed-chunk-9-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Outlier Bias\n\n### Explanation: \n\nOutlier bias happens when extreme values (outliers) unduly influence the results of an analysis. Outliers can occur due to data entry errors, measurement errors, or true but rare events. For example, if you're analyzing average income and a few extremely high incomes are present in the data, they can raise the average, making it seem like the typical person earns more than they actually do.\n\n### Why it matters: \n\nOutliers can distort the results, especially when using statistical methods like the mean or regression. This can lead to misleading conclusions unless the outliers are properly handled.\n\n### Example:\n\nIn this trend line we can see how just a few extreme data points can alter the slope of association between two variables\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-data-bias_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n### What to do about it\n\nDealing with outliers is difficult - what we should never do is drop them from the dataset without careful consideration. First we should attempt to determine if they are impossible or simply improbable.\n\n### Example:\n\nA measurement of human heights finds several values that are extremely large, more than 3 standard deviations from the mean or greater than 1.5X the IQR. This should prompt us to pay close attention to this data, but while it is extreme we should not discount it. However, by contrast a negative value or a height so large or small as to be impossible for a human being can be safely removed as an impossible value. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-data-bias_files/figure-html/unnamed-chunk-11-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\nWhen we have excluded impossible values we should record this, implausible values will be kept for now until we know if they affect our analyses. \n\n## Omitted variable bias\n\n### Explanation: \n\nOmitted variable bias occurs when a relevant variable is left out of an analysis, leading to incorrect conclusions. For example, a drug may appear ineffective if you don't account for gender differences, but including gender in the analysis may reveal that the drug works well for women but not for men.\n\n### Why it matters: \n\nIgnoring important variables can mask the true relationships between variables, leading to faulty interpretations and conclusions.\n\n### Example:\n\nA new drug is being tested in a clinical trial setting and initial analysis indicates little evidence of an effect\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-data-bias_files/figure-html/unnamed-chunk-12-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\nBut when separated into clinically relevant subgroups such as gender we see that the drug does produce strong responses, but they are positive for women and negative for men, not including other important control variables can lead to over or underestimating effects, depending on how they interact. \n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-data-bias_files/figure-html/unnamed-chunk-13-1.png){fig-align='center' width=100%}\n:::\n:::\n\n\n\n\n## Summary\n\nUnderstanding bias in data and analysis is crucial because it helps ensure that conclusions drawn from data are accurate and reliable. Bias can distort results, leading to incorrect interpretations, faulty decisions, and misleading insights. Whether it’s selection bias, survivorship bias, or other forms, failing to account for bias can cause analysts to overlook critical information or make assumptions that don’t reflect the full reality. Recognising and addressing bias is key to maintaining the integrity of analysis and making well-informed, data-driven decisions.\n",
    "supporting": [
      "06-data-bias_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}